 # Grok : 비정영화된 데이터를 분석해서 정형화시킴
 # Ruby :  출력을 보기좋은 json 포맷으로 바꿔줌
 # message, @version, @timestamp, host 필드는 logstash에 내장되어 있는 필드
 # mutate에 입력하는 메세지를 split으로 나누어 message 배열에 저장하도록 구현
 # field 명을 생성할 때 대괄호를 안에도 쳐야함 %{[field_name][index]} 


input { 
  kafka { 
    bootstrap_servers => "${KAFKA_SERVER}"
    topics => "input"
    codec => json 
    } 
}


# filter { 

  # mutate { 
  #   add_field => {"time" => "%{@timestamp}"}
  #   } 

  # date { 
  #   match => ["time", "ISO8601"] 
  #   target => "@timestamp" 
  #   } 

  # json{ 
  #   source => "message" 
  #   remove_field => ["video_unique"] #우리칼럼명꺼로넣어
  #   } 
    
#   grok{
#     match => ["chat_id", "%{NUMBER:chat_id:int}"]
#     overwrite => ["chat_id"]
#     }

#   grok{
#     match => ["abuse", "%{NUMBER:abuse:float}"]
#     overwrite => ["abuse"]
#     }

#   grok{
#     match => ["emotion", "%{NUMBER:emotion:float}"]
#     overwrite => ["emotion"]
#     }
# } 

output { 
   stdout { 
     codec => rubydebug #rubydebug는 출력을 보기좋은 포맷으로 바꿔 준다.
  } 
  mongodb { 
      #  uri => "mongodb://ek:ek@${MONGODB_HOST}/LiveCommerce" 
      # uri => "mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@${MONGODB_HOST}/LiveCommerce"  # mongodb://아이디:비번@Mongoddb서버주소:포트넘버/
       uri => "mongodb://ek:ek@mongodb:27017/LiveCommerce"
       collection => "LiveCommerce" 
       database => "LiveCommerce" 
       codec => json 
      # isodate => true
  } 
  
}