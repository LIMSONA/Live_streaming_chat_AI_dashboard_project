 # Grok : 비정영화된 데이터를 분석해서 정형화시킴
 # Ruby :  출력을 보기좋은 json 포맷으로 바꿔줌
 # message, @version, @timestamp, host 필드는 logstash에 내장되어 있는 필드
 # mutate에 입력하는 메세지를 split으로 나누어 message 배열에 저장하도록 구현
 # field 명을 생성할 때 대괄호를 안에도 쳐야함 %{[field_name][index]} 


input { 
  kafka { 
    bootstrap_servers => "${KAFKA_SERVER}"
    topics => "message"
    codec => json 
    } 
}
output { 
   stdout { 
     codec => rubydebug #rubydebug는 출력을 보기좋은 포맷으로 바꿔 준다.
  } 
    influxdb {
      # measurement => "location"
       # send_as_tags => ["your_tag_name"]
      data_points => {}
       #     ...
      # }c
      host => "influxdb_default"
      db => "db0"
      user => "admin"
      password => "password"
      codec => json
    }
  }