 # Grok : 비정영화된 데이터를 분석해서 정형화시킴
 # Ruby :  출력을 보기좋은 json 포맷으로 바꿔줌
 # message, @version, @timestamp, host 필드는 logstash에 내장되어 있는 필드
 # mutate에 입력하는 메세지를 split으로 나누어 message 배열에 저장하도록 구현
 # field 명을 생성할 때 대괄호를 안에도 쳐야함 %{[field_name][index]} 


# input { 
#   kafka { 
#     bootstrap_servers => "${KAFKA_SERVER}"
#     topics => "input" 
#     codec => json 
#   } 
  
# } 

filter {

# filter { 
#
#     mutate {
#         # message에서 스플릿을 하고싶으면 split 기호를 / 이렇게 정하고
#         # split => {"message" => "/"} 이렇게 작성하면 댐 
#         add_field => {"time" => "%{@timestamp}"}
#     } 


# filter { 

#   mutate { 
#     add_field => {"time" => "%{@timestamp}"}
#     } 

  # date { 
  #   match => ["time", "ISO8601"] 
  #   target => "@timestamp" 
  #   } 

#   json{ 
#     source => "message" 
#     remove_field => ["message","@version","_id"] 
#     } 
    
#   grok{
#     match => ["chat_id", "%{NUMBER:chat_id:int}"]
#     overwrite => ["chat_id"]
#     }

#   grok{
#     match => ["abuse", "%{NUMBER:abuse:float}"]
#     overwrite => ["abuse"]
#     }

#   grok{
#     match => ["emotion", "%{NUMBER:emotion:float}"]
#     overwrite => ["emotion"]
#     }
} 

# output { 
#    stdout { 
#      codec => rubydebug #rubydebug는 출력을 보기좋은 포맷으로 바꿔 준다.
#   } 
#   mongodb { 
#       #  uri => "mongodb://ek:ek@${MONGODB_HOST}/LiveCommerce" 
#       # uri => "mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@${MONGODB_HOST}/LiveCommerce"  
#       # mongodb://아이디:비번@Mongoddb서버주소:포트넘버/
#        uri => "mongodb://ek:ek@mongodb:27017"
#        collection => "LiveCommerce" 
#        database => "LiveCommerce" 
#        codec => json 
#        isodate => true
#   } 
  
# }