{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8cd895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# install 없이 import 가능한 모듈\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import bz2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "550e2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "?ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e324ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6697, 0.2794, 0.4329],\n",
      "        [0.4944, 0.3505, 0.8900],\n",
      "        [0.0087, 0.2734, 0.0721],\n",
      "        [0.5704, 0.3738, 0.0837],\n",
      "        [0.1363, 0.8818, 0.6198]])\n",
      "1.10.2+cu102\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# torch 사용가능한지 확인\n",
    "\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f7e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('naver_shopping_all_220427.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b134877",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if rate < 3 else 1 for rate in df.label] # 3점 미만이면 0(부정), 3점 초과이면 1(긍정)으로 라벨 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66c12648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112500 37500 50000\n",
      "112500 37500 50000\n"
     ]
    }
   ],
   "source": [
    "#평가 데이터셋 분리\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df['text'].tolist(), y, random_state=0)\n",
    "\n",
    "#학습, 검증 데이터셋분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=0)\n",
    "\n",
    "print(len(X_train), len(X_val), len(X_test))\n",
    "print(len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbd3b9",
   "metadata": {},
   "source": [
    "### bert-base-multilingual-cased를 이용한 미세조정학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96babd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 전 GPU 정리\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61c265c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.10.2+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(torch.__version__)\n",
    "#model.to(device)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "635f3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 측정을 위한 준비 단계 (... 잘 모르겠음..)\n",
    "\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "# 정확도 계산 함수 생성\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c675467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안', '##녕', '##하', '##세', '##요', '.', '반', '##갑', '##습', '##니다', '.']\n",
      "{'input_ids': [101, 9521, 118741, 35506, 24982, 48549, 119, 9321, 118610, 119081, 48345, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 준비&확인\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "print(tokenizer.tokenize('안녕하세요. 반갑습니다.'))\n",
    "\n",
    "inputs = tokenizer('안녕하세요. 반갑습니다.')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8c5f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbcd680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "val_input = tokenizer(X_val, truncation=True, padding=True, return_tensors='pt')\n",
    "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "059b39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 생성\n",
    "train_dataset = OurDataset(train_input, y_train)\n",
    "val_dataset = OurDataset(val_input, y_val)\n",
    "test_dataset = OurDataset(test_input, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e86c1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# bert-base-multilingual-cased 사전학습 모형으로부터 분류기 모형을 생성\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0b3fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1    #checkpoint 갯수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0650d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath='./checkpoint_test',\n",
    "#     save_top_k=3,\n",
    "#     monitor='val_acc',\n",
    "#     mode='max'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "462c2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 객체생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f3edcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14063' max='14063' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14063/14063 4:06:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.553600</td>\n",
       "      <td>0.481021</td>\n",
       "      <td>0.813360</td>\n",
       "      <td>203.460700</td>\n",
       "      <td>184.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.529100</td>\n",
       "      <td>0.737283</td>\n",
       "      <td>0.503227</td>\n",
       "      <td>206.998000</td>\n",
       "      <td>181.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.539900</td>\n",
       "      <td>0.479215</td>\n",
       "      <td>0.811067</td>\n",
       "      <td>204.227700</td>\n",
       "      <td>183.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.636900</td>\n",
       "      <td>0.667264</td>\n",
       "      <td>0.615013</td>\n",
       "      <td>215.121200</td>\n",
       "      <td>174.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.622497</td>\n",
       "      <td>0.747707</td>\n",
       "      <td>206.774200</td>\n",
       "      <td>181.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>0.661193</td>\n",
       "      <td>0.569147</td>\n",
       "      <td>207.713400</td>\n",
       "      <td>180.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.695135</td>\n",
       "      <td>0.520507</td>\n",
       "      <td>203.757100</td>\n",
       "      <td>184.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.685652</td>\n",
       "      <td>0.496773</td>\n",
       "      <td>203.796400</td>\n",
       "      <td>184.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>209.343200</td>\n",
       "      <td>179.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.489309</td>\n",
       "      <td>0.815520</td>\n",
       "      <td>210.486200</td>\n",
       "      <td>178.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>0.479946</td>\n",
       "      <td>0.814960</td>\n",
       "      <td>210.711700</td>\n",
       "      <td>177.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>0.487416</td>\n",
       "      <td>0.808720</td>\n",
       "      <td>209.254600</td>\n",
       "      <td>179.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>0.526834</td>\n",
       "      <td>0.780427</td>\n",
       "      <td>209.097400</td>\n",
       "      <td>179.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.540467</td>\n",
       "      <td>0.745520</td>\n",
       "      <td>214.293500</td>\n",
       "      <td>174.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.575785</td>\n",
       "      <td>0.709147</td>\n",
       "      <td>210.465900</td>\n",
       "      <td>178.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.560147</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>209.791800</td>\n",
       "      <td>178.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.597300</td>\n",
       "      <td>0.586146</td>\n",
       "      <td>0.721040</td>\n",
       "      <td>206.909400</td>\n",
       "      <td>181.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.595300</td>\n",
       "      <td>0.621236</td>\n",
       "      <td>0.663227</td>\n",
       "      <td>211.199700</td>\n",
       "      <td>177.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.629501</td>\n",
       "      <td>0.666293</td>\n",
       "      <td>206.314800</td>\n",
       "      <td>181.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.547335</td>\n",
       "      <td>0.759440</td>\n",
       "      <td>212.042800</td>\n",
       "      <td>176.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>0.592227</td>\n",
       "      <td>0.681387</td>\n",
       "      <td>203.753400</td>\n",
       "      <td>184.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.698321</td>\n",
       "      <td>0.503227</td>\n",
       "      <td>207.487800</td>\n",
       "      <td>180.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.709869</td>\n",
       "      <td>0.497813</td>\n",
       "      <td>211.273200</td>\n",
       "      <td>177.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.660200</td>\n",
       "      <td>0.556062</td>\n",
       "      <td>0.756347</td>\n",
       "      <td>209.482900</td>\n",
       "      <td>179.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.656659</td>\n",
       "      <td>0.578960</td>\n",
       "      <td>213.706900</td>\n",
       "      <td>175.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.642780</td>\n",
       "      <td>0.605493</td>\n",
       "      <td>208.740200</td>\n",
       "      <td>179.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.602600</td>\n",
       "      <td>0.596800</td>\n",
       "      <td>0.673280</td>\n",
       "      <td>215.423200</td>\n",
       "      <td>174.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.583400</td>\n",
       "      <td>0.585588</td>\n",
       "      <td>0.689200</td>\n",
       "      <td>209.994500</td>\n",
       "      <td>178.576000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5536\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.856764305664972e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.04\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.4810209274291992\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.81336\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "203.4607\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "184.311\n",
      "Attempted to log scalar metric epoch:\n",
      "0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5291\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.6777196877461866e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.07\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.7372829914093018\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.5032266666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "206.998\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "181.161\n",
      "Attempted to log scalar metric epoch:\n",
      "0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5399\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.498675069827401e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.11\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.4792153239250183\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.8110666666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "204.2277\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "183.619\n",
      "Attempted to log scalar metric epoch:\n",
      "0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6369\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.3196304519086153e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.14\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6672639846801758\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6150133333333333\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "215.1212\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "174.32\n",
      "Attempted to log scalar metric epoch:\n",
      "0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5725\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.1405858339898304e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.18\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6224966049194336\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.7477066666666666\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "206.7742\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "181.357\n",
      "Attempted to log scalar metric epoch:\n",
      "0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5182\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.9615412160710454e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.21\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6611927151679993\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.5691466666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "207.7134\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "180.537\n",
      "Attempted to log scalar metric epoch:\n",
      "0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.7025\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.78249659815226e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.25\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.695135235786438\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.5205066666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "203.7571\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "184.043\n",
      "Attempted to log scalar metric epoch:\n",
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6915\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.603451980233474e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.28\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6856516599655151\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.49677333333333334\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "203.7964\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "184.007\n",
      "Attempted to log scalar metric epoch:\n",
      "0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6952\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.4244073623146885e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.32\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6891151070594788\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.5103466666666666\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "209.3432\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "179.132\n",
      "Attempted to log scalar metric epoch:\n",
      "0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5656\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.2453627443959035e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.36\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.48930948972702026\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.81552\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "210.4862\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "178.159\n",
      "Attempted to log scalar metric epoch:\n",
      "0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5247\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.0663181264771186e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.39\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.4799462556838989\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.81496\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "210.7117\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "177.968\n",
      "Attempted to log scalar metric epoch:\n",
      "0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5223\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.887273508558333e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.43\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.48741602897644043\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.80872\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "209.2546\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "179.208\n",
      "Attempted to log scalar metric epoch:\n",
      "0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5103\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.7082288906395476e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.46\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5268344879150391\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.7804266666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "209.0974\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "179.342\n",
      "Attempted to log scalar metric epoch:\n",
      "0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5698\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.529184272720762e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.5\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5404667854309082\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.74552\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "214.2935\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "174.994\n",
      "Attempted to log scalar metric epoch:\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5684\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.350139654801977e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.53\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5757848620414734\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.7091466666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "210.4659\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "178.176\n",
      "Attempted to log scalar metric epoch:\n",
      "0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5498\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.1710950368831914e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.57\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5601468086242676\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.7264\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "209.7918\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "178.749\n",
      "Attempted to log scalar metric epoch:\n",
      "0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5973\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.992050418964406e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.6\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5861457586288452\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.72104\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "206.9094\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "181.239\n",
      "Attempted to log scalar metric epoch:\n",
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5953\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.8130058010456208e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.64\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6212357878684998\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6632266666666666\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "211.1997\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "177.557\n",
      "Attempted to log scalar metric epoch:\n",
      "0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6133\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.6339611831268355e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.68\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6295010447502136\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6662933333333333\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "206.3148\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "181.761\n",
      "Attempted to log scalar metric epoch:\n",
      "0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.588\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.4549165652080499e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.71\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5473349094390869\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.75944\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "212.0428\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "176.851\n",
      "Attempted to log scalar metric epoch:\n",
      "0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6112\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.2758719472892647e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.75\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5922272205352783\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6813866666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "203.7534\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "184.046\n",
      "Attempted to log scalar metric epoch:\n",
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6657\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.0968273293704792e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.78\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6983214616775513\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.5032266666666667\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "207.4878\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "180.733\n",
      "Attempted to log scalar metric epoch:\n",
      "0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.699\n",
      "Attempted to log scalar metric learning_rate:\n",
      "9.177827114516938e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "0.82\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.7098689079284668\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.49781333333333333\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "211.2732\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "177.495\n",
      "Attempted to log scalar metric epoch:\n",
      "0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6602\n",
      "Attempted to log scalar metric learning_rate:\n",
      "7.387380935329084e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "0.85\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5560619831085205\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.7563466666666666\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "209.4829\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "179.012\n",
      "Attempted to log scalar metric epoch:\n",
      "0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.656\n",
      "Attempted to log scalar metric learning_rate:\n",
      "5.59693475614123e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "0.89\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6566588282585144\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.57896\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "213.7069\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "175.474\n",
      "Attempted to log scalar metric epoch:\n",
      "0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6623\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.806488576953377e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "0.92\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6427804231643677\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6054933333333333\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "208.7402\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "179.649\n",
      "Attempted to log scalar metric epoch:\n",
      "0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6026\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.016042397765523e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "0.96\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.596799910068512\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.67328\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "215.4232\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "174.076\n",
      "Attempted to log scalar metric epoch:\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.5834\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.2559621857766956e-07\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5855880975723267\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.6892\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "209.9945\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "178.576\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric train_runtime:\n",
      "14813.9026\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "0.949\n",
      "Attempted to log scalar metric total_flos:\n",
      "1.500651376875e+16\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14063, training_loss=0.5994022111418678, metrics={'train_runtime': 14813.9026, 'train_samples_per_second': 0.949, 'total_flos': 1.500651376875e+16, 'epoch': 1.0, 'init_mem_cpu_alloc_delta': -1048576, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 1048576, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 78082048, 'train_mem_gpu_alloc_delta': 2166102528, 'train_mem_cpu_peaked_delta': 745082880, 'train_mem_gpu_peaked_delta': 877608448})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c90bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('questionDetection_model_v0.0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63a8940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11135/2497499804.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.5845708250999451\n",
      "Attempted to log scalar metric eval_accuracy:\n",
      "0.69154\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "275.5246\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "181.472\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5845708250999451,\n",
       " 'eval_accuracy': 0.69154,\n",
       " 'eval_runtime': 275.5246,\n",
       " 'eval_samples_per_second': 181.472,\n",
       " 'epoch': 1.0,\n",
       " 'eval_mem_cpu_alloc_delta': 8192,\n",
       " 'eval_mem_gpu_alloc_delta': 0,\n",
       " 'eval_mem_cpu_peaked_delta': 0,\n",
       " 'eval_mem_gpu_peaked_delta': 62691328}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d3e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_azureml_py38",
   "language": "python",
   "name": "conda-env-new_azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
