{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff032c8",
   "metadata": {},
   "source": [
    "# 0. 들어가기 앞서\n",
    "\n",
    "* 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6590be",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd80559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c03f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f00e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27195632",
   "metadata": {},
   "source": [
    "# 2. 모델, 사전, 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d08d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_QA_baseline/.cache/kobert_v1.zip\n",
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_QA_baseline/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4d31c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '질의응답_K쇼핑_질문유형분류_원본.csv',\n",
       " '[0차] 원본데이터_preprocessing.ipynb',\n",
       " '질의응답_K쇼핑_질문분류_원본.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../[0차] 원본_preprocessing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0662872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../[0차] 원본_preprocessing/질의응답_K쇼핑_질문분류_원본.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68210ad6",
   "metadata": {},
   "source": [
    "# 3. 질문분류시작\n",
    "\n",
    "* 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7182b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2중 리스트로 변환됨\n",
    "\n",
    "data_list = []\n",
    "for q, label in zip(df[\"msg\"],df[\"QA\"])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ae42c",
   "metadata": {},
   "source": [
    "## 3-1. Train / Test set 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3766de",
   "metadata": {},
   "source": [
    "* 라벨링은 이미 진행했으므로, 바로 train/ test 분리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189c8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c20346a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753924\n",
      "251309\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba4b04",
   "metadata": {},
   "source": [
    "## 3-2. KoBERT 입력 데이터로 만들기\n",
    "\n",
    "* 데이터를 train data와 test data로 나누었다면 각 데이터가 KoBERT 모델의 입력으로 들어갈 수 있는 형태가 되도록 토큰화, 정수 인코딩, 패딩 등을 해주어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325540ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f60101ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "\n",
    "max_len = 32 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d51a085",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_QA_baseline/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "tokenizer= get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a38a513a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 2847, 4103, 5130,  793, 5925,  517,   54, 2926, 6141, 6050,\n",
       "        2822, 5330, 7287,  517, 7707, 7494,  517, 7710, 7753, 6664,  517,\n",
       "        6539, 5931, 3647, 6314, 2650, 6749, 6964, 4227, 1767,    3],\n",
       "       dtype=int32),\n",
       " array(32, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째는 패딩된 시퀀스\n",
    "# 두 번째는 길이와 타입에 대한 내용\n",
    "# 세 번재는 어텐션 마스크 시퀀스\n",
    "\n",
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd75b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a46aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch용 DataLoader 사용(torch 형식의 dataset을 만들어주기)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1b0fb",
   "metadata": {},
   "source": [
    "## 3-3. KoBERT 학습모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6cc27",
   "metadata": {},
   "source": [
    "* 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0 \n",
    "* 3가지의 class를 분류하기 때문에 num_classes는 3으로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba1174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=3,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6b75d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee52fb4",
   "metadata": {},
   "source": [
    "## 3-4. KoBERT 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1f3486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14730/2673822008.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f299470bab48b2aef231190609ee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.6713322997093201 train acc 0.8125\n",
      "epoch 1 batch id 201 loss 0.37738046050071716 train acc 0.8468594527363185\n",
      "epoch 1 batch id 401 loss 0.22280533611774445 train acc 0.8641677057356608\n",
      "epoch 1 batch id 601 loss 0.33898356556892395 train acc 0.8824875207986689\n",
      "epoch 1 batch id 801 loss 0.23097948729991913 train acc 0.8920099875156055\n",
      "epoch 1 batch id 1001 loss 0.167324960231781 train acc 0.8983204295704296\n",
      "epoch 1 batch id 1201 loss 0.08900411427021027 train acc 0.9041944213155704\n",
      "epoch 1 batch id 1401 loss 0.12853601574897766 train acc 0.908168272662384\n",
      "epoch 1 batch id 1601 loss 0.23934578895568848 train acc 0.9110126483447845\n",
      "epoch 1 batch id 1801 loss 0.27416399121284485 train acc 0.9137978900610771\n",
      "epoch 1 batch id 2001 loss 0.18008917570114136 train acc 0.916104447776112\n",
      "epoch 1 batch id 2201 loss 0.1914428323507309 train acc 0.9173671058609723\n",
      "epoch 1 batch id 2401 loss 0.13977640867233276 train acc 0.9189139941690962\n",
      "epoch 1 batch id 2601 loss 0.2002972811460495 train acc 0.9196583044982699\n",
      "epoch 1 batch id 2801 loss 0.16167175769805908 train acc 0.9212781149589432\n",
      "epoch 1 batch id 3001 loss 0.24046072363853455 train acc 0.9222550816394535\n",
      "epoch 1 batch id 3201 loss 0.24398024380207062 train acc 0.9228561387066542\n",
      "epoch 1 batch id 3401 loss 0.048254646360874176 train acc 0.9236437812408115\n",
      "epoch 1 batch id 3601 loss 0.30696433782577515 train acc 0.9244741044154402\n",
      "epoch 1 batch id 3801 loss 0.19374403357505798 train acc 0.9250690607734806\n",
      "epoch 1 batch id 4001 loss 0.23743490874767303 train acc 0.9257998000499875\n",
      "epoch 1 batch id 4201 loss 0.15343160927295685 train acc 0.9263791359200191\n",
      "epoch 1 batch id 4401 loss 0.06098208203911781 train acc 0.9271401386048626\n",
      "epoch 1 batch id 4601 loss 0.2651103138923645 train acc 0.927733101499674\n",
      "epoch 1 batch id 4801 loss 0.04942570626735687 train acc 0.9281660070818579\n",
      "epoch 1 batch id 5001 loss 0.277974396944046 train acc 0.9285830333933214\n",
      "epoch 1 batch id 5201 loss 0.2818277180194855 train acc 0.9287216400692174\n",
      "epoch 1 batch id 5401 loss 0.10919035971164703 train acc 0.9293475745232365\n",
      "epoch 1 batch id 5601 loss 0.3817979395389557 train acc 0.9296331012319229\n",
      "epoch 1 batch id 5801 loss 0.14194968342781067 train acc 0.9297588777796931\n",
      "epoch 1 batch id 6001 loss 0.10008768737316132 train acc 0.930178303616064\n",
      "epoch 1 batch id 6201 loss 0.06812655925750732 train acc 0.9304749233994517\n",
      "epoch 1 batch id 6401 loss 0.0942596048116684 train acc 0.9307237150445243\n",
      "epoch 1 batch id 6601 loss 0.10984335094690323 train acc 0.9311089228904711\n",
      "epoch 1 batch id 6801 loss 0.18365557491779327 train acc 0.9313244375827084\n",
      "epoch 1 batch id 7001 loss 0.25423455238342285 train acc 0.9314963933723753\n",
      "epoch 1 batch id 7201 loss 0.150934636592865 train acc 0.9316544577142064\n",
      "epoch 1 batch id 7401 loss 0.05094636231660843 train acc 0.9318250912038913\n",
      "epoch 1 batch id 7601 loss 0.1986926645040512 train acc 0.9319209643467965\n",
      "epoch 1 batch id 7801 loss 0.1117715910077095 train acc 0.931939815408281\n",
      "epoch 1 batch id 8001 loss 0.21465077996253967 train acc 0.932074896887889\n",
      "epoch 1 batch id 8201 loss 0.18216264247894287 train acc 0.9321995793195952\n",
      "epoch 1 batch id 8401 loss 0.04315677285194397 train acc 0.9323257647899059\n",
      "epoch 1 batch id 8601 loss 0.26101553440093994 train acc 0.9325369143122892\n",
      "epoch 1 batch id 8801 loss 0.03546341136097908 train acc 0.9326994091580503\n",
      "epoch 1 batch id 9001 loss 0.16908268630504608 train acc 0.9328199644483947\n",
      "epoch 1 batch id 9201 loss 0.4743625223636627 train acc 0.9330235843930008\n",
      "epoch 1 batch id 9401 loss 0.3609747886657715 train acc 0.9331520582916711\n",
      "epoch 1 batch id 9601 loss 0.22326329350471497 train acc 0.9333500416623268\n",
      "epoch 1 batch id 9801 loss 0.1083214059472084 train acc 0.9335463218038975\n",
      "epoch 1 batch id 10001 loss 0.12804867327213287 train acc 0.93369100589941\n",
      "epoch 1 batch id 10201 loss 0.28343185782432556 train acc 0.93379325556318\n",
      "epoch 1 batch id 10401 loss 0.18784311413764954 train acc 0.9338435006249399\n",
      "epoch 1 batch id 10601 loss 0.17130891978740692 train acc 0.933980284878785\n",
      "epoch 1 batch id 10801 loss 0.2189738154411316 train acc 0.9340830710119433\n",
      "epoch 1 batch id 11001 loss 0.0738164559006691 train acc 0.9341821198072903\n",
      "epoch 1 batch id 11201 loss 0.17994114756584167 train acc 0.9342134630836533\n",
      "epoch 1 batch id 11401 loss 0.19058257341384888 train acc 0.9342245197789668\n",
      "epoch 1 batch id 11601 loss 0.21489010751247406 train acc 0.9342190328419964\n",
      "epoch 1 batch id 11801 loss 0.04481134191155434 train acc 0.9343064147106177\n",
      "epoch 1 batch id 12001 loss 0.06336309760808945 train acc 0.9343283893008916\n",
      "epoch 1 batch id 12201 loss 0.0369725339114666 train acc 0.9344392877632981\n",
      "epoch 1 batch id 12401 loss 0.09659738093614578 train acc 0.9345113297314732\n",
      "epoch 1 batch id 12601 loss 0.35448157787323 train acc 0.9346257241488771\n",
      "epoch 1 batch id 12801 loss 0.21435584127902985 train acc 0.934646219045387\n",
      "epoch 1 batch id 13001 loss 0.32516077160835266 train acc 0.934730982232136\n",
      "epoch 1 batch id 13201 loss 0.13387234508991241 train acc 0.9348652564199682\n",
      "epoch 1 batch id 13401 loss 0.1462436467409134 train acc 0.9349768673979554\n",
      "epoch 1 batch id 13601 loss 0.20440234243869781 train acc 0.9350783030659511\n",
      "epoch 1 batch id 13801 loss 0.046802960336208344 train acc 0.9351722701253532\n",
      "epoch 1 batch id 14001 loss 0.26268860697746277 train acc 0.9352055210342118\n",
      "epoch 1 batch id 14201 loss 0.08903086185455322 train acc 0.9351784205337652\n",
      "epoch 1 batch id 14401 loss 0.39685046672821045 train acc 0.9352215123949725\n",
      "epoch 1 batch id 14601 loss 0.13391035795211792 train acc 0.9352869666461201\n",
      "epoch 1 batch id 14801 loss 0.18229714035987854 train acc 0.935418214985474\n",
      "epoch 1 batch id 15001 loss 0.15470942854881287 train acc 0.9354980501299913\n",
      "epoch 1 batch id 15201 loss 0.3185572922229767 train acc 0.935569617130452\n",
      "epoch 1 batch id 15401 loss 0.03748846799135208 train acc 0.9355906272319979\n",
      "epoch 1 batch id 15601 loss 0.14876219630241394 train acc 0.9356311294147811\n",
      "epoch 1 batch id 15801 loss 0.06353790313005447 train acc 0.9357121384722485\n",
      "epoch 1 batch id 16001 loss 0.31558769941329956 train acc 0.9357794044122242\n",
      "epoch 1 batch id 16201 loss 0.08475268632173538 train acc 0.9358488673538671\n",
      "epoch 1 batch id 16401 loss 0.2730347216129303 train acc 0.9359737973294311\n",
      "epoch 1 batch id 16601 loss 0.07879287749528885 train acc 0.9360750105415336\n",
      "epoch 1 batch id 16801 loss 0.03042534925043583 train acc 0.9360956937087078\n",
      "epoch 1 batch id 17001 loss 0.26758861541748047 train acc 0.9361416240221163\n",
      "epoch 1 batch id 17201 loss 0.412171334028244 train acc 0.9360738474507296\n",
      "epoch 1 batch id 17401 loss 0.059629712253808975 train acc 0.9361638698925349\n",
      "epoch 1 batch id 17601 loss 0.09931258857250214 train acc 0.9362713766263281\n",
      "epoch 1 batch id 17801 loss 0.17807376384735107 train acc 0.9363062468400651\n",
      "epoch 1 batch id 18001 loss 0.22531862556934357 train acc 0.9364045747458475\n",
      "epoch 1 batch id 18201 loss 0.11480855196714401 train acc 0.9364320641722982\n",
      "epoch 1 batch id 18401 loss 0.24883916974067688 train acc 0.9364691456986033\n",
      "epoch 1 batch id 18601 loss 0.1612391173839569 train acc 0.936495349712381\n",
      "epoch 1 batch id 18801 loss 0.09028756618499756 train acc 0.9365642120099995\n",
      "epoch 1 batch id 19001 loss 0.1713677942752838 train acc 0.9366234013999263\n",
      "epoch 1 batch id 19201 loss 0.14850802719593048 train acc 0.9366911228581845\n",
      "epoch 1 batch id 19401 loss 0.5320892930030823 train acc 0.9368347636719757\n",
      "epoch 1 batch id 19601 loss 0.15493641793727875 train acc 0.9368670603540635\n",
      "epoch 1 batch id 19801 loss 0.0736546441912651 train acc 0.9368860789859098\n",
      "epoch 1 batch id 20001 loss 0.0757884755730629 train acc 0.9368890930453477\n",
      "epoch 1 batch id 20201 loss 0.06748861819505692 train acc 0.9369461907826345\n",
      "epoch 1 batch id 20401 loss 0.22307175397872925 train acc 0.9370557815793343\n",
      "epoch 1 batch id 20601 loss 0.13587765395641327 train acc 0.937108635503131\n",
      "epoch 1 batch id 20801 loss 0.03572565317153931 train acc 0.9371454497379934\n",
      "epoch 1 batch id 21001 loss 0.10805096477270126 train acc 0.9371964430265225\n",
      "epoch 1 batch id 21201 loss 0.24994775652885437 train acc 0.9372022546106316\n",
      "epoch 1 batch id 21401 loss 0.056217536330223083 train acc 0.9372342413905892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 21601 loss 0.059612151235342026 train acc 0.9372728693116059\n",
      "epoch 1 batch id 21801 loss 0.10626745223999023 train acc 0.9373236892803083\n",
      "epoch 1 batch id 22001 loss 0.032149143517017365 train acc 0.9373863688014181\n",
      "epoch 1 batch id 22201 loss 0.416692852973938 train acc 0.937436658258637\n",
      "epoch 1 batch id 22401 loss 0.3622431457042694 train acc 0.9374665193518147\n",
      "epoch 1 batch id 22601 loss 0.3928498923778534 train acc 0.9375221229149153\n",
      "epoch 1 batch id 22801 loss 0.19935035705566406 train acc 0.9375849743432305\n",
      "epoch 1 batch id 23001 loss 0.06947287172079086 train acc 0.9376290704751967\n",
      "epoch 1 batch id 23201 loss 0.1982797086238861 train acc 0.9376589371147795\n",
      "epoch 1 batch id 23401 loss 0.1719861626625061 train acc 0.9376976411264476\n",
      "epoch 1 train acc 0.9377612898433852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14730/2673822008.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23468a75eaf8495b9540a478686c1a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.944120830150242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d75e3a7f2b449178ebc017c9a5dd439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.15985627472400665 train acc 0.96875\n",
      "epoch 2 batch id 201 loss 0.1864076405763626 train acc 0.9345460199004975\n",
      "epoch 2 batch id 401 loss 0.19038473069667816 train acc 0.9390586034912718\n",
      "epoch 2 batch id 601 loss 0.12435223907232285 train acc 0.9407757903494176\n",
      "epoch 2 batch id 801 loss 0.12288222461938858 train acc 0.9406601123595506\n",
      "epoch 2 batch id 1001 loss 0.3048648536205292 train acc 0.939935064935065\n",
      "epoch 2 batch id 1201 loss 0.03089788928627968 train acc 0.9411427976686095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 3201 loss 0.30379876494407654 train acc 0.9412488284910965\n",
      "epoch 2 batch id 3401 loss 0.14878815412521362 train acc 0.9415613054983828\n",
      "epoch 2 batch id 3601 loss 0.5793598890304565 train acc 0.9416221188558733\n",
      "epoch 2 batch id 3801 loss 0.20120035111904144 train acc 0.9417834122599316\n",
      "epoch 2 batch id 4001 loss 0.3725069463253021 train acc 0.9417255061234692\n",
      "epoch 2 batch id 4201 loss 0.1440453827381134 train acc 0.9416879909545346\n",
      "epoch 2 batch id 4401 loss 0.05173569172620773 train acc 0.9419521131561008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 5001 loss 0.22692067921161652 train acc 0.9422615476904619\n",
      "epoch 2 batch id 5201 loss 0.23618099093437195 train acc 0.9421144972120746\n",
      "epoch 2 batch id 5401 loss 0.13292382657527924 train acc 0.9423254952786521\n",
      "epoch 2 batch id 5601 loss 0.2737630009651184 train acc 0.9422815122299589\n",
      "epoch 2 batch id 5801 loss 0.1959785372018814 train acc 0.9419173418376142\n",
      "epoch 2 batch id 6001 loss 0.11611108481884003 train acc 0.9416191051491418\n",
      "epoch 2 batch id 6201 loss 0.05464968830347061 train acc 0.9414761731978714\n",
      "epoch 2 batch id 6401 loss 0.045884281396865845 train acc 0.9415521012341822\n",
      "epoch 2 batch id 6601 loss 0.08790092915296555 train acc 0.9413819875776398\n",
      "epoch 2 batch id 6801 loss 0.17504191398620605 train acc 0.9413872959858844\n",
      "epoch 2 batch id 7001 loss 0.25396066904067993 train acc 0.9414503285244965\n",
      "epoch 2 batch id 7201 loss 0.16198013722896576 train acc 0.9414838216914317\n",
      "epoch 2 batch id 7401 loss 0.09790629148483276 train acc 0.9414732806377517\n",
      "epoch 2 batch id 7601 loss 0.1796841025352478 train acc 0.9413646230759111\n",
      "epoch 2 batch id 7801 loss 0.09518033266067505 train acc 0.9413256313293168\n",
      "epoch 2 batch id 8001 loss 0.15446682274341583 train acc 0.9413862329708786\n",
      "epoch 2 batch id 8201 loss 0.11388202011585236 train acc 0.9413752895988294\n",
      "epoch 2 batch id 8401 loss 0.045805711299180984 train acc 0.9413946256398048\n",
      "epoch 2 batch id 8601 loss 0.21998998522758484 train acc 0.94144212882223\n",
      "epoch 2 batch id 8801 loss 0.03497757762670517 train acc 0.9414271105556187\n",
      "epoch 2 batch id 9001 loss 0.20680023729801178 train acc 0.9413467948005777\n",
      "epoch 2 batch id 9201 loss 0.5531885623931885 train acc 0.9413990327138354\n",
      "epoch 2 batch id 9401 loss 0.1992063820362091 train acc 0.9413659451122222\n",
      "epoch 2 batch id 9601 loss 0.20804394781589508 train acc 0.9414286272263306\n",
      "epoch 2 batch id 9801 loss 0.10252094268798828 train acc 0.9415429548005305\n",
      "epoch 2 batch id 10001 loss 0.1985863447189331 train acc 0.9416277122287772\n",
      "epoch 2 batch id 10201 loss 0.11729052662849426 train acc 0.9416509410842074\n",
      "epoch 2 batch id 10401 loss 0.21166297793388367 train acc 0.9416432314200558\n",
      "epoch 2 batch id 10601 loss 0.20468372106552124 train acc 0.94172424771248\n",
      "epoch 2 batch id 10801 loss 0.0949511006474495 train acc 0.9417906906767892\n",
      "epoch 2 batch id 11001 loss 0.058714039623737335 train acc 0.9418291518952823\n",
      "epoch 2 batch id 11201 loss 0.09825298190116882 train acc 0.941788121596286\n",
      "epoch 2 batch id 11401 loss 0.1544974446296692 train acc 0.9418033505832821\n",
      "epoch 2 batch id 11601 loss 0.1317639946937561 train acc 0.9417560986121886\n",
      "epoch 2 batch id 11801 loss 0.029977699741721153 train acc 0.941792538767901\n",
      "epoch 2 batch id 12001 loss 0.06931410729885101 train acc 0.9417574577118574\n",
      "epoch 2 batch id 12201 loss 0.07492153346538544 train acc 0.9418387837062536\n",
      "epoch 2 batch id 12401 loss 0.14878244698047638 train acc 0.9419099266188211\n",
      "epoch 2 batch id 12601 loss 0.3950788378715515 train acc 0.9419391318149353\n",
      "epoch 2 batch id 12801 loss 0.2858631908893585 train acc 0.9419698656354972\n",
      "epoch 2 batch id 13001 loss 0.21239851415157318 train acc 0.9420284978078609\n",
      "epoch 2 batch id 13201 loss 0.05453888326883316 train acc 0.9420900878721309\n",
      "epoch 2 batch id 13401 loss 0.457875519990921 train acc 0.942154503395269\n",
      "epoch 2 batch id 13601 loss 0.2396111637353897 train acc 0.9421503933534299\n",
      "epoch 2 batch id 13801 loss 0.08262462913990021 train acc 0.9421282878052315\n",
      "epoch 2 batch id 14001 loss 0.28062742948532104 train acc 0.9421514534676094\n",
      "epoch 2 batch id 14201 loss 0.08774001151323318 train acc 0.9420727413562425\n",
      "epoch 2 batch id 14401 loss 0.23917049169540405 train acc 0.9421025449621554\n",
      "epoch 2 batch id 14601 loss 0.10869002342224121 train acc 0.9421358126155743\n",
      "epoch 2 batch id 14801 loss 0.1904442459344864 train acc 0.9421850719545977\n",
      "epoch 2 batch id 15001 loss 0.15409067273139954 train acc 0.9422621825211652\n",
      "epoch 2 batch id 15201 loss 0.32590991258621216 train acc 0.9422344747056115\n",
      "epoch 2 batch id 15401 loss 0.03242076560854912 train acc 0.9422074865268489\n",
      "epoch 2 batch id 15601 loss 0.45459139347076416 train acc 0.9421851964617652\n",
      "epoch 2 batch id 15801 loss 0.0663142204284668 train acc 0.9422267578001392\n",
      "epoch 2 batch id 16001 loss 0.21285662055015564 train acc 0.9422809511905506\n",
      "epoch 2 batch id 16201 loss 0.057020027190446854 train acc 0.9422720819702487\n",
      "epoch 2 batch id 16401 loss 0.08118519932031631 train acc 0.9423396439241509\n",
      "epoch 2 batch id 16601 loss 0.06893328577280045 train acc 0.9423698120595145\n",
      "epoch 2 batch id 16801 loss 0.021688802167773247 train acc 0.9423583417653711\n",
      "epoch 2 batch id 17001 loss 0.30851686000823975 train acc 0.9423691988706546\n",
      "epoch 2 batch id 17201 loss 0.3574097454547882 train acc 0.9422707982094064\n",
      "epoch 2 batch id 17401 loss 0.07176422327756882 train acc 0.942298574794552\n",
      "epoch 2 batch id 17601 loss 0.24560432136058807 train acc 0.942354127606386\n",
      "epoch 2 batch id 17801 loss 0.11671046912670135 train acc 0.9422960788719735\n",
      "epoch 2 batch id 18001 loss 0.21638746559619904 train acc 0.9423486889617243\n",
      "epoch 2 batch id 18201 loss 0.09422225505113602 train acc 0.942305711224658\n",
      "epoch 2 batch id 18401 loss 0.14564889669418335 train acc 0.942260271180914\n",
      "epoch 2 batch id 18601 loss 0.41006216406822205 train acc 0.9422779689264018\n",
      "epoch 2 batch id 18801 loss 0.2836175262928009 train acc 0.9423285330567523\n",
      "epoch 2 batch id 19001 loss 0.21770334243774414 train acc 0.9423780327351192\n",
      "epoch 2 batch id 19201 loss 0.12119602411985397 train acc 0.9424037159522941\n",
      "epoch 2 batch id 19401 loss 0.5934977531433105 train acc 0.9425206819236122\n",
      "epoch 2 batch id 19601 loss 0.3817347586154938 train acc 0.9425619228610785\n",
      "epoch 2 batch id 19801 loss 0.1989179253578186 train acc 0.9425644538154638\n",
      "epoch 2 batch id 20001 loss 0.08519333600997925 train acc 0.9425544347782611\n",
      "epoch 2 batch id 20201 loss 0.0774492621421814 train acc 0.9426080392059799\n",
      "epoch 2 batch id 20401 loss 0.20421895384788513 train acc 0.9426866330081859\n",
      "epoch 2 batch id 20601 loss 0.08175152540206909 train acc 0.9427500485413329\n",
      "epoch 2 batch id 20801 loss 0.05972793325781822 train acc 0.9427521513388779\n",
      "epoch 2 batch id 21001 loss 0.08354949951171875 train acc 0.942794390743298\n",
      "epoch 2 batch id 21201 loss 0.2722134292125702 train acc 0.942793087590208\n",
      "epoch 2 batch id 21401 loss 0.040975458920001984 train acc 0.9428166324003551\n",
      "epoch 2 batch id 21601 loss 0.18646979331970215 train acc 0.9428296143697051\n",
      "epoch 2 batch id 21801 loss 0.21188509464263916 train acc 0.9428409247282235\n",
      "epoch 2 batch id 22001 loss 0.06295730173587799 train acc 0.942853449843189\n",
      "epoch 2 batch id 22201 loss 0.24284034967422485 train acc 0.9428544885365524\n",
      "epoch 2 batch id 22401 loss 0.27943655848503113 train acc 0.9428387683585554\n",
      "epoch 2 batch id 22601 loss 0.30951952934265137 train acc 0.9429035219680545\n",
      "epoch 2 batch id 22801 loss 0.1863500028848648 train acc 0.9429506929520635\n",
      "epoch 2 batch id 23001 loss 0.09398683905601501 train acc 0.9429657949654363\n",
      "epoch 2 batch id 23201 loss 0.21708089113235474 train acc 0.9430008404810137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 2001 loss 0.2143349051475525 train acc 0.9449650174912544\n",
      "epoch 3 batch id 2201 loss 0.14813576638698578 train acc 0.9445706497046797\n",
      "epoch 3 batch id 2401 loss 0.12956920266151428 train acc 0.9442159516867972\n",
      "epoch 3 batch id 2601 loss 0.11064151674509048 train acc 0.9439758746635909\n",
      "epoch 3 batch id 2801 loss 0.11601313948631287 train acc 0.9445622099250268\n",
      "epoch 3 batch id 3001 loss 0.06880909949541092 train acc 0.9443102299233589\n",
      "epoch 3 batch id 3201 loss 0.2748487889766693 train acc 0.944148313027179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 5801 loss 0.24595405161380768 train acc 0.9447886140320635\n",
      "epoch 3 batch id 6001 loss 0.08718191087245941 train acc 0.9449518830194967\n",
      "epoch 3 batch id 6201 loss 0.017170244827866554 train acc 0.9447568940493469\n",
      "epoch 3 batch id 6401 loss 0.04788504168391228 train acc 0.9448279565692861\n",
      "epoch 3 batch id 6601 loss 0.17266497015953064 train acc 0.9448994470534767\n",
      "epoch 3 batch id 6801 loss 0.18458138406276703 train acc 0.9449575430083811\n",
      "epoch 3 batch id 7001 loss 0.23212362825870514 train acc 0.9450435652049707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 9201 loss 0.3744829297065735 train acc 0.9447818171937833\n",
      "epoch 3 batch id 9401 loss 0.14768704771995544 train acc 0.9447731624295288\n",
      "epoch 3 batch id 9601 loss 0.22535528242588043 train acc 0.9448625143214249\n",
      "epoch 3 batch id 9801 loss 0.08479530364274979 train acc 0.9449131466176921\n",
      "epoch 3 batch id 10001 loss 0.18875668942928314 train acc 0.9449711278872113\n",
      "epoch 3 batch id 10201 loss 0.0954781100153923 train acc 0.9450053916282717\n",
      "epoch 3 batch id 10401 loss 0.12948673963546753 train acc 0.9450293241034516\n",
      "epoch 3 batch id 10601 loss 0.22202101349830627 train acc 0.9450936232430903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 13001 loss 0.15491464734077454 train acc 0.9451917160218445\n",
      "epoch 3 batch id 13201 loss 0.05287919566035271 train acc 0.9452977047193395\n",
      "epoch 3 batch id 13401 loss 0.36613574624061584 train acc 0.9453608872472203\n",
      "epoch 3 batch id 13601 loss 0.28229233622550964 train acc 0.9453785567237704\n",
      "epoch 3 batch id 13801 loss 0.045480385422706604 train acc 0.9453504275052532\n",
      "epoch 3 batch id 14001 loss 0.23382218182086945 train acc 0.9453766695236054\n",
      "epoch 3 batch id 14201 loss 0.10070531070232391 train acc 0.945296546017886\n",
      "epoch 3 batch id 14401 loss 0.19735458493232727 train acc 0.9453466773140754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 17001 loss 0.2882872521877289 train acc 0.9459645756131992\n",
      "epoch 3 batch id 17201 loss 0.4161304533481598 train acc 0.9459297424568339\n",
      "epoch 3 batch id 17401 loss 0.12423323094844818 train acc 0.9459837078328832\n",
      "epoch 3 batch id 17601 loss 0.27512112259864807 train acc 0.9460328958581898\n",
      "epoch 3 batch id 17801 loss 0.1268053650856018 train acc 0.9460177799000056\n",
      "epoch 3 batch id 18001 loss 0.13461896777153015 train acc 0.9461193128159546\n",
      "epoch 3 batch id 18201 loss 0.0945521742105484 train acc 0.9461207488599528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 20601 loss 0.08127056062221527 train acc 0.9465393063443522\n",
      "epoch 3 batch id 20801 loss 0.04378838464617729 train acc 0.9465169943752704\n",
      "epoch 3 batch id 21001 loss 0.3311086595058441 train acc 0.9465605804485501\n",
      "epoch 3 batch id 21201 loss 0.21061034500598907 train acc 0.9465237488797699\n",
      "epoch 3 batch id 21401 loss 0.14313600957393646 train acc 0.9465182701742909\n",
      "epoch 3 batch id 21601 loss 0.16924962401390076 train acc 0.9464738322299894\n",
      "epoch 3 batch id 21801 loss 0.15525983273983002 train acc 0.9464918467042797\n",
      "epoch 3 batch id 22001 loss 0.0576753243803978 train acc 0.9465152152174902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1801 loss 0.1961064487695694 train acc 0.9496980843975569\n",
      "epoch 4 batch id 2001 loss 0.16780635714530945 train acc 0.9498844327836082\n",
      "epoch 4 batch id 2201 loss 0.06627018004655838 train acc 0.9493838028169014\n",
      "epoch 4 batch id 2401 loss 0.12716104090213776 train acc 0.9495132236568097\n",
      "epoch 4 batch id 2601 loss 0.07987946271896362 train acc 0.9493584198385236\n",
      "epoch 4 batch id 2801 loss 0.08761551231145859 train acc 0.9500847911460193\n",
      "epoch 4 batch id 3001 loss 0.1874416321516037 train acc 0.9499125291569477\n",
      "epoch 4 batch id 3201 loss 0.21166186034679413 train acc 0.9495763042799126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 5601 loss 0.27470266819000244 train acc 0.950226522049634\n",
      "epoch 4 batch id 5801 loss 0.1992512196302414 train acc 0.9502133252887434\n",
      "epoch 4 batch id 6001 loss 0.0600331574678421 train acc 0.9503416097317113\n",
      "epoch 4 batch id 6201 loss 0.05012010410428047 train acc 0.9503457103692953\n",
      "epoch 4 batch id 6401 loss 0.03076469898223877 train acc 0.9503788470551476\n",
      "epoch 4 batch id 6601 loss 0.17995457351207733 train acc 0.9504573170731707\n",
      "epoch 4 batch id 6801 loss 0.17818957567214966 train acc 0.9504117041611527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 9201 loss 0.33789899945259094 train acc 0.9503111074883165\n",
      "epoch 4 batch id 9401 loss 0.0954081192612648 train acc 0.9502845441974258\n",
      "epoch 4 batch id 9601 loss 0.13500037789344788 train acc 0.9503339495885845\n",
      "epoch 4 batch id 9801 loss 0.0646088495850563 train acc 0.9504259769411284\n",
      "epoch 4 batch id 10001 loss 0.20118360221385956 train acc 0.9504955754424558\n",
      "epoch 4 batch id 10201 loss 0.08677928894758224 train acc 0.9505287471816488\n",
      "epoch 4 batch id 10401 loss 0.1927189826965332 train acc 0.9505305980194212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 12401 loss 0.0755591168999672 train acc 0.9505231432948956\n",
      "epoch 4 batch id 12601 loss 0.30917489528656006 train acc 0.9505495595587652\n",
      "epoch 4 batch id 12801 loss 0.2822939157485962 train acc 0.9505605030856964\n",
      "epoch 4 batch id 13001 loss 0.14268004894256592 train acc 0.9506312014460426\n",
      "epoch 4 batch id 13201 loss 0.0771171823143959 train acc 0.9507092265737445\n",
      "epoch 4 batch id 13401 loss 0.5010039210319519 train acc 0.9507499440340273\n",
      "epoch 4 batch id 13601 loss 0.40826714038848877 train acc 0.9507848687596501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 16201 loss 0.17366282641887665 train acc 0.9509366705758904\n",
      "epoch 4 batch id 16401 loss 0.13102759420871735 train acc 0.9509881257240412\n",
      "epoch 4 batch id 16601 loss 0.03997732326388359 train acc 0.95102704656346\n",
      "epoch 4 batch id 16801 loss 0.022381676360964775 train acc 0.9510278406047259\n",
      "epoch 4 batch id 17001 loss 0.3116569221019745 train acc 0.9510433209811188\n",
      "epoch 4 batch id 17201 loss 0.43769174814224243 train acc 0.951000305214813\n",
      "epoch 4 batch id 17401 loss 0.0829300582408905 train acc 0.9510265214642837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 19801 loss 0.02327548712491989 train acc 0.9513282157466795\n",
      "epoch 4 batch id 20001 loss 0.14396169781684875 train acc 0.9513102469876507\n",
      "epoch 4 batch id 20201 loss 0.06856479495763779 train acc 0.9513328548091678\n",
      "epoch 4 batch id 20401 loss 0.15637752413749695 train acc 0.9513963776285477\n",
      "epoch 4 batch id 20601 loss 0.07719969004392624 train acc 0.9514359133051794\n",
      "epoch 4 batch id 20801 loss 0.08621272444725037 train acc 0.9514356280948031\n",
      "epoch 4 batch id 21001 loss 0.18107454478740692 train acc 0.9514680848531022\n",
      "epoch 4 batch id 21201 loss 0.2336631566286087 train acc 0.9514512876751097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train acc 0.9516295467085438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4055fa294c4a98b034b66111ab204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1001 loss 0.12903693318367004 train acc 0.9520791708291708\n",
      "epoch 5 batch id 1201 loss 0.020033176988363266 train acc 0.9526436303080766\n",
      "epoch 5 batch id 1401 loss 0.08010727912187576 train acc 0.9529800142755175\n",
      "epoch 5 batch id 1601 loss 0.28645768761634827 train acc 0.953408026233604\n",
      "epoch 5 batch id 1801 loss 0.1449361890554428 train acc 0.9539838978345364\n",
      "epoch 5 batch id 2001 loss 0.22656212747097015 train acc 0.9542572463768116\n",
      "epoch 5 batch id 2201 loss 0.06285908073186874 train acc 0.9538987960018174\n",
      "epoch 5 batch id 2401 loss 0.06870408356189728 train acc 0.953990524781341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 4401 loss 0.020313037559390068 train acc 0.9544421722335833\n",
      "epoch 5 batch id 4601 loss 0.2161734253168106 train acc 0.9545750923712236\n",
      "epoch 5 batch id 4801 loss 0.06827736645936966 train acc 0.9545472297438033\n",
      "epoch 5 batch id 5001 loss 0.06870435178279877 train acc 0.9546090781843631\n",
      "epoch 5 batch id 5201 loss 0.1827896684408188 train acc 0.9545159584695251\n",
      "epoch 5 batch id 5401 loss 0.03722337633371353 train acc 0.9548116089613035\n",
      "epoch 5 batch id 5601 loss 0.2754688858985901 train acc 0.9546621139082306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 8001 loss 0.19949588179588318 train acc 0.9543338332708411\n",
      "epoch 5 batch id 8201 loss 0.12416625767946243 train acc 0.9543996159004999\n",
      "epoch 5 batch id 8401 loss 0.04310927167534828 train acc 0.9543320735626711\n",
      "epoch 5 batch id 8601 loss 0.07814836502075195 train acc 0.9543476049296593\n",
      "epoch 5 batch id 8801 loss 0.010730432346463203 train acc 0.9543482274741507\n",
      "epoch 5 batch id 9001 loss 0.21970294415950775 train acc 0.9543488223530718\n",
      "epoch 5 batch id 9201 loss 0.25325170159339905 train acc 0.9544376969894577\n",
      "epoch 5 batch id 9401 loss 0.0997912809252739 train acc 0.9544297149239442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 11801 loss 0.039614077657461166 train acc 0.9545721760867724\n",
      "epoch 5 batch id 12001 loss 0.0361827127635479 train acc 0.9544959795017082\n",
      "epoch 5 batch id 12201 loss 0.04513010010123253 train acc 0.9545529054995492\n",
      "epoch 5 batch id 12401 loss 0.09025018662214279 train acc 0.9546004354487542\n",
      "epoch 5 batch id 12601 loss 0.1327977180480957 train acc 0.9546414967066106\n",
      "epoch 5 batch id 12801 loss 0.22040139138698578 train acc 0.9546666276072182\n",
      "epoch 5 batch id 13001 loss 0.13071748614311218 train acc 0.9547126182601339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 15201 loss 0.15757040679454803 train acc 0.9549865140451286\n",
      "epoch 5 batch id 15401 loss 0.02415342442691326 train acc 0.9549765437309266\n",
      "epoch 5 batch id 15601 loss 0.13506273925304413 train acc 0.954978847509775\n",
      "epoch 5 batch id 15801 loss 0.030794866383075714 train acc 0.9550265805961649\n",
      "epoch 5 batch id 16001 loss 0.1990462988615036 train acc 0.9550672614211612\n",
      "epoch 5 batch id 16201 loss 0.05403732880949974 train acc 0.9550683599777792\n",
      "epoch 5 batch id 16401 loss 0.1415528655052185 train acc 0.9550922962014511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 18801 loss 0.21627788245677948 train acc 0.9552051752566353\n",
      "epoch 5 batch id 19001 loss 0.285936564207077 train acc 0.9552276853849797\n",
      "epoch 5 batch id 19201 loss 0.1019584983587265 train acc 0.955264374251341\n",
      "epoch 5 batch id 19401 loss 0.3171822726726532 train acc 0.9553599041286531\n",
      "epoch 5 batch id 19601 loss 0.23122118413448334 train acc 0.9553610147441457\n",
      "epoch 5 batch id 19801 loss 0.02075735665857792 train acc 0.9553447426897631\n",
      "epoch 5 batch id 20001 loss 0.0886542797088623 train acc 0.9553319209039548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 22401 loss 0.19471345841884613 train acc 0.9553856412660149\n",
      "epoch 5 batch id 22601 loss 0.14114578068256378 train acc 0.9554444493606478\n",
      "epoch 5 batch id 22801 loss 0.21647141873836517 train acc 0.9554720735932635\n",
      "epoch 5 batch id 23001 loss 0.0890384167432785 train acc 0.9554924242424242\n",
      "epoch 5 batch id 23201 loss 0.13988149166107178 train acc 0.955494914012327\n",
      "epoch 5 batch id 23401 loss 0.05011158064007759 train acc 0.9555173924191274\n",
      "epoch 5 train acc 0.955555526081236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692480d97da45fcbf48bbfa12f8d091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.9491222625413802\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84f3f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b4a938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "#모델의 형태를 포함하여 저장하기\n",
    "# torch.save(model, 'KoBERT_QA_v.0.0.2_sona.pth')\n",
    "# torch.save(model.state_dict(), \"./KoBERT_QA_v.0.0.2_sona.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf52910",
   "metadata": {},
   "source": [
    "## 3-5.새로운 문장 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee2e5ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불러오기\n",
    "# model_pt= BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "# model_pt.load_state_dict(torch.load('KoBERT_QA_v.0.0.2_sona.pt'))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model_pt = BERTClassifier(bertmodel,  dr_rate=0.5)\n",
    "model_pt.load_state_dict(torch.load('KoBERT_QA_v.0.0.2_sona.pt'))\n",
    "model_pt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6470ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_QA_baseline/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model_pt.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model_pt(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            # 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0\n",
    "\n",
    "            print(np.argmax(logits))\n",
    "#             if np.argmax(logits) == 0:\n",
    "#                 test_eval.append(\"대답\")\n",
    "#             elif np.argmax(logits) == 1:\n",
    "#                 test_eval.append(\"고객 질문\")\n",
    "#             elif np.argmax(logits) == 2:\n",
    "#                 test_eval.append(\"상담원 질문\")\n",
    "\n",
    "#         print(\">> 입력하신 내용은 \" + test_eval[0] + \" 라고 판단됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02a6d0e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 : 이렇게 말하면 몇이 나올까\n",
      "1\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 일단은 돌려돌려를 해볼까나\n",
      "1\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 몇시까지 하나요\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m :\n\u001b[0;32m----> 3\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m하고싶은 말을 입력해주세요 : \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentence \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py:1007\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m     )\n\u001b[0;32m-> 1007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py:1052\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == 0 :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
