{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff032c8",
   "metadata": {},
   "source": [
    "# 0. 들어가기 앞서\n",
    "\n",
    "* 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0\n",
    "* 'AS':0, '주문':1, '배송':2, '업무처리':3, '교환':4, '반품':5, '결제':6\n",
    "* 참고: https://velog.io/@seolini43/KOBERT%EB%A1%9C-%EB%8B%A4%EC%A4%91-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-%ED%8C%8C%EC%9D%B4%EC%8D%ACColab\n",
    "\n",
    "* 한국어언어모델 다양하게 사용해보기 : https://littlefoxdiary.tistory.com/81"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6590be",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fef1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gluonnlp\n",
    "# !pip install mxnet\n",
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c03f343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f00e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27195632",
   "metadata": {},
   "source": [
    "# 2. 모델, 사전, 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d08d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/.cache/kobert_v1.zip\n",
      "using cached model. /home/adminuser/notebooks/modeling/question/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4d31c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '5movies.csv',\n",
       " '통합_민원(콜센터)_질의응답_K쇼핑.csv',\n",
       " 'crawling',\n",
       " '한국어_단발성_대화_데이터셋.csv',\n",
       " 'naver_shopping_all_220427.csv',\n",
       " '한국어_단발성_대화_데이터셋.xlsx',\n",
       " 'test.csv',\n",
       " '크롤링데이터 합치기.ipynb',\n",
       " 'bad_words.txt',\n",
       " '일간베스트_댓글.txt',\n",
       " 'youtube_220504.csv',\n",
       " 'test.csv.lock']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0662872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../raw_data/통합_민원(콜센터)_질의응답_K쇼핑.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127f36c",
   "metadata": {},
   "source": [
    "**라벨링 처리된 csv였기에 라벨링 과정 skip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2727cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질분 다중분류\n",
    "df1= df[[\"대화내용\",\"분류\"]]\n",
    "df1.columns=[\"comment\",\"QA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2f3112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>QA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 ㅇㅇㅇ입니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네. 아쿠아 청소기를 샀었는데요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아. 그러십니까?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네. 얼마 전에도 전화 한 번 드렸던 적이 있어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아. 네.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        comment  QA\n",
       "0                    저는 ㅇㅇㅇ입니다.   0\n",
       "1            네. 아쿠아 청소기를 샀었는데요.   1\n",
       "2                     아. 그러십니까?   2\n",
       "3  네. 얼마 전에도 전화 한 번 드렸던 적이 있어요.   1\n",
       "4                         아. 네.   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476175a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 카테고리 다중분류\n",
    "df2= df[(df.분류==1)][[\"대화내용\",\"카테고리\"]]\n",
    "df2.columns=[\"comment\",\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7fc15b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네. 아쿠아 청소기를 샀었는데요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네. 얼마 전에도 전화 한 번 드렸던 적이 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>그런데 지금 너무 화가 나네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>아쿠아 청소기에서 걸레 꽂는 부분이요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>청소가 제대로 안되는 거 같아서 청소기 아래를 다 분해해 봤거든요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 comment  category\n",
       "1                     네. 아쿠아 청소기를 샀었는데요.         0\n",
       "3           네. 얼마 전에도 전화 한 번 드렸던 적이 있어요.         0\n",
       "5                      그런데 지금 너무 화가 나네요.         0\n",
       "7                  아쿠아 청소기에서 걸레 꽂는 부분이요.         0\n",
       "9  청소가 제대로 안되는 거 같아서 청소기 아래를 다 분해해 봤거든요.         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68210ad6",
   "metadata": {},
   "source": [
    "# 3. 질문분류(df1)부터 시작\n",
    "\n",
    "* 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7182b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2중 리스트로 변환됨\n",
    "\n",
    "data_list = []\n",
    "for q, label in zip(df1[\"comment\"],df1[\"QA\"])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ae42c",
   "metadata": {},
   "source": [
    "## 3-1. Train / Test set 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3766de",
   "metadata": {},
   "source": [
    "* 라벨링은 이미 진행했으므로, 바로 train/ test 분리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189c8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20346a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753924\n",
      "251309\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba4b04",
   "metadata": {},
   "source": [
    "## 3-2. KoBERT 입력 데이터로 만들기\n",
    "\n",
    "* 데이터를 train data와 test data로 나누었다면 각 데이터가 KoBERT 모델의 입력으로 들어갈 수 있는 형태가 되도록 토큰화, 정수 인코딩, 패딩 등을 해주어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "325540ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60101ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "\n",
    "max_len = 64 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d51a085",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "tokenizer= get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38a513a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 2847, 4103, 5130,  793, 5925,  517,   54, 2926, 6141, 6050,\n",
       "        2822, 5330, 7287,  517, 7707, 7494,  517, 7710, 7753, 6664,  517,\n",
       "        6539, 5931, 3647, 6314, 2650, 6749, 6964, 4227, 1767, 3861,  994,\n",
       "        5778, 2207, 7748, 4089, 6116, 4924, 6733,  889, 6079, 5130, 5906,\n",
       "         517,   54,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
       " array(47, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째는 패딩된 시퀀스\n",
    "# 두 번째는 길이와 타입에 대한 내용\n",
    "# 세 번재는 어텐션 마스크 시퀀스\n",
    "\n",
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a46aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch용 DataLoader 사용(torch 형식의 dataset을 만들어주기)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1b0fb",
   "metadata": {},
   "source": [
    "## 3-3. KoBERT 학습모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6cc27",
   "metadata": {},
   "source": [
    "* 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0 \n",
    "* 3가지의 class를 분류하기 때문에 num_classes는 3으로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba1174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=3,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6b75d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/version_test_azureml_py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee52fb4",
   "metadata": {},
   "source": [
    "## 3-4. KoBERT 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f3486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5623/2673822008.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e716c975d02e4aca85a49765ccb7af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.1340909004211426 train acc 0.359375\n",
      "epoch 1 batch id 201 loss 0.8274189829826355 train acc 0.486318407960199\n",
      "epoch 1 batch id 401 loss 0.41078007221221924 train acc 0.6704332917705735\n",
      "epoch 1 batch id 601 loss 0.15138986706733704 train acc 0.7529378119800333\n",
      "epoch 1 batch id 801 loss 0.2737046778202057 train acc 0.7971676029962547\n",
      "epoch 1 batch id 1001 loss 0.292715847492218 train acc 0.8248001998001998\n",
      "epoch 1 batch id 1201 loss 0.20305629074573517 train acc 0.8426571606994172\n",
      "epoch 1 batch id 1401 loss 0.14970576763153076 train acc 0.8558730371163454\n",
      "epoch 1 batch id 1601 loss 0.30628061294555664 train acc 0.8652795128044972\n",
      "epoch 1 batch id 1801 loss 0.14616483449935913 train acc 0.8732301499167129\n",
      "epoch 1 batch id 2001 loss 0.37702062726020813 train acc 0.8797476261869065\n",
      "epoch 1 batch id 2201 loss 0.06964673101902008 train acc 0.8853362108132667\n",
      "epoch 1 batch id 2401 loss 0.1443168818950653 train acc 0.8896683673469388\n",
      "epoch 1 batch id 2601 loss 0.1600094735622406 train acc 0.8932081410995771\n",
      "epoch 1 batch id 2801 loss 0.17328689992427826 train acc 0.8966998393430917\n",
      "epoch 1 batch id 3001 loss 0.19600637257099152 train acc 0.899481422859047\n",
      "epoch 1 batch id 3201 loss 0.11922196298837662 train acc 0.9020667369572009\n",
      "epoch 1 batch id 3401 loss 0.11969930678606033 train acc 0.9043296089385475\n",
      "epoch 1 batch id 3601 loss 0.13145236670970917 train acc 0.9061892529852819\n",
      "epoch 1 batch id 3801 loss 0.1194503903388977 train acc 0.9079395224940805\n",
      "epoch 1 batch id 4001 loss 0.15950775146484375 train acc 0.9095265246188453\n",
      "epoch 1 batch id 4201 loss 0.15490864217281342 train acc 0.9110293680076172\n",
      "epoch 1 batch id 4401 loss 0.08114530891180038 train acc 0.9124204726198591\n",
      "epoch 1 batch id 4601 loss 0.2433398813009262 train acc 0.9136261138882852\n",
      "epoch 1 batch id 4801 loss 0.1784815490245819 train acc 0.9148321964174131\n",
      "epoch 1 batch id 5001 loss 0.24059422314167023 train acc 0.9159355628874225\n",
      "epoch 1 batch id 5201 loss 0.11143475025892258 train acc 0.9169480628725245\n",
      "epoch 1 batch id 5401 loss 0.13165976107120514 train acc 0.9179145065728569\n",
      "epoch 1 batch id 5601 loss 0.22555281221866608 train acc 0.9186333913586859\n",
      "epoch 1 batch id 5801 loss 0.21671567857265472 train acc 0.9193053999310463\n",
      "epoch 1 batch id 6001 loss 0.11116243153810501 train acc 0.9199846900516581\n",
      "epoch 1 batch id 6201 loss 0.10824769735336304 train acc 0.9206957547169812\n",
      "epoch 1 batch id 6401 loss 0.1536175012588501 train acc 0.921355061709108\n",
      "epoch 1 batch id 6601 loss 0.07001280039548874 train acc 0.9220075556733828\n",
      "epoch 1 batch id 6801 loss 0.17590464651584625 train acc 0.9226124834583149\n",
      "epoch 1 batch id 7001 loss 0.19360853731632233 train acc 0.923205167118983\n",
      "epoch 1 batch id 7201 loss 0.23836494982242584 train acc 0.9236629461185947\n",
      "epoch 1 batch id 7401 loss 0.17478470504283905 train acc 0.9241867653019862\n",
      "epoch 1 batch id 7601 loss 0.07803986966609955 train acc 0.9247056308380476\n",
      "epoch 1 batch id 7801 loss 0.14469210803508759 train acc 0.9251398057941289\n",
      "epoch 1 batch id 8001 loss 0.17309845983982086 train acc 0.9256596831646045\n",
      "epoch 1 batch id 8201 loss 0.18525879085063934 train acc 0.9261275301792464\n",
      "epoch 1 batch id 8401 loss 0.0690264105796814 train acc 0.9265117247946673\n",
      "epoch 1 batch id 8601 loss 0.150295227766037 train acc 0.9268489855830717\n",
      "epoch 1 batch id 8801 loss 0.21224896609783173 train acc 0.9273040705601636\n",
      "epoch 1 batch id 9001 loss 0.10425498336553574 train acc 0.9277163648483502\n",
      "epoch 1 batch id 9201 loss 0.13530214130878448 train acc 0.9280377132920334\n",
      "epoch 1 batch id 9401 loss 0.11030358821153641 train acc 0.9284218434209127\n",
      "epoch 1 batch id 9601 loss 0.13453345000743866 train acc 0.9288241459222998\n",
      "epoch 1 batch id 10001 loss 0.0802370086312294 train acc 0.9294992375762424\n",
      "epoch 1 batch id 10201 loss 0.08354920893907547 train acc 0.9298353102636996\n",
      "epoch 1 batch id 10401 loss 0.09103894978761673 train acc 0.9301359244303432\n",
      "epoch 1 batch id 10601 loss 0.06364752352237701 train acc 0.9303544476936139\n",
      "epoch 1 batch id 10801 loss 0.12372813373804092 train acc 0.9306227432645126\n",
      "epoch 1 batch id 11001 loss 0.07098019868135452 train acc 0.9308770225434051\n",
      "epoch 1 batch id 11201 loss 0.33178946375846863 train acc 0.9310985068297474\n",
      "epoch 1 batch id 11401 loss 0.16524870693683624 train acc 0.9313574467152004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 11601 loss 0.17070648074150085 train acc 0.9315751336091717\n",
      "epoch 1 train acc 0.9318592967490026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5623/2673822008.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded228f073de4934b5e979e555030e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.9473210748946043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807208780df640638d73189b7bba1769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.09879152476787567 train acc 0.96875\n",
      "epoch 2 batch id 601 loss 0.05269382521510124 train acc 0.9432716306156406\n",
      "epoch 2 batch id 801 loss 0.1758647859096527 train acc 0.9437421972534332\n",
      "epoch 2 batch id 1001 loss 0.21402721107006073 train acc 0.9447895854145855\n",
      "epoch 2 batch id 1201 loss 0.14432626962661743 train acc 0.944291215653622\n",
      "epoch 2 batch id 1401 loss 0.08141428232192993 train acc 0.9447269807280514\n",
      "epoch 2 batch id 1601 loss 0.17691278457641602 train acc 0.9444390224859462\n",
      "epoch 2 batch id 1801 loss 0.14520104229450226 train acc 0.944596751804553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 5401 loss 0.11089872568845749 train acc 0.9462773097574523\n",
      "epoch 2 batch id 5601 loss 0.18080779910087585 train acc 0.9462038028923406\n",
      "epoch 2 batch id 5801 loss 0.21295979619026184 train acc 0.9461434450956732\n",
      "epoch 2 batch id 6001 loss 0.06724787503480911 train acc 0.9461574112647892\n",
      "epoch 2 batch id 6201 loss 0.14642691612243652 train acc 0.9462914247701983\n",
      "epoch 2 batch id 6401 loss 0.1124415397644043 train acc 0.9462925714732073\n",
      "epoch 2 batch id 6601 loss 0.059106580913066864 train acc 0.9464072678382063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 8201 loss 0.10173861682415009 train acc 0.9469329197658822\n",
      "epoch 2 batch id 8401 loss 0.06043674796819687 train acc 0.9469724586358766\n",
      "epoch 2 batch id 8601 loss 0.16371043026447296 train acc 0.9470065254040227\n",
      "epoch 2 batch id 8801 loss 0.201140895485878 train acc 0.9471011816838996\n",
      "epoch 2 batch id 9001 loss 0.09816337376832962 train acc 0.9471621208754583\n",
      "epoch 2 batch id 9201 loss 0.15074287354946136 train acc 0.9471677670905336\n",
      "epoch 2 batch id 9401 loss 0.1249326691031456 train acc 0.9472679103286884\n",
      "epoch 2 batch id 9601 loss 0.11082640290260315 train acc 0.9473606264972398\n",
      "epoch 2 batch id 9801 loss 0.15082241594791412 train acc 0.9474846316702378\n",
      "epoch 2 batch id 10001 loss 0.08238112181425095 train acc 0.9474911883811619\n",
      "epoch 2 batch id 10201 loss 0.09957218170166016 train acc 0.9476108347220861\n",
      "epoch 2 batch id 10401 loss 0.08832509070634842 train acc 0.9476778074223632\n",
      "epoch 2 batch id 10601 loss 0.06968457251787186 train acc 0.9476803485520234\n",
      "epoch 2 batch id 10801 loss 0.0952361673116684 train acc 0.9477102814554208\n",
      "epoch 2 batch id 11001 loss 0.07830275595188141 train acc 0.9477377056631215\n",
      "epoch 2 batch id 11201 loss 0.3036496043205261 train acc 0.9477627555575395\n",
      "epoch 2 batch id 11401 loss 0.13827301561832428 train acc 0.9478677857205509\n",
      "epoch 2 batch id 11601 loss 0.16118721663951874 train acc 0.947901851133523\n",
      "epoch 2 train acc 0.9479697181903064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b137539f5684276a57d2d83f22113c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.9483754739269445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1fccebed66458b871ddde1f203f18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.0965975821018219 train acc 0.96875\n",
      "epoch 3 batch id 201 loss 0.10601777583360672 train acc 0.949160447761194\n",
      "epoch 3 batch id 401 loss 0.08694331347942352 train acc 0.9486440149625935\n",
      "epoch 3 batch id 601 loss 0.0479179322719574 train acc 0.9485232945091514\n",
      "epoch 3 batch id 801 loss 0.17610467970371246 train acc 0.9492821473158551\n",
      "epoch 3 batch id 1001 loss 0.18764249980449677 train acc 0.9499562937062938\n",
      "epoch 3 batch id 1201 loss 0.1428525149822235 train acc 0.9495862822647794\n",
      "epoch 3 batch id 1401 loss 0.08443325757980347 train acc 0.9500356887937188\n",
      "epoch 3 batch id 1601 loss 0.1548403650522232 train acc 0.9499921923797626\n",
      "epoch 3 batch id 1801 loss 0.15062370896339417 train acc 0.9502967101610217\n",
      "epoch 3 batch id 2001 loss 0.22977964580059052 train acc 0.9502123938030984\n",
      "epoch 3 batch id 2201 loss 0.055925920605659485 train acc 0.9504202635165834\n",
      "epoch 3 batch id 2401 loss 0.15633553266525269 train acc 0.9505674718867139\n",
      "epoch 3 batch id 2601 loss 0.13540926575660706 train acc 0.9505899173394848\n",
      "epoch 3 batch id 2801 loss 0.13877367973327637 train acc 0.950826713673688\n",
      "epoch 3 batch id 3001 loss 0.09659594297409058 train acc 0.9508757497500833\n",
      "epoch 3 batch id 3201 loss 0.09148593991994858 train acc 0.9509381833801936\n",
      "epoch 3 batch id 3401 loss 0.08806444704532623 train acc 0.9510300279329609\n",
      "epoch 3 batch id 3601 loss 0.11094345897436142 train acc 0.9510639405720633\n",
      "epoch 3 batch id 3801 loss 0.08081625401973724 train acc 0.9510819521178637\n",
      "epoch 3 batch id 4001 loss 0.12312488257884979 train acc 0.9509731942014497\n",
      "epoch 3 batch id 4201 loss 0.13537660241127014 train acc 0.9510867948107593\n",
      "epoch 3 batch id 4601 loss 0.18070466816425323 train acc 0.9512266355140186\n",
      "epoch 3 batch id 4801 loss 0.09075415134429932 train acc 0.951325244740679\n",
      "epoch 3 batch id 5001 loss 0.21603138744831085 train acc 0.9515284443111378\n",
      "epoch 3 batch id 5201 loss 0.08855187892913818 train acc 0.9516589357815805\n",
      "epoch 3 batch id 5401 loss 0.08150263130664825 train acc 0.9517624051101647\n",
      "epoch 3 batch id 5601 loss 0.17269840836524963 train acc 0.95178037404035\n",
      "epoch 3 batch id 5801 loss 0.195565328001976 train acc 0.9517001379072574\n",
      "epoch 3 batch id 6001 loss 0.06586875021457672 train acc 0.9517241918013665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 7201 loss 0.17792055010795593 train acc 0.9521963095403416\n",
      "epoch 3 batch id 7401 loss 0.126146137714386 train acc 0.9523438555600594\n",
      "epoch 3 batch id 7601 loss 0.10990075767040253 train acc 0.9524055222996974\n",
      "epoch 3 batch id 7801 loss 0.16812662780284882 train acc 0.9524439975644148\n",
      "epoch 3 batch id 8001 loss 0.15038210153579712 train acc 0.9525039838770154\n",
      "epoch 3 batch id 8201 loss 0.0708112046122551 train acc 0.9526067705157908\n",
      "epoch 3 batch id 8401 loss 0.03416600450873375 train acc 0.9526842042613974\n",
      "epoch 3 batch id 8601 loss 0.16428349912166595 train acc 0.9527235205208696\n",
      "epoch 3 batch id 8801 loss 0.14700011909008026 train acc 0.9527947818429724\n",
      "epoch 3 batch id 9001 loss 0.15346020460128784 train acc 0.9528576685923786\n",
      "epoch 3 batch id 9201 loss 0.13523462414741516 train acc 0.9528940468427345\n",
      "epoch 3 batch id 9401 loss 0.11257615685462952 train acc 0.9529704286778002\n",
      "epoch 3 batch id 9601 loss 0.11329488456249237 train acc 0.9530712946568066\n",
      "epoch 3 batch id 9801 loss 0.1260215938091278 train acc 0.9531983343536374\n",
      "epoch 3 batch id 10001 loss 0.10460518300533295 train acc 0.9532421757824218\n",
      "epoch 3 batch id 10201 loss 0.07431897521018982 train acc 0.953356288599157\n",
      "epoch 3 batch id 10401 loss 0.06482085585594177 train acc 0.9534104292856456\n",
      "epoch 3 batch id 10601 loss 0.07502378523349762 train acc 0.9534301009338741\n",
      "epoch 3 batch id 10801 loss 0.0808982327580452 train acc 0.953475083325618\n",
      "epoch 3 batch id 11001 loss 0.07582785934209824 train acc 0.9535255317698391\n",
      "epoch 3 batch id 11201 loss 0.2640853524208069 train acc 0.9535393045263816\n",
      "epoch 3 batch id 11401 loss 0.10576006025075912 train acc 0.9536636040698184\n",
      "epoch 3 batch id 11601 loss 0.10104246437549591 train acc 0.9536906839927592\n",
      "epoch 3 train acc 0.953776207452678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bb8515d1e14e0a86e39b47870bf9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.9490677963104434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb14cf3b4c3741e491482334f7a2d8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.07779673486948013 train acc 0.96875\n",
      "epoch 4 batch id 201 loss 0.07237216085195541 train acc 0.9565453980099502\n",
      "epoch 4 batch id 401 loss 0.09005780518054962 train acc 0.9552291147132169\n",
      "epoch 4 batch id 601 loss 0.042296119034290314 train acc 0.955464850249584\n",
      "epoch 4 batch id 801 loss 0.14479804039001465 train acc 0.9564021535580525\n",
      "epoch 4 batch id 1001 loss 0.17304658889770508 train acc 0.9567932067932068\n",
      "epoch 4 batch id 1201 loss 0.12064414471387863 train acc 0.9565336178184846\n",
      "epoch 4 batch id 1401 loss 0.0747576504945755 train acc 0.9570061563169164\n",
      "epoch 4 batch id 1601 loss 0.1328076869249344 train acc 0.956521314803248\n",
      "epoch 4 batch id 1801 loss 0.13245196640491486 train acc 0.9566039700166574\n",
      "epoch 4 batch id 2001 loss 0.2002410888671875 train acc 0.9567247626186907\n",
      "epoch 4 batch id 2201 loss 0.06313017755746841 train acc 0.9569016924125398\n",
      "epoch 4 batch id 2401 loss 0.09970775246620178 train acc 0.9568734381507705\n",
      "epoch 4 batch id 2601 loss 0.0914054811000824 train acc 0.9569816897347174\n",
      "epoch 4 batch id 2801 loss 0.16503022611141205 train acc 0.9573255087468762\n",
      "epoch 4 batch id 3001 loss 0.05392330139875412 train acc 0.957378790403199\n",
      "epoch 4 batch id 3201 loss 0.10537494719028473 train acc 0.9574498203686348\n",
      "epoch 4 batch id 3401 loss 0.09129307419061661 train acc 0.9574160173478389\n",
      "epoch 4 batch id 3601 loss 0.07199059426784515 train acc 0.9575551930019439\n",
      "epoch 4 batch id 3801 loss 0.07165408879518509 train acc 0.9576386148382005\n",
      "epoch 4 batch id 4001 loss 0.09128888696432114 train acc 0.9576707385653587\n",
      "epoch 4 batch id 4201 loss 0.1012953370809555 train acc 0.957759313258748\n",
      "epoch 4 batch id 4401 loss 0.031319789588451385 train acc 0.9578540388548057\n",
      "epoch 4 batch id 4601 loss 0.19632156193256378 train acc 0.9579846772440773\n",
      "epoch 4 batch id 4801 loss 0.08439882099628448 train acc 0.9580556134138721\n",
      "epoch 4 batch id 5001 loss 0.1814756840467453 train acc 0.9582271045790842\n",
      "epoch 4 batch id 5201 loss 0.07002750039100647 train acc 0.9583253220534512\n",
      "epoch 4 batch id 5401 loss 0.08664803951978683 train acc 0.9584683391964451\n",
      "epoch 4 batch id 5601 loss 0.151265487074852 train acc 0.9584811863952866\n",
      "epoch 4 batch id 5801 loss 0.2121102511882782 train acc 0.9584715997241855\n",
      "epoch 4 batch id 6001 loss 0.06045965105295181 train acc 0.9585095192467922\n",
      "epoch 4 batch id 6201 loss 0.13751894235610962 train acc 0.9586054668601839\n",
      "epoch 4 batch id 6401 loss 0.09785762429237366 train acc 0.9586441571629433\n",
      "epoch 4 batch id 6601 loss 0.043134257197380066 train acc 0.9588154256930768\n",
      "epoch 4 batch id 6801 loss 0.10827072709798813 train acc 0.9589375643287752\n",
      "epoch 4 batch id 7001 loss 0.14616112411022186 train acc 0.9590348700185688\n",
      "epoch 4 batch id 7201 loss 0.1494731307029724 train acc 0.9590877135120123\n",
      "epoch 4 batch id 7401 loss 0.1439339518547058 train acc 0.9592115930279692\n",
      "epoch 4 batch id 7601 loss 0.08982968330383301 train acc 0.95931045257203\n",
      "epoch 4 batch id 7801 loss 0.1516655683517456 train acc 0.9593341398538648\n",
      "epoch 4 batch id 8001 loss 0.12724603712558746 train acc 0.9594464754405699\n",
      "epoch 4 batch id 8201 loss 0.0461563803255558 train acc 0.9595457108889159\n",
      "epoch 4 batch id 8401 loss 0.027628790587186813 train acc 0.9596532406856326\n",
      "epoch 4 batch id 8601 loss 0.1167246550321579 train acc 0.9596903703057784\n",
      "epoch 4 batch id 8801 loss 0.16046778857707977 train acc 0.9597666458357005\n",
      "epoch 4 batch id 9001 loss 0.06525532901287079 train acc 0.959856890901011\n",
      "epoch 4 batch id 9201 loss 0.0657845064997673 train acc 0.9598735871100967\n",
      "epoch 4 batch id 9401 loss 0.0886131227016449 train acc 0.9599410966918412\n",
      "epoch 4 batch id 9601 loss 0.08533702045679092 train acc 0.9600139308405374\n",
      "epoch 4 batch id 9801 loss 0.1513654738664627 train acc 0.9601300249974493\n",
      "epoch 4 batch id 10001 loss 0.04689181223511696 train acc 0.9601836691330867\n",
      "epoch 4 batch id 10201 loss 0.06021875888109207 train acc 0.9602888197235565\n",
      "epoch 4 batch id 10401 loss 0.11163032799959183 train acc 0.9603718993366023\n",
      "epoch 4 batch id 10601 loss 0.0502498559653759 train acc 0.9603987831336667\n",
      "epoch 4 batch id 10801 loss 0.06982771307229996 train acc 0.9604290112026664\n",
      "epoch 4 batch id 11001 loss 0.06002558022737503 train acc 0.9604709230979002\n",
      "epoch 4 batch id 11201 loss 0.3044205605983734 train acc 0.9604904138023391\n",
      "epoch 4 batch id 11401 loss 0.0998503640294075 train acc 0.9606161192000702\n",
      "epoch 4 batch id 11601 loss 0.09647788852453232 train acc 0.9606566783035945\n",
      "epoch 4 train acc 0.9607577879636703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681b41be7bd64a52bf108c36a1992a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.9498357171151288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7415e44ea8934acfa8133023ffe3a3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.07168957591056824 train acc 0.96875\n",
      "epoch 5 batch id 201 loss 0.039368774741888046 train acc 0.9624533582089553\n",
      "epoch 5 batch id 401 loss 0.05005868151783943 train acc 0.9613466334164589\n",
      "epoch 5 batch id 601 loss 0.03857196867465973 train acc 0.9610024958402662\n",
      "epoch 5 batch id 801 loss 0.11838959902524948 train acc 0.9626638576779026\n",
      "epoch 5 batch id 1001 loss 0.2145552635192871 train acc 0.9631306193806194\n",
      "epoch 5 batch id 1201 loss 0.053156740963459015 train acc 0.9632467735220649\n",
      "epoch 5 batch id 1401 loss 0.06967693567276001 train acc 0.9636866523911491\n",
      "epoch 5 batch id 1601 loss 0.12547457218170166 train acc 0.9633041848844472\n",
      "epoch 5 batch id 1801 loss 0.12356951087713242 train acc 0.9636660188784009\n",
      "epoch 5 batch id 2001 loss 0.190815269947052 train acc 0.9637837331334332\n",
      "epoch 5 batch id 2201 loss 0.05238257348537445 train acc 0.963865856428896\n",
      "epoch 5 batch id 2401 loss 0.09244471788406372 train acc 0.9636870054144107\n",
      "epoch 5 batch id 2601 loss 0.06747318804264069 train acc 0.9637278931180315\n",
      "epoch 5 batch id 2801 loss 0.12591533362865448 train acc 0.9639581845769368\n",
      "epoch 5 batch id 3001 loss 0.06404615938663483 train acc 0.9639547234255248\n",
      "epoch 5 batch id 3201 loss 0.07564488053321838 train acc 0.9640395579506404\n",
      "epoch 5 batch id 3401 loss 0.06310376524925232 train acc 0.9640225301381946\n",
      "epoch 5 batch id 3601 loss 0.05129295587539673 train acc 0.9641809566787004\n",
      "epoch 5 batch id 3801 loss 0.031572964042425156 train acc 0.9642199421204946\n",
      "epoch 5 batch id 4001 loss 0.08755357563495636 train acc 0.9642081667083229\n",
      "epoch 5 batch id 4201 loss 0.12851348519325256 train acc 0.9643090930730779\n",
      "epoch 5 batch id 4401 loss 0.034489698708057404 train acc 0.9643475914564872\n",
      "epoch 5 batch id 4601 loss 0.2393588423728943 train acc 0.9644472668985004\n",
      "epoch 5 batch id 4801 loss 0.08847314864397049 train acc 0.9644605290564465\n",
      "epoch 5 batch id 5001 loss 0.1979180872440338 train acc 0.9645477154569086\n",
      "epoch 5 batch id 5201 loss 0.02864052541553974 train acc 0.9646762641799654\n",
      "epoch 5 batch id 5401 loss 0.08189231157302856 train acc 0.9648010785039808\n",
      "epoch 5 batch id 5601 loss 0.1662791669368744 train acc 0.9647802847705766\n",
      "epoch 5 batch id 5801 loss 0.19222399592399597 train acc 0.9647474573349423\n",
      "epoch 5 batch id 6001 loss 0.03843417391180992 train acc 0.9647558740209965\n",
      "epoch 5 batch id 6201 loss 0.13123324513435364 train acc 0.9648872157716497\n",
      "epoch 5 batch id 6401 loss 0.061397675424814224 train acc 0.9649444422746446\n",
      "epoch 5 batch id 6601 loss 0.031033605337142944 train acc 0.9651236555067414\n",
      "epoch 5 batch id 6801 loss 0.10783298313617706 train acc 0.9652302970151448\n",
      "epoch 5 batch id 7001 loss 0.19417224824428558 train acc 0.9653152228253107\n",
      "epoch 5 batch id 7201 loss 0.11667725443840027 train acc 0.9653064678516873\n",
      "epoch 5 batch id 7401 loss 0.14212994277477264 train acc 0.9654438589379813\n",
      "epoch 5 batch id 7601 loss 0.08304022997617722 train acc 0.9655123503486384\n",
      "epoch 5 batch id 7801 loss 0.1680544763803482 train acc 0.965581335726189\n",
      "epoch 5 batch id 8001 loss 0.14500325918197632 train acc 0.9657035058117736\n",
      "epoch 5 batch id 8201 loss 0.06056597828865051 train acc 0.9657739909767101\n",
      "epoch 5 batch id 8401 loss 0.020274769514799118 train acc 0.9658913373407928\n",
      "epoch 5 batch id 8601 loss 0.13220781087875366 train acc 0.9658851441692826\n",
      "epoch 5 batch id 8801 loss 0.14331208169460297 train acc 0.9659218412680377\n",
      "epoch 5 batch id 9001 loss 0.11769411712884903 train acc 0.96600204143984\n",
      "epoch 5 batch id 9201 loss 0.035100266337394714 train acc 0.9660057330724922\n",
      "epoch 5 batch id 9401 loss 0.058283597230911255 train acc 0.9660341984895224\n",
      "epoch 5 batch id 9601 loss 0.08177916705608368 train acc 0.9660826346213937\n",
      "epoch 5 batch id 9801 loss 0.07401292026042938 train acc 0.9661992398734823\n",
      "epoch 5 batch id 10001 loss 0.03137429803609848 train acc 0.9662033796620338\n",
      "epoch 5 batch id 10201 loss 0.04649179428815842 train acc 0.9662471816488579\n",
      "epoch 5 batch id 10401 loss 0.05912036448717117 train acc 0.9662697697336795\n",
      "epoch 5 batch id 10601 loss 0.029805069789290428 train acc 0.9662752924252429\n",
      "epoch 5 batch id 10801 loss 0.0708078071475029 train acc 0.9662661443384872\n",
      "epoch 5 batch id 11001 loss 0.06504915654659271 train acc 0.966289996363967\n",
      "epoch 5 batch id 11201 loss 0.3128035366535187 train acc 0.966338105972681\n",
      "epoch 5 batch id 11401 loss 0.08694305270910263 train acc 0.9664297539689501\n",
      "epoch 5 batch id 11601 loss 0.07450178265571594 train acc 0.9664603266959745\n",
      "epoch 5 train acc 0.9665311200237671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfefe64f28d244ef87318118d33cb94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.9497243089154853\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf52910",
   "metadata": {},
   "source": [
    "## 3-5.새로운 문장 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6470ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            # 고객 질문: 1, 상담원 질문: 2, 고객 및 상담원 대답: 0\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"대답\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"고객 질문\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"상담원 질문\")\n",
    "\n",
    "        print(\">> 입력하신 내용은 \" + test_eval[0] + \" 라고 판단됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02a6d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 : 66사이즈 있나요?\n",
      ">> 입력하신 내용은 고객 질문 라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 핑크색입니다\n",
      ">> 입력하신 내용은 대답 라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 물어보고싶어요\n",
      ">> 입력하신 내용은 고객 질문 라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 고객님 지금 없습니다\n",
      ">> 입력하신 내용은 대답 라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 다시한번 알려주세요\n",
      ">> 입력하신 내용은 고객 질문 라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 리모컨을 놓을 수가 없네요\n",
      ">> 입력하신 내용은 고객 질문 라고 판단됩니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m :\n\u001b[0;32m----> 3\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m하고싶은 말을 입력해주세요 : \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentence \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/version_test_azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py:1007\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m     )\n\u001b[0;32m-> 1007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/version_test_azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py:1052\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == 0 :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dee8b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "#모델의 형태를 포함하여 저장하\n",
    "torch.save(model, 'KoBERT_v.0.0.1_sona.pth')\n",
    "\n",
    "#불러오기\n",
    "# model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "version_test_azureml_py38",
   "language": "python",
   "name": "conda-env-version_test_azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
