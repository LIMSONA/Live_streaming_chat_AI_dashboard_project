{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3dae558",
   "metadata": {},
   "source": [
    "## 일베 댓글+ 캐글 데이터로 fast-text 임베딩 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f537832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.python.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1523bc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다 10년 더 입어야지</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190576</th>\n",
       "      <td>드라마도 완전 재밌고 배우들도 멋있어서</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190577</th>\n",
       "      <td>원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190578</th>\n",
       "      <td>케석대 어깨 올라간거봐라</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190579</th>\n",
       "      <td>로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190580</th>\n",
       "      <td>개지랄병 병신좌좀새끼</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       댓글  비속어여부\n",
       "0                                                  좌배 까는건      1\n",
       "1                                집에 롱 패딩만 세 개다 10년 더 입어야지      0\n",
       "2               개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                             세탁이라고 봐도 된다      0\n",
       "4                                            애새끼가 초딩도 아니고      1\n",
       "...                                                   ...    ...\n",
       "190576                              드라마도 완전 재밌고 배우들도 멋있어서      0\n",
       "190577  원작을 읽을 때 이런 건 절대 영상화하기 힘들다고 생각했는데 벤휘쇼의 연기와 더불어...      0\n",
       "190578                                      케석대 어깨 올라간거봐라      1\n",
       "190579           로버트다우니주니어를 좋아해서 봤는데너무재밌게 봤던영화생각없이 볼때 딱좋음      0\n",
       "190580                                        개지랄병 병신좌좀새끼      1\n",
       "\n",
       "[190581 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/비속어댓글총합_특수문자,null값제거o.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1dc1d",
   "metadata": {},
   "source": [
    "# 자모 분류, fast text 는 git 참고 \n",
    "https://github.com/smothly/bad-word-detection/blob/master/FastTextVocab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76299312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHOSUNGS = [u'ㄱ',u'ㄲ',u'ㄴ',u'ㄷ',u'ㄸ',u'ㄹ',u'ㅁ',u'ㅂ',u'ㅃ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅉ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "JOONGSUNGS = [u'ㅏ',u'ㅐ',u'ㅑ',u'ㅒ',u'ㅓ',u'ㅔ',u'ㅕ',u'ㅖ',u'ㅗ',u'ㅘ',u'ㅙ',u'ㅚ',u'ㅛ',u'ㅜ',u'ㅝ',u'ㅞ',u'ㅟ',u'ㅠ',u'ㅡ',u'ㅢ',u'ㅣ']\n",
    "JONGSUNGS = [u'_',u'ㄱ',u'ㄲ',u'ㄳ',u'ㄴ',u'ㄵ',u'ㄶ',u'ㄷ',u'ㄹ',u'ㄺ',u'ㄻ',u'ㄼ',u'ㄽ',u'ㄾ',u'ㄿ',u'ㅀ',u'ㅁ',u'ㅂ',u'ㅄ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "TOTAL = CHOSUNGS + JOONGSUNGS + JONGSUNGS\n",
    "\n",
    "# 자모분리\n",
    "def jamo_split(word, end_char=\"_\"):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for char in word:\n",
    "        \n",
    "        character_code = ord(char)\n",
    "        \n",
    "        if 0xD7A3 < character_code or character_code < 0xAC00:\n",
    "            result.append(char)\n",
    "            continue\n",
    "\n",
    "        chosung_index = int((((character_code - 0xAC00) / 28) / 21) % 19)\n",
    "        joongsung_index = int(((character_code - 0xAC00) / 28) % 21)\n",
    "        jongsung_index = int((character_code - 0xAC00) % 28)\n",
    "        \n",
    "        chosung = CHOSUNGS[chosung_index]\n",
    "        joongsung = JOONGSUNGS[joongsung_index]\n",
    "        jongsung = JONGSUNGS[jongsung_index]\n",
    "        \n",
    "        # 종성 범위 밖에 있는 것들은 end_char로 메꿔준다.\n",
    "        if jongsung_index == 0:\n",
    "            jongsung = end_char\n",
    "        \n",
    "        result.append(chosung)\n",
    "        result.append(joongsung)\n",
    "        result.append(jongsung)\n",
    "\n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006f8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장을 jamo_split하여 저장\n",
    "#from JamoSplit import jamo_split, jamo_combine\n",
    "df.loc[:,'댓글'] = df.loc[:,'댓글'].apply(lambda x: jamo_split(x))\n",
    "df.loc[:,'댓글'] = df.loc[:,'댓글'].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cb71f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ㅈㅘ_ㅂㅐ_, ㄲㅏ_ㄴㅡㄴㄱㅓㄴ]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ㅈㅣㅂㅇㅔ_, ㄹㅗㅇ, ㅍㅐ_ㄷㅣㅇㅁㅏㄴ, ㅅㅔ_, ㄱㅐ_ㄷㅏ_, 10ㄴㅕㄴ, ㄷ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ㄱㅐ_ㅅㅗ_ㄹㅣ_ㅇㅑ_, ㄴㅣ_ㄱㅏ_, ㅃㅏㄹㄱㅐㅇㅇㅣ_ㄹㅡㄹ, ㅇㅗㅇㅎㅗ_ㅎㅏ_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ㅅㅔ_ㅌㅏㄱㅇㅣ_ㄹㅏ_ㄱㅗ_, ㅂㅘ_ㄷㅗ_, ㄷㅚㄴㄷㅏ_]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ㅇㅐ_ㅅㅐ_ㄲㅣ_ㄱㅏ_, ㅊㅗ_ㄷㅣㅇㄷㅗ_, ㅇㅏ_ㄴㅣ_ㄱㅗ_]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[731ㅂㅜ_ㄷㅐ_ㅇㅢ_, ㅎㅜ_ㅇㅖ_ㄹㅏ_, ㄱㅡ_ㄹㅓㄴㅈㅣ_, ㄱㅏ_ㅎㅏㄱㅈㅓㄱ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ㅈㅐ_ㅇㅏㅇㅇㅣ_ㅎㅏㄴㄱㅓㄴㅎㅐㅅㄴㅗ_]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ㄱㅡㄹㅆㅡㄴㅇㅣ_, ㅇㅘ_ㄲㅜ_, ㅅㅡㅇㄹㅣ_ㅇㅔ_, ㅂㅣ_ㅎㅏ_ㅁㅕㄴ, ㅂㅏㅇㅅ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ㅁㅏ_, ㅆㅣ_ㅂㅏㄹㄹㅕㄴ, ㅇㅏ_, ㅁㅕㅊㅍㅕㅇㅇㅣ_ㄱㅗ_, ㅁㅐㅅㄱㅐ_ㄷㅡ_ㄱ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ㅇㅡㄴㅎㅐㅇㅇㅔ_, ㄷㅐ_ㅊㅜㄹ, ㅅㅏㅇㄷㅏㅁ, ㅂㅏㄷㅇㅡ_ㄹㅓ_, ㄱㅏ_ㅂㅗ_ㅁ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ㅇㅜ_ㄹㅣ_ㅈㅣ_ㅇㅕㄱㄱㅜㄴㄷㅔ_, ㄱㅡㅁㅌㅐ_ㅅㅓㅂ, ㅃㅗㅂㅇㅡ_ㅁㅕㄴ, ㅇㅏㄴ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[ㄲㅗㅊㄷㅏ_ㅂㅏㄹㅅㅏ_ㄷㅡㄹㄱㅗ_, ㅇㅏㄹㅂㅏ_ㅎㅏ_ㄴㅡㄴㄱㅗㅅㅊㅏㅈㅇㅏ_ㄱㅏ_ㅅ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[ㅂㅏㄱㄱㅡㄴㅎㅖ_, ㅇㅏㄴㅃㅏ_ㄴㅡㄴㄷㅔ_, ㅂㅗ_ㅅㅜ_ㅌㅗㅇㅎㅏㅂ, 3ㅇㅝㄴㅊㅣ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ㄷㅐ_ㄱㅏ_ㄹㅣ_ㅇㅔ_, ㅍㅣㄹㅌㅓ_ㅇㅓㅄㄴㅡㄴ, ㅇㅕㄴㅂㅗㅇ, 30ㅇㅓㄱ, ㄱㅏ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ㅂㅐㄱㅈㅓㅇㅈㅜ_ㅈㅔ_ㅇㅔ_, ㄹㅏ_ㄱㅗ_ㅎㅏ_ㄴㅡㄴㄱㅓㄹ, ㅂㅣ_ㅎㅏ_ㄹㅏ_ㄱㅗ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   댓글  비속어여부\n",
       "0                                 [ㅈㅘ_ㅂㅐ_, ㄲㅏ_ㄴㅡㄴㄱㅓㄴ]      1\n",
       "1   [ㅈㅣㅂㅇㅔ_, ㄹㅗㅇ, ㅍㅐ_ㄷㅣㅇㅁㅏㄴ, ㅅㅔ_, ㄱㅐ_ㄷㅏ_, 10ㄴㅕㄴ, ㄷ...      0\n",
       "2   [ㄱㅐ_ㅅㅗ_ㄹㅣ_ㅇㅑ_, ㄴㅣ_ㄱㅏ_, ㅃㅏㄹㄱㅐㅇㅇㅣ_ㄹㅡㄹ, ㅇㅗㅇㅎㅗ_ㅎㅏ_...      1\n",
       "3                   [ㅅㅔ_ㅌㅏㄱㅇㅣ_ㄹㅏ_ㄱㅗ_, ㅂㅘ_ㄷㅗ_, ㄷㅚㄴㄷㅏ_]      0\n",
       "4                [ㅇㅐ_ㅅㅐ_ㄲㅣ_ㄱㅏ_, ㅊㅗ_ㄷㅣㅇㄷㅗ_, ㅇㅏ_ㄴㅣ_ㄱㅗ_]      1\n",
       "5   [731ㅂㅜ_ㄷㅐ_ㅇㅢ_, ㅎㅜ_ㅇㅖ_ㄹㅏ_, ㄱㅡ_ㄹㅓㄴㅈㅣ_, ㄱㅏ_ㅎㅏㄱㅈㅓㄱ...      1\n",
       "6                             [ㅈㅐ_ㅇㅏㅇㅇㅣ_ㅎㅏㄴㄱㅓㄴㅎㅐㅅㄴㅗ_]      1\n",
       "7   [ㄱㅡㄹㅆㅡㄴㅇㅣ_, ㅇㅘ_ㄲㅜ_, ㅅㅡㅇㄹㅣ_ㅇㅔ_, ㅂㅣ_ㅎㅏ_ㅁㅕㄴ, ㅂㅏㅇㅅ...      1\n",
       "8   [ㅁㅏ_, ㅆㅣ_ㅂㅏㄹㄹㅕㄴ, ㅇㅏ_, ㅁㅕㅊㅍㅕㅇㅇㅣ_ㄱㅗ_, ㅁㅐㅅㄱㅐ_ㄷㅡ_ㄱ...      1\n",
       "9   [ㅇㅡㄴㅎㅐㅇㅇㅔ_, ㄷㅐ_ㅊㅜㄹ, ㅅㅏㅇㄷㅏㅁ, ㅂㅏㄷㅇㅡ_ㄹㅓ_, ㄱㅏ_ㅂㅗ_ㅁ...      0\n",
       "10  [ㅇㅜ_ㄹㅣ_ㅈㅣ_ㅇㅕㄱㄱㅜㄴㄷㅔ_, ㄱㅡㅁㅌㅐ_ㅅㅓㅂ, ㅃㅗㅂㅇㅡ_ㅁㅕㄴ, ㅇㅏㄴ...      0\n",
       "11  [ㄲㅗㅊㄷㅏ_ㅂㅏㄹㅅㅏ_ㄷㅡㄹㄱㅗ_, ㅇㅏㄹㅂㅏ_ㅎㅏ_ㄴㅡㄴㄱㅗㅅㅊㅏㅈㅇㅏ_ㄱㅏ_ㅅ...      1\n",
       "12  [ㅂㅏㄱㄱㅡㄴㅎㅖ_, ㅇㅏㄴㅃㅏ_ㄴㅡㄴㄷㅔ_, ㅂㅗ_ㅅㅜ_ㅌㅗㅇㅎㅏㅂ, 3ㅇㅝㄴㅊㅣ...      1\n",
       "13  [ㄷㅐ_ㄱㅏ_ㄹㅣ_ㅇㅔ_, ㅍㅣㄹㅌㅓ_ㅇㅓㅄㄴㅡㄴ, ㅇㅕㄴㅂㅗㅇ, 30ㅇㅓㄱ, ㄱㅏ...      1\n",
       "14  [ㅂㅐㄱㅈㅓㅇㅈㅜ_ㅈㅔ_ㅇㅔ_, ㄹㅏ_ㄱㅗ_ㅎㅏ_ㄴㅡㄴㄱㅓㄹ, ㅂㅣ_ㅎㅏ_ㄹㅏ_ㄱㅗ...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c741143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190581"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe -> list로 변환\n",
    "sentence_list = list(df['댓글'])\n",
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1531a05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ㅈㅘ_ㅂㅐ_', 'ㄲㅏ_ㄴㅡㄴㄱㅓㄴ'],\n",
       " ['ㅈㅣㅂㅇㅔ_',\n",
       "  'ㄹㅗㅇ',\n",
       "  'ㅍㅐ_ㄷㅣㅇㅁㅏㄴ',\n",
       "  'ㅅㅔ_',\n",
       "  'ㄱㅐ_ㄷㅏ_',\n",
       "  '10ㄴㅕㄴ',\n",
       "  'ㄷㅓ_',\n",
       "  'ㅇㅣㅂㅇㅓ_ㅇㅑ_ㅈㅣ_'],\n",
       " ['ㄱㅐ_ㅅㅗ_ㄹㅣ_ㅇㅑ_',\n",
       "  'ㄴㅣ_ㄱㅏ_',\n",
       "  'ㅃㅏㄹㄱㅐㅇㅇㅣ_ㄹㅡㄹ',\n",
       "  'ㅇㅗㅇㅎㅗ_ㅎㅏ_ㄱㅗ_',\n",
       "  'ㄷㅡ_ㄹㅜ_ㅋㅣㅇㅇㅡㄹ',\n",
       "  'ㅈㅣㅅㅇㅣ_ㄹㅏ_ㄱㅗ_',\n",
       "  'ㅁㅏㄹㅁㅗㅅㅎㅐ_ㅅㅓ_',\n",
       "  'ㅃㅣ_ㅈㅣㄴㄱㅓ_ㅇㅑ_',\n",
       "  'ㅃㅏㄹㄱㅐㅇㅇㅏ_'],\n",
       " ['ㅅㅔ_ㅌㅏㄱㅇㅣ_ㄹㅏ_ㄱㅗ_', 'ㅂㅘ_ㄷㅗ_', 'ㄷㅚㄴㄷㅏ_'],\n",
       " ['ㅇㅐ_ㅅㅐ_ㄲㅣ_ㄱㅏ_', 'ㅊㅗ_ㄷㅣㅇㄷㅗ_', 'ㅇㅏ_ㄴㅣ_ㄱㅗ_'],\n",
       " ['731ㅂㅜ_ㄷㅐ_ㅇㅢ_',\n",
       "  'ㅎㅜ_ㅇㅖ_ㄹㅏ_',\n",
       "  'ㄱㅡ_ㄹㅓㄴㅈㅣ_',\n",
       "  'ㄱㅏ_ㅎㅏㄱㅈㅓㄱㅇㅣㄴ',\n",
       "  'ㅇㅏ_ㅇㅣ_ㄷㅣ_ㅇㅓ_ㄴㅡㄴ',\n",
       "  'ㅅㅔ_ㄱㅖ_ㅊㅚ_ㄱㅗ_ㅇㅣㅁ',\n",
       "  'ㅇㅣ_ㄹㅐ_ㅅㅓ_',\n",
       "  'ㅇㅐ_ㄱㅛ_ㅁㅏㄴ',\n",
       "  'ㄸㅓㄹㅇㅓ_ㄷㅗ_',\n",
       "  'ㄷㅗㄴ',\n",
       "  'ㅂㅓㄹㄹㅣ_ㄴㅡㄴ',\n",
       "  'ㅎㅏㄴㄱㅜㄱㅇㅔ_',\n",
       "  'ㄱㅣ_ㄹㅡㄹ',\n",
       "  'ㅆㅓ_ㅅㅓ_',\n",
       "  'ㅈㅣㄴㅊㅜㄹㅎㅏ_ㄹㅕ_ㄱㅗ_',\n",
       "  'ㅎㅏ_ㅈㅣ_ㅈㅗ_ㅅㅔㄴㄴㅏㅁㅈㅏ_ㄷㅡㄹㅇㅡㄴ',\n",
       "  'ㄸㅗ_',\n",
       "  'ㅇㅣ_ㅃㅡㄴㅇㅕ_ㅈㅏ_ㅁㅏㄴ',\n",
       "  'ㅂㅗ_ㅁㅕㄴ',\n",
       "  'ㅅㅏ_ㅈㅗㄱㅇㅡㄹ',\n",
       "  'ㅁㅗㅅㅆㅡ_ㅁㅕ_',\n",
       "  'ㄱㅗㅇㅈㅜ_ㄷㅐ_ㅈㅓㅂㅎㅐ_ㅈㅜ_ㄴㅡㄴ',\n",
       "  'ㄴㅗㅁㄷㅡㄹㅇㅣ_ㄴㅣ_'],\n",
       " ['ㅈㅐ_ㅇㅏㅇㅇㅣ_ㅎㅏㄴㄱㅓㄴㅎㅐㅅㄴㅗ_'],\n",
       " ['ㄱㅡㄹㅆㅡㄴㅇㅣ_',\n",
       "  'ㅇㅘ_ㄲㅜ_',\n",
       "  'ㅅㅡㅇㄹㅣ_ㅇㅔ_',\n",
       "  'ㅂㅣ_ㅎㅏ_ㅁㅕㄴ',\n",
       "  'ㅂㅏㅇㅅㅏ_ㄴㅡㅇ',\n",
       "  'ㅍㅣ_ㅍㅗㄱ',\n",
       "  'ㅇㅝㄴㅅㅜㅇㅇㅣ_',\n",
       "  'ㅇㅣㄹㄷㅡㅅ'],\n",
       " ['ㅁㅏ_',\n",
       "  'ㅆㅣ_ㅂㅏㄹㄹㅕㄴ',\n",
       "  'ㅇㅏ_',\n",
       "  'ㅁㅕㅊㅍㅕㅇㅇㅣ_ㄱㅗ_',\n",
       "  'ㅁㅐㅅㄱㅐ_ㄷㅡ_ㄱㅏㅆㄴㅗ_',\n",
       "  'ㄴㅣ_',\n",
       "  'ㄷㅐ_ㅎㅏ_ㅇㅣ_ㅎㅐㅁㅎㅏ_ㄱㅗ_',\n",
       "  'ㅎㅐ_ㅂㅏㅆㄴㅏ_'],\n",
       " ['ㅇㅡㄴㅎㅐㅇㅇㅔ_',\n",
       "  'ㄷㅐ_ㅊㅜㄹ',\n",
       "  'ㅅㅏㅇㄷㅏㅁ',\n",
       "  'ㅂㅏㄷㅇㅡ_ㄹㅓ_',\n",
       "  'ㄱㅏ_ㅂㅗ_ㅁㅕㄴ',\n",
       "  'ㅈㅣㄱㅇㅓㅂㅇㅢ_',\n",
       "  'ㄱㅟ_ㅊㅓㄴ',\n",
       "  'ㅂㅏ_ㄹㅗ_',\n",
       "  'ㅇㅏㄹㄹㅕ_ㅈㅜㅁ']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fasttext 인풋 완성!\n",
    "sentence_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b30287",
   "metadata": {},
   "source": [
    "### FastText WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51a7e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 차원: 100\n",
    "# window size: 좌우 2단어 비속어는 좌우단어와 별로 연관이 없다고 판단...\n",
    "# min_count: 최소 3번 등장한 단어들\n",
    "# workers: -1 전부!!\n",
    "# sg: skipgram이 더 성능이 좋기 때문\n",
    "# min_n max_n : n-gram단위인데 한글자가 3글자라 최소 자모3개부터 최대 6개까지 ngram하기로 하였다. 1글자 ~ 2글자\n",
    "# iter: 반복횟수 10\n",
    "\n",
    "model = FastText(sentence_list, size=100, window=2, min_count=3, workers=4, sg=1, min_n=3, max_n=6, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a67fa1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62105"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 62105개 단어로 vocab이 만들어졌다.\n",
    "# len(model.wv)\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2383f874",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 연도 같은 경우는 연도와 비슷한 단어들이 나온다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(jamo_split(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018년\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 연도 같은 경우는 연도와 비슷한 단어들이 나온다.\n",
    "model.wv.most_similar(jamo_split(\"2018년\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bad4edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅈㅟ_ㅅㅐ_ㄲㅣ_', 0.9755383729934692),\n",
       " ('ㅊㅣ_ㅁㅐ_ㅅㅐ_ㄲㅣ_', 0.9718326330184937),\n",
       " ('ㅇㅐ_ㅅㅐ_ㄲㅣ_', 0.9717241525650024),\n",
       " ('ㄱㅐ_ㅆㅣㅂㅅㅐ_ㄲㅣ_', 0.9717193841934204),\n",
       " ('ㅅㅣㅂㅅㅐ_ㄲㅣ_', 0.9686024785041809),\n",
       " ('ㄱㅐ_ㄷㅗㄱㅅㅐ_ㄲㅣ_', 0.96709805727005),\n",
       " ('ㅉㅏㅇㄲㅐ_ㅅㅐ_ㄲㅣ_', 0.9652191400527954),\n",
       " ('ㅊㅣ_ㅌㅏ_ㅅㅐ_ㄲㅣ_', 0.9636259078979492),\n",
       " ('ㅆㅣㅂㅅㅐ_ㄲㅣ_', 0.9634711146354675),\n",
       " ('ㅁㅜㄴㅅㅐ_ㄲㅣ_', 0.9631229043006897)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 욕설 같은 경우는 비슷한 형태의 욕설이 나온다.\n",
    "model.wv.most_similar(jamo_split(\"개새끼\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d657313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅁㅝㄴㅅㅣ_ㅂㅏㄹ', 0.9581457376480103),\n",
       " ('ㅆㅣ_ㅂㅏㄹ', 0.9515796899795532),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄴㅓㅁ', 0.9480047225952148),\n",
       " ('ㅅㅣ_ㅂㅏㅋ', 0.9453717470169067),\n",
       " ('ㅇㅘ_ㅆㅣ_ㅂㅏㄹ', 0.9367014169692993),\n",
       " ('ㅅㅣ_ㅂㅏㄹㅇㅘ_', 0.932921290397644),\n",
       " ('ㅇㅘ_ㅅㅣ_ㅂㅏㄹ', 0.9328004121780396),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄲㅓ_', 0.9291257858276367),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄴㅗㅁ', 0.9290575981140137),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄹㅕㄴ', 0.9143559336662292)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"시발\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78140479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅅㅣ_ㅂㅏㅋ', 0.9333863258361816),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄹㅓㅁㅇㅏ_', 0.9325875639915466),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄹㅗㅁㅇㅏ_', 0.9319903254508972),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄴㅓㅁ', 0.9314566850662231),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄲㅓ_', 0.9202462434768677),\n",
       " ('ㅅㅣ_ㅂㅏㄹㅇㅏ_', 0.9190757870674133),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄹㅕㄴㅇㅏ_', 0.9178509712219238),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄴㅗㅁ', 0.9153333902359009),\n",
       " ('ㅅㅣ_ㅂㅏㄹㄴㅕㄴㅇㅏ_', 0.9124631881713867),\n",
       " ('ㅆㅣ_ㅂㅏ_', 0.909488320350647)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"시바\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1145ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅁㅣ_ㅊㅣㄴㄴㅓㅁ', 0.9066715836524963),\n",
       " ('ㅁㅣ_ㅊㅣㄴㅈㅣㅅ', 0.8714250922203064),\n",
       " ('ㅁㅣ_ㅊㅣㄴㄴㅗㅁ', 0.8459020256996155),\n",
       " ('ㄱㅐ_ㅁㅣ_ㅊㅣㄴ', 0.8347834348678589),\n",
       " ('ㅁㅣ_ㅊㅣㄹ', 0.8251173496246338),\n",
       " ('ㅁㅣ_ㅊㅣㄴㄴㅕㄴ', 0.8197712898254395),\n",
       " ('ㅂㅣ_ㅊㅣㄴ', 0.8066060543060303),\n",
       " ('ㅁㅣ_ㅊㅕ_', 0.7836000919342041),\n",
       " ('ㅁㅣ_ㅊㅣㄴㄴㅗㅁㅇㅏ_', 0.782168984413147),\n",
       " ('ㅈㅣ_ㅊㅣㄴ', 0.7717003226280212)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"미친\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fdf2c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅈㅗㄴㄴㅏ_ㅍㅐㅁ', 0.9640662670135498),\n",
       " ('ㅅㅗㄴㄴㅏ_', 0.9248775839805603),\n",
       " ('ㅈㅗ_ㅇㅗㄴㄴㅏ_', 0.906119704246521),\n",
       " ('ㅈㅗㄴㄴㅏ_ㅎㅏㅁ', 0.8897804021835327),\n",
       " ('ㅈㅗㄴㄴㅏ_ㅇㅜㅅㅈㅏ_', 0.8823866844177246),\n",
       " ('ㅈㅛㄴㄴㅏ_', 0.8606939911842346),\n",
       " ('ㅈㅝㄴㄴㅏ_', 0.8542730808258057),\n",
       " ('ㅈㅗㄴㄴㅏ_ㅁㅏㄶㄴㅔ_', 0.852696418762207),\n",
       " ('ㅈㅗㄴㄴㅏ_ㅅㅣㅀㅇㅡㅁ', 0.8515698313713074),\n",
       " ('ㅇㅛㄴㄴㅏ_', 0.8508866429328918)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"존나\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ad69ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅈㅣ_ㄹㅏㄹㅂㅕㅇ', 0.9685596227645874),\n",
       " ('ㅈㅣ_ㄹㅏㄹㅈㅗㅁ', 0.9577693939208984),\n",
       " ('ㅈㅣ_ㄹㅏㄹㅂㅏㄹㄱㅘㅇ', 0.9528383016586304),\n",
       " ('ㅈㅣ_ㄹㅏㄹㅁㅏ_', 0.9420679211616516),\n",
       " ('ㅈㅗㅈㅈㅣ_ㄹㅏㄹ', 0.9324055910110474),\n",
       " ('ㅈㅣ_ㄹㅏㄹㅇㅣㅁ', 0.9312236309051514),\n",
       " ('ㅂㅕㄹㅈㅣ_ㄹㅏㄹ', 0.9237711429595947),\n",
       " ('ㅈㅣ_ㄹㅏㄹㅎㅏㅁ', 0.9230659604072571),\n",
       " ('ㅈㅣ_ㄹㅏㄹㅎㅏㄹ', 0.9047238826751709),\n",
       " ('ㄱㅐ_ㅈㅣ_ㄹㅏㄹ', 0.9012449979782104)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"지랄\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91bd21f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅆㅣㅂㅆㅡ_ㄹㅔ_ㄱㅣ_', 0.9678969979286194),\n",
       " ('ㅈㅗㅈㅆㅡ_ㄹㅔ_ㄱㅣ_', 0.9603729248046875),\n",
       " ('ㄱㅐ_ㅆㅡ_ㄹㅔ_ㄱㅣ_', 0.954119086265564),\n",
       " ('ㅆㅡ_ㄹㅔ_ㄱㅣ_ㅌㅗㅇ', 0.9291515350341797),\n",
       " ('ㄱㅐ_ㅆㅣㅂㅆㅡ_ㄹㅔ_ㄱㅣ_', 0.9211405515670776),\n",
       " ('ㅇㅣㄴㄱㅏㄴㅆㅡ_ㄹㅔ_ㄱㅣ_', 0.9059302806854248),\n",
       " ('ㅆㅡ_ㄹㅔ_ㄱㅣ_ㄴㅣ_', 0.9002506136894226),\n",
       " ('ㄱㅣ_ㄹㅔ_ㄱㅣ_', 0.8951807022094727),\n",
       " ('ㅆㅡ_ㄹㅔ_ㄱㅣ_ㅇㅣㅁ', 0.8636864423751831),\n",
       " ('ㅆㅡ_ㄹㅐ_ㄱㅣ_', 0.8620851039886475)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"쓰레기\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27af411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model 저장\n",
    "model.save(\"./festtext_embedded_1.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9dacb",
   "metadata": {},
   "source": [
    "### ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "831539ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext 모델 불러오기\n",
    "\n",
    "from gensim.models import FastText\n",
    "\n",
    "embedded_model = FastText.load(\"./festtext_embedded_1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbd157a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31149/1170649138.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  df['댓글'] = df['댓글'].apply(lambda x: [embedded_model[_] for _ in x])\n"
     ]
    }
   ],
   "source": [
    "# 각 단어를 벡터화 시켜주는 과정 3 x 100(embedding dimension) \n",
    "df['댓글'] = df['댓글'].apply(lambda x: [embedded_model[_] for _ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a0311b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.6416038, 0.39122328, -0.45883512, -0.1057...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.060996383, -0.039162956, 0.9557268, 1.0635...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.31791896, 1.0826435, -0.18621485, 0.75556...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.59272283, 0.58092606, 0.6686394, 0.181487...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.2995909, 0.94177955, -0.5402276, 0.117031...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  댓글  비속어여부\n",
       "0  [[-0.6416038, 0.39122328, -0.45883512, -0.1057...      1\n",
       "1  [[0.060996383, -0.039162956, 0.9557268, 1.0635...      0\n",
       "2  [[-0.31791896, 1.0826435, -0.18621485, 0.75556...      1\n",
       "3  [[-0.59272283, 0.58092606, 0.6686394, 0.181487...      0\n",
       "4  [[-0.2995909, 0.94177955, -0.5402276, 0.117031...      1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd59b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화된 데이터로 저장\n",
    "df.to_json(\"./fasttext_vectorized_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea2e17",
   "metadata": {},
   "source": [
    "## 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155c8e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.6416038275, 0.39122328160000003, -0.45883...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0609963834, -0.0391629562, 0.9557268023000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.3179189563, 1.0826435089, -0.1862148494, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.5927228332000001, 0.5809260607, 0.6686394...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.2995908856, 0.9417795539, -0.540227592, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  댓글  비속어여부\n",
       "0  [[-0.6416038275, 0.39122328160000003, -0.45883...      1\n",
       "1  [[0.0609963834, -0.0391629562, 0.9557268023000...      0\n",
       "2  [[-0.3179189563, 1.0826435089, -0.1862148494, ...      1\n",
       "3  [[-0.5927228332000001, 0.5809260607, 0.6686394...      0\n",
       "4  [[-0.2995908856, 0.9417795539, -0.540227592, 0...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_json(\"./fasttext_vectorized_1.json\")\n",
    "df2.columns = [\"댓글\", \"비속어여부\"]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefd69c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "8\n",
      "9\n",
      "3\n",
      "3\n",
      "23\n",
      "1\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "13\n",
      "5\n",
      "7\n",
      "8\n",
      "4\n",
      "8\n",
      "19\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 상위 20개 문장의 단어 개수 살펴보기\n",
    "for i in range(0,20):\n",
    "    print(len(df2.iloc[i,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb55e1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최대 단어길이 : 312\n",
      "문장의 평균 단어길이 : 8.244289829521305\n"
     ]
    }
   ],
   "source": [
    "print('문장의 최대 단어길이 :',max(len(review) for review in df2['댓글']))\n",
    "print('문장의 평균 단어길이 :',sum(map(len, df2['댓글']))/len(df2['댓글']))\n",
    "\n",
    "# 한 문장의 최대 단어의 개수는 312개, 평균 단어의 개수는 8개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73627fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문장들 중 단어개수가 30 이하인 문장의 비율: 97.1733803474638\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    count = 0\n",
    "    for sentence in nested_list:\n",
    "        if(len(sentence) <= max_len):\n",
    "            count = count + 1\n",
    "    print('전체 문장들 중 단어개수가 %s 이하인 문장의 비율: %s'%(max_len, (count / len(nested_list))*100))\n",
    "    \n",
    "max_len = 30\n",
    "below_threshold_len(max_len, df2['댓글'])\n",
    "\n",
    "# 97 % 가 30 단어 이하이기 때문에 최대단어수는 30으로 패딩해주는것이 좋을것같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01fbd1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152464 152464 38117 38117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df2['댓글'], df2['비속어여부'] , test_size=0.2, random_state=0)\n",
    "print(len(train_x), len(train_y), len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a320d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[-0.6416038275, 0.39122328160000003, -0.45883...\n",
       "1    [[0.0609963834, -0.0391629562, 0.9557268023000...\n",
       "2    [[-0.3179189563, 1.0826435089, -0.1862148494, ...\n",
       "3    [[-0.5927228332000001, 0.5809260607, 0.6686394...\n",
       "4    [[-0.2995908856, 0.9417795539, -0.540227592, 0...\n",
       "5    [[-0.1525025368, -0.38018080590000003, -0.2431...\n",
       "6    [[-0.5504084826, 0.7977899313, -0.079168982800...\n",
       "7    [[-0.9684337378000001, 1.1426610947, -0.196303...\n",
       "8    [[-0.3493541181, 0.7854241133000001, -1.033611...\n",
       "9    [[-0.3350792825, 0.09681017700000001, 0.822802...\n",
       "Name: 댓글, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['댓글'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebde07dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46726     [[-0.4425993264, -0.0899327248, 0.0366247185, ...\n",
       "94165     [[-0.5336186886000001, 0.6592813134000001, -0....\n",
       "136954    [[-1.1767054796, -0.0874177217, 1.0539677143, ...\n",
       "183719    [[-0.1866511256, 0.4419595897, 0.0912217647, -...\n",
       "133146    [[0.24270738660000002, 0.8839552999, -0.201448...\n",
       "                                ...                        \n",
       "152315    [[-0.42085075380000003, -0.15677140650000002, ...\n",
       "176963    [[0.2120446712, -0.2478029579, -0.4419538975, ...\n",
       "117952    [[-0.7531749606, 0.1324819475, -0.2797733247, ...\n",
       "173685    [[-0.6214374304, -0.019838854700000002, -0.857...\n",
       "43567     [[-0.10557022690000001, 0.7503887415, -0.19460...\n",
       "Name: 댓글, Length: 152464, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b9bc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46726     1\n",
       "94165     1\n",
       "136954    0\n",
       "183719    0\n",
       "133146    0\n",
       "         ..\n",
       "152315    0\n",
       "176963    0\n",
       "117952    1\n",
       "173685    0\n",
       "43567     1\n",
       "Name: 비속어여부, Length: 152464, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c03d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=[]\n",
    "# for i in train_x:\n",
    "#     a.append(np.array(train_x))\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532f3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y array형식으로 변경\n",
    "y_train = np.array(train_y)\n",
    "y_test = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affde514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(train_x, maxlen=max_len)\n",
    "X_test = pad_sequences(test_x, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0db5d7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  1, ..., -1,  0,  0],\n",
       "        [ 0,  1,  0, ...,  0,  0,  0],\n",
       "        [ 0,  1, -1, ...,  1,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0, -1, -1],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0, -1,  0],\n",
       "        [ 0,  0, -1, ...,  1,  0,  0],\n",
       "        [ 0,  0, -1, ...,  1, -2, -2]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  1,  0, ...,  0,  0,  0]]], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a091a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38117, 30, 100)\n",
      "(152464, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "418c5cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38117,)\n",
      "(152464,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73abf7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51192d39",
   "metadata": {},
   "source": [
    "### LSTM 학습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f91c9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 04:43:10.655291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-11 04:43:10.889755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0001:00:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2022-05-11 04:43:10.891584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-11 04:43:10.986634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-11 04:43:11.078489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-11 04:43:11.083474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-11 04:43:11.230731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-11 04:43:11.236194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-11 04:43:11.236392: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2022-05-11 04:43:11.236406: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-11 04:43:11.236949: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-05-11 04:43:11.278626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2445435000 Hz\n",
      "2022-05-11 04:43:11.278802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efcec000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-05-11 04:43:11.278819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-05-11 04:43:11.280692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-11 04:43:11.280708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n",
      "2022-05-11 04:43:11.557627: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1829568000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4765/4765 [==============================] - 29s 6ms/step - loss: 0.3397 - accuracy: 0.8621 - val_loss: 0.2899 - val_accuracy: 0.8788\n",
      "Epoch 2/10\n",
      "4765/4765 [==============================] - 29s 6ms/step - loss: 0.2817 - accuracy: 0.8808 - val_loss: 0.2839 - val_accuracy: 0.8785\n",
      "Epoch 3/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2774 - accuracy: 0.8817 - val_loss: 0.2829 - val_accuracy: 0.8792\n",
      "Epoch 4/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2763 - accuracy: 0.8820 - val_loss: 0.2828 - val_accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2756 - accuracy: 0.8820 - val_loss: 0.2820 - val_accuracy: 0.8792\n",
      "Epoch 6/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2753 - accuracy: 0.8817 - val_loss: 0.2835 - val_accuracy: 0.8780\n",
      "Epoch 7/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2751 - accuracy: 0.8824 - val_loss: 0.2814 - val_accuracy: 0.8791\n",
      "Epoch 8/10\n",
      "4765/4765 [==============================] - 29s 6ms/step - loss: 0.2751 - accuracy: 0.8820 - val_loss: 0.2821 - val_accuracy: 0.8799\n",
      "Epoch 9/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2748 - accuracy: 0.8825 - val_loss: 0.2805 - val_accuracy: 0.8799\n",
      "Epoch 10/10\n",
      "4765/4765 [==============================] - 28s 6ms/step - loss: 0.2750 - accuracy: 0.8822 - val_loss: 0.2820 - val_accuracy: 0.8792\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=1, input_shape=(30, 100)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "# mc = ModelCheckpoint('FT_best_model_v0.0.1.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "329d80ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192/1192 [==============================] - 2s 2ms/step - loss: 0.2820 - accuracy: 0.8792\n",
      "\n",
      " 테스트 정확도: 0.8792\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1])) # model.evaluate(X_test, y_test)\n",
    "# x와 y 의 test 에 대한 정확도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5083b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./fasttext_LSTM1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1c856c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 09:01:21.980801: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/check_up_py38_PT_TF/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./fasttext_model/assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"./fasttext_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd725c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 09:29:27.588928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-11 09:29:27.732822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0001:00:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2022-05-11 09:29:27.734832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-11 09:29:27.829004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-11 09:29:27.930799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-11 09:29:27.935553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-11 09:29:28.074339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-11 09:29:28.080021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-11 09:29:28.080246: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2022-05-11 09:29:28.080260: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-11 09:29:28.080582: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-05-11 09:29:28.118654: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2445435000 Hz\n",
      "2022-05-11 09:29:28.118979: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec54000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-05-11 09:29:28.118994: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-05-11 09:29:28.120871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-11 09:29:28.120885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n"
     ]
    }
   ],
   "source": [
    "lstm_model = load_model('./fasttext_LSTM1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617f4f1",
   "metadata": {},
   "source": [
    "# 모델 사용해서 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e858fa8",
   "metadata": {},
   "source": [
    "### for index in range(len(test_word.split)) 일 경우 예측 - O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "168111da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(test_word_split)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.9:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "646cb1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/1192334688.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result(\"마라탕\", embedded_model, lstm_model) # ㅠㅠ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aebb6189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/1192334688.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result(\"지랄하지마\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83656a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/1192334688.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result(\"나가서 놀고싶다\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35066f",
   "metadata": {},
   "source": [
    "### for index in range(len(s)) 일 경우 예측 - O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2d85b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result2(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(s)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.9:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b8f30e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 30, 100) for input Tensor(\"lstm_input:0\", shape=(None, 30, 100), dtype=float32), but it was called on an input with incompatible shape (None, 7, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/3639305100.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "test_result2(\"너무 어려워요\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "661577fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/3639305100.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result2(\"마라탕\", embedded_model, lstm_model) # ?? ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55340a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/3639305100.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result2(\"졸라 시끄러워\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991775d3",
   "metadata": {},
   "source": [
    "### for index in range(len(test_word)) 일 경우 예측 - O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "019ea160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result10(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(test_word)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.9:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0376b0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 30, 100) for input Tensor(\"lstm_input:0\", shape=(None, 30, 100), dtype=float32), but it was called on an input with incompatible shape (None, 19, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/88498840.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "test_result10(\"졸라 시끄러워\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f73c8c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 30, 100) for input Tensor(\"lstm_input:0\", shape=(None, 30, 100), dtype=float32), but it was called on an input with incompatible shape (None, 9, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/88498840.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7feedc3e8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "test_result10(\"마라탕\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c4acb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/88498840.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result10(\"집에 갈꺼에요\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43045d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/88498840.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result10(\"집에 갈꺼에용\", embedded_model, lstm_model) # 왜일까"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352edd0",
   "metadata": {},
   "source": [
    "### 반대로 적용해보기 - X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a54c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result3(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(s)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.9:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da47dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/3385605691.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result3(\"졸라 시끄러워\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0988545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 30, 100) for input Tensor(\"lstm_input:0\", shape=(None, 30, 100), dtype=float32), but it was called on an input with incompatible shape (None, 12, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/3385605691.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "test_result3(\"돌체라떼 너무 맛있어요\", embedded_model, lstm_model) # 반대로 하는거는 틀린것같음!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8393ec",
   "metadata": {},
   "source": [
    "### range(len(test_word_split) 로 해보기 - X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8af1bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result4(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(test_word_split)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.4:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "da05d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/2997558423.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result4(\"돌체라떼 너무 맛있어요\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "573910a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/2997558423.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result4(\"돌체라떼 미친놈\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831c620",
   "metadata": {},
   "source": [
    "### 값을 낮춰보기 - O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ceabe2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result5(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(s)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.4:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a0bbbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/4085268211.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result5(\"돌체라떼 너무 맛있어요\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e558e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 30, 100) for input Tensor(\"lstm_input:0\", shape=(None, 30, 100), dtype=float32), but it was called on an input with incompatible shape (None, 8, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/4085268211.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "test_result5(\"돌체라떼 미친놈\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2f78c",
   "metadata": {},
   "source": [
    "### range(len(test_word_split))로 바꿔보기 - O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05cb1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result6(s, embedded_model, lstm_model):\n",
    "    test_word = jamo_split(s)\n",
    "    test_word_split = test_word.split()\n",
    "    fast_vec = []\n",
    "    for index in range(len(test_word_split)):\n",
    "        if index < len(test_word_split):\n",
    "            fast_vec.append(embedded_model[test_word_split[index]])\n",
    "        else:\n",
    "            fast_vec.append(np.array([0]*100))\n",
    "    fast_vec = np.array(fast_vec)\n",
    "    fast_vec=fast_vec.reshape(1, fast_vec.shape[0], fast_vec.shape[1])\n",
    "    # 학습 데이터와 마찬가지로 3차원으로 크기 조절\n",
    "    test_pre = lstm_model.predict_classes([fast_vec]) # 비속어 판별\n",
    "    if test_pre[0][0] > 0.4:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있습니다.\")\n",
    "    else:\n",
    "        print(\"lstm 결과 : 비속어가 포함되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81060ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/155278071.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result6(\"돌체라떼 맛있어요\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c71432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/155278071.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result6(\"돌체라떼 미친놈\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1edd75db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm 결과 : 비속어가 포함되어 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15844/155278071.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  fast_vec.append(embedded_model[test_word_split[index]])\n"
     ]
    }
   ],
   "source": [
    "test_result6(\"마라탕\", embedded_model, lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647caf0a",
   "metadata": {},
   "source": [
    "#### O = 어느정도 구분은 하지만 비속어가 아닌데도 비속어라고 판별하는 경우가 있음\n",
    "#### 예를 들어 마라탕을 왜 비속어라고 분류하는지? 알 수 있는 방법이 없다..\n",
    "#### len() 에 어떤것이 들어가야 하는지는 알아봐야한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "check_up_py38_PT_TF",
   "language": "python",
   "name": "conda-env-check_up_py38_PT_TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
