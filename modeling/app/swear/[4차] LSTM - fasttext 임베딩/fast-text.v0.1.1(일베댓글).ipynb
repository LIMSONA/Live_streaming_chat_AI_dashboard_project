{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3dae558",
   "metadata": {},
   "source": [
    "## 일베 댓글로 fast-text 임베딩 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전처리 코드 블로그에서 받아온거\n",
    "import re\n",
    "from lxml import etree\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "targetXML = open('./ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행한다.\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "result = []\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "### FastText 학습\n",
    "from gensim.models import FastText\n",
    "ft_model = FastText(result, size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f537832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49568250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다 10년 더 입어야지</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>재앙이한건햇노</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>글쓴이 와꾸 승리에 비하면 방사능 피폭 원숭이 일듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  댓글  비속어여부\n",
       "0                                             좌배 까는건      1\n",
       "1                           집에 롱 패딩만 세 개다 10년 더 입어야지      0\n",
       "2          개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                        세탁이라고 봐도 된다      0\n",
       "4                                       애새끼가 초딩도 아니고      1\n",
       "5  731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 ...      1\n",
       "6                                            재앙이한건햇노      1\n",
       "7                       글쓴이 와꾸 승리에 비하면 방사능 피폭 원숭이 일듯      1\n",
       "8                    마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나      1\n",
       "9                    은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./비속어데이터셋_전처리o.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be706d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터에 적용시키기 위한 과정\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    sentence_split = sentence.split()\n",
    "    sentence_split_result = []\n",
    "    for word in sentence_split:\n",
    "        if word[0] != '@' and word[:4] !='http':\n",
    "            sentence_split_result.append(word)\n",
    "    sentence_result = ' '.join(sentence_split_result)\n",
    "    text_result = ''.join(re.compile('[가-힣|0-9|a-z| ]+').\\\n",
    "    findall(sentence_result)).strip()\n",
    "    return text_result\n",
    "\n",
    "df[\"댓글\"] = df[\"댓글\"].apply(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19272feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다 10년 더 입어야지</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>재앙이한건햇노</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>글쓴이 와꾸 승리에 비하면 방사능 피폭 원숭이 일듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  댓글  비속어여부\n",
       "0                                             좌배 까는건      1\n",
       "1                           집에 롱 패딩만 세 개다 10년 더 입어야지      0\n",
       "2          개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                        세탁이라고 봐도 된다      0\n",
       "4                                       애새끼가 초딩도 아니고      1\n",
       "5  731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 ...      1\n",
       "6                                            재앙이한건햇노      1\n",
       "7                       글쓴이 와꾸 승리에 비하면 방사능 피폭 원숭이 일듯      1\n",
       "8                    마 씨발련 아 몇평이고 맷개드갔노 니 대하이햄하고 해밨나      1\n",
       "9                    은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8e18de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "댓글       0\n",
      "비속어여부    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# white space 데이터를 empty value로 변경\n",
    "\n",
    "df[\"댓글\"] = df[\"댓글\"].str.replace('^ +', \"\")\n",
    "df[\"댓글\"].replace('', np.nan, inplace=True)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d996782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 내 한글자만 이루어진 댓글은 삭제\n",
    "\n",
    "def onewordremove(sentence):\n",
    "    sentence_list = []\n",
    "    for index in range(len(sentence.split())):\n",
    "        if len(sentence.split()[index]) > 1: #문자 1글자 초과일 때\n",
    "            sentence_list.append(sentence.split()[index]) #문자 1글자로 이루어진 단어만 빼고 sentence_list에 추가\n",
    "    sentence = \" \".join(sentence_list) #리스트의 내용을 하나의 문자열로 join\n",
    "    return sentence\n",
    "\n",
    "df['댓글'] = df['댓글'].apply(onewordremove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d05fa425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 패딩만 개다 10년 입어야지</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>후장꽂아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6765</th>\n",
       "      <td>후장뚫어</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>흐접</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>흐젚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>흐졉</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6769 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             댓글  비속어여부\n",
       "0                                        좌배 까는건      1\n",
       "1                            집에 패딩만 개다 10년 입어야지      0\n",
       "2     개소리야 니가 빨갱이를 옹호하고 드루킹을 짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                   세탁이라고 봐도 된다      0\n",
       "4                                  애새끼가 초딩도 아니고      1\n",
       "...                                         ...    ...\n",
       "6764                                       후장꽂아      1\n",
       "6765                                       후장뚫어      1\n",
       "6766                                         흐접      1\n",
       "6767                                         흐젚      1\n",
       "6768                                         흐졉      1\n",
       "\n",
       "[6769 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "977a0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','을','으로','자','에','와','한','하다','부터']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0221f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd862f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ba0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dd1dc1d",
   "metadata": {},
   "source": [
    "# 자모 분류, fast text 는 git 참고 \n",
    "https://github.com/smothly/bad-word-detection/blob/master/FastTextVocab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72c2a7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "문장       object\n",
       "혐오 여부     int64\n",
       "글자수       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9026f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자나 한자 등이 안날라 갔을 경우를 처리\n",
    "import re\n",
    "pattern = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9a-zA-Z ]\") # 한글 숫자 영어 공백 말고 제거\n",
    "\n",
    "# 각 단어에 해당 해당 정규표현식 적용\n",
    "def clear_word(word):\n",
    "    word = re.sub(pattern, \"\", word)\n",
    "    return word\n",
    "\n",
    "df['문장'] = df['문장'].astype('str')\n",
    "df['문장'] = df['문장'].apply(lambda x: clear_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9488d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 뒤죽박죽 된 것 재정비\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc659b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76299312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHOSUNGS = [u'ㄱ',u'ㄲ',u'ㄴ',u'ㄷ',u'ㄸ',u'ㄹ',u'ㅁ',u'ㅂ',u'ㅃ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅉ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "JOONGSUNGS = [u'ㅏ',u'ㅐ',u'ㅑ',u'ㅒ',u'ㅓ',u'ㅔ',u'ㅕ',u'ㅖ',u'ㅗ',u'ㅘ',u'ㅙ',u'ㅚ',u'ㅛ',u'ㅜ',u'ㅝ',u'ㅞ',u'ㅟ',u'ㅠ',u'ㅡ',u'ㅢ',u'ㅣ']\n",
    "JONGSUNGS = [u'_',u'ㄱ',u'ㄲ',u'ㄳ',u'ㄴ',u'ㄵ',u'ㄶ',u'ㄷ',u'ㄹ',u'ㄺ',u'ㄻ',u'ㄼ',u'ㄽ',u'ㄾ',u'ㄿ',u'ㅀ',u'ㅁ',u'ㅂ',u'ㅄ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "TOTAL = CHOSUNGS + JOONGSUNGS + JONGSUNGS\n",
    "\n",
    "# 자모분리\n",
    "def jamo_split(word, end_char=\"_\"):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for char in word:\n",
    "        \n",
    "        character_code = ord(char)\n",
    "        \n",
    "        if 0xD7A3 < character_code or character_code < 0xAC00:\n",
    "            result.append(char)\n",
    "            continue\n",
    "\n",
    "        chosung_index = int((((character_code - 0xAC00) / 28) / 21) % 19)\n",
    "        joongsung_index = int(((character_code - 0xAC00) / 28) % 21)\n",
    "        jongsung_index = int((character_code - 0xAC00) % 28)\n",
    "        \n",
    "        chosung = CHOSUNGS[chosung_index]\n",
    "        joongsung = JOONGSUNGS[joongsung_index]\n",
    "        jongsung = JONGSUNGS[jongsung_index]\n",
    "        \n",
    "        # 종성 범위 밖에 있는 것들은 end_char로 메꿔준다.\n",
    "        if jongsung_index == 0:\n",
    "            jongsung = end_char\n",
    "        \n",
    "        result.append(chosung)\n",
    "        result.append(joongsung)\n",
    "        result.append(jongsung)\n",
    "\n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "006f8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장을 jamo_split하여 저장\n",
    "#from JamoSplit import jamo_split, jamo_combine\n",
    "tmp.loc[:,'댓글'] = tmp.loc[:,'댓글'].apply(lambda x: jamo_split(x))\n",
    "tmp.loc[:,'댓글'] = tmp.loc[:,'댓글'].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb71f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>비속어여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>[ㄱㅕㅇㅇㅟ_, ㅇㅣ_ㅅㅏㅇ, ㅅㅏ_ㅂㅓㅂㄱㅕㅇㅊㅏㄹㄱㅘㄴㅁㅏㄴ, ㄱㅏ_ㄴㅡㅇㅅㅜㄴ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>[ㅇㅒ_ㄷㅗ_, ㅎㅓㄴㅂㅓㅂ, ㄱㅏㅇㅇㅢ_ㅎㅐ_ㅅㅓ_, ㅈㅗ_ㅁㅜ_ㅅㅏ_, ㄷㅚ_ㅁ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>[ㄱㅔ_ㅇㅣ_ㅇㅑ_, ㅇㅛㅇㄱㅣ_ㅅㅏ_ㅁㅕㄴ, ㄷㅡ_ㄹㅐ_ㄱㅗㄴ, ㅅㅏ_ㅇㅕㄱㅎㅏ_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>[ㄱㅡㄴㄷㅔ_, ㅇㅣㄹㄱㅔ_ㅇㅣ_ㄷㅡㄹㅇㅡㄴ, ㄱㅘㄴㄱㅖ_ㅇㅓㅄㅈㅏ_ㄴㅏ_, ㄱㅕㄹ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>[ㅈㅓ_ㄱㅓ_, ㄸㅏㄱㅂㅘ_ㄷㅗ_ㅉㅣㄴㄸㅏ_ㅅㅐ_ㄲㅣ_ㄱㅏ_, ㅇㅣㄹㅈㅣㄴㅎㅕㅇㄴㅣ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>[ㅇㅠㄱㄱㅗ_ㄱㅣ_ㄴㅡㄴ, ㅁㅏㅅㅇㅣㅆㅇㅝ_]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>[ㅇㅓ_ㅉㅓ_ㄹㅏ_ㄱㅗ_ㅎㅏ_ㅊㅏㄶㅇㅡㄴ, ㅊㅜㄱㅅㅐㅇㅎㅏㄴㅌㅔ_ㄲㅏ_ㅈㅣ_, ㄴㅏ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>[ㅅㅣㄴㅂㅏㄹㅁㅓ_ㅇㅣㅁ, ㄱㅐ_ㅇㅣ_ㅃㅡ_]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>[ㅇㅜㅅㄱㅗ_ㄱㅏㄴㄷㅏ_, ㅂㅕㅇㅅㅣㄴㅇㅏ_]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>[ㅂㅔ_ㅊㅜㅇㅇㅣ_ㅇㅘㄹㅇㅣ_ㄱㅓㅅㅇㅡㄴ, ㅈㅗ_ㅈㅏㄱㅇㅣ_ㅁㅡ_ㄴㅣ_ㄷㅏ_, ㅃㅏ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>[ㅂㅣ_ㄹㅣ_ㄷㅗ_, ㅇㅓ_ㅁㅏ_ㅇㅓ_ㅁㅏ_, ㅎㅏ_ㄷㅓ_ㅁㅏㄴ]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>[ㅈㅓ_ㄱㅔ_, ㅅㅏ_ㅅㅣㄹㅇㅣ_ㅁㅕㄴ, ㅇㅏ_ㅇㅣ_ㄷㅗㄹ, 80ㄴㅡㄴ, ㅅㅏ_ㅎㅕ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>[ㅂㅗ_ㅅㅜ_ㅇㅠ_ㅌㅜ_ㅂㅓ_ㄷㅡㄹ, ㄷㅐ_ㅂㅜ_ㅂㅜㄴㅇㅣ_, ㅈㅓ_ㄹㅓㄴ, ㅅㅣㄱ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>[ㅇㅠㄴㅅㅓㄱㄹㅕㄹ, ㅈㅏㅇㅁㅗ_, ㅂㅣ_ㄹㅣ_, ㄷㅓㅍㅇㅡ_ㄹㅕ_ㄱㅗ_, ㅁㅣ_ㄹ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>[ㄱㅡㄴㄷㅔ_, ㅁㅏㄹㅇㅣ_, ㄴㅓ_ㅁㅜ_, ㅉㅏㄴㅎㅏ_ㄷㅏ_, ㅂㅗㄴㅇㅣㄴㄷㅗ_,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     댓글  비속어여부\n",
       "2658  [ㄱㅕㅇㅇㅟ_, ㅇㅣ_ㅅㅏㅇ, ㅅㅏ_ㅂㅓㅂㄱㅕㅇㅊㅏㄹㄱㅘㄴㅁㅏㄴ, ㄱㅏ_ㄴㅡㅇㅅㅜㄴ...      0\n",
       "317   [ㅇㅒ_ㄷㅗ_, ㅎㅓㄴㅂㅓㅂ, ㄱㅏㅇㅇㅢ_ㅎㅐ_ㅅㅓ_, ㅈㅗ_ㅁㅜ_ㅅㅏ_, ㄷㅚ_ㅁ...      0\n",
       "4641  [ㄱㅔ_ㅇㅣ_ㅇㅑ_, ㅇㅛㅇㄱㅣ_ㅅㅏ_ㅁㅕㄴ, ㄷㅡ_ㄹㅐ_ㄱㅗㄴ, ㅅㅏ_ㅇㅕㄱㅎㅏ_...      1\n",
       "2594  [ㄱㅡㄴㄷㅔ_, ㅇㅣㄹㄱㅔ_ㅇㅣ_ㄷㅡㄹㅇㅡㄴ, ㄱㅘㄴㄱㅖ_ㅇㅓㅄㅈㅏ_ㄴㅏ_, ㄱㅕㄹ...      1\n",
       "5304  [ㅈㅓ_ㄱㅓ_, ㄸㅏㄱㅂㅘ_ㄷㅗ_ㅉㅣㄴㄸㅏ_ㅅㅐ_ㄲㅣ_ㄱㅏ_, ㅇㅣㄹㅈㅣㄴㅎㅕㅇㄴㅣ...      1\n",
       "692                           [ㅇㅠㄱㄱㅗ_ㄱㅣ_ㄴㅡㄴ, ㅁㅏㅅㅇㅣㅆㅇㅝ_]      0\n",
       "4277  [ㅇㅓ_ㅉㅓ_ㄹㅏ_ㄱㅗ_ㅎㅏ_ㅊㅏㄶㅇㅡㄴ, ㅊㅜㄱㅅㅐㅇㅎㅏㄴㅌㅔ_ㄲㅏ_ㅈㅣ_, ㄴㅏ...      0\n",
       "3132                          [ㅅㅣㄴㅂㅏㄹㅁㅓ_ㅇㅣㅁ, ㄱㅐ_ㅇㅣ_ㅃㅡ_]      0\n",
       "2624                          [ㅇㅜㅅㄱㅗ_ㄱㅏㄴㄷㅏ_, ㅂㅕㅇㅅㅣㄴㅇㅏ_]      1\n",
       "3978  [ㅂㅔ_ㅊㅜㅇㅇㅣ_ㅇㅘㄹㅇㅣ_ㄱㅓㅅㅇㅡㄴ, ㅈㅗ_ㅈㅏㄱㅇㅣ_ㅁㅡ_ㄴㅣ_ㄷㅏ_, ㅃㅏ...      1\n",
       "3318               [ㅂㅣ_ㄹㅣ_ㄷㅗ_, ㅇㅓ_ㅁㅏ_ㅇㅓ_ㅁㅏ_, ㅎㅏ_ㄷㅓ_ㅁㅏㄴ]      0\n",
       "2690  [ㅈㅓ_ㄱㅔ_, ㅅㅏ_ㅅㅣㄹㅇㅣ_ㅁㅕㄴ, ㅇㅏ_ㅇㅣ_ㄷㅗㄹ, 80ㄴㅡㄴ, ㅅㅏ_ㅎㅕ...      0\n",
       "2395  [ㅂㅗ_ㅅㅜ_ㅇㅠ_ㅌㅜ_ㅂㅓ_ㄷㅡㄹ, ㄷㅐ_ㅂㅜ_ㅂㅜㄴㅇㅣ_, ㅈㅓ_ㄹㅓㄴ, ㅅㅣㄱ...      0\n",
       "676   [ㅇㅠㄴㅅㅓㄱㄹㅕㄹ, ㅈㅏㅇㅁㅗ_, ㅂㅣ_ㄹㅣ_, ㄷㅓㅍㅇㅡ_ㄹㅕ_ㄱㅗ_, ㅁㅣ_ㄹ...      0\n",
       "1900  [ㄱㅡㄴㄷㅔ_, ㅁㅏㄹㅇㅣ_, ㄴㅓ_ㅁㅜ_, ㅉㅏㄴㅎㅏ_ㄷㅏ_, ㅂㅗㄴㅇㅣㄴㄷㅗ_,...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c741143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6769"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe -> list로 변환\n",
    "sentence_list = list(tmp['댓글'])\n",
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1531a05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ㅈㅘ_ㅂㅐ_', 'ㄲㅏ_ㄴㅡㄴㄱㅓㄴ'],\n",
       " ['ㅈㅣㅂㅇㅔ_', 'ㅍㅐ_ㄷㅣㅇㅁㅏㄴ', 'ㄱㅐ_ㄷㅏ_', '10ㄴㅕㄴ', 'ㅇㅣㅂㅇㅓ_ㅇㅑ_ㅈㅣ_'],\n",
       " ['ㄱㅐ_ㅅㅗ_ㄹㅣ_ㅇㅑ_',\n",
       "  'ㄴㅣ_ㄱㅏ_',\n",
       "  'ㅃㅏㄹㄱㅐㅇㅇㅣ_ㄹㅡㄹ',\n",
       "  'ㅇㅗㅇㅎㅗ_ㅎㅏ_ㄱㅗ_',\n",
       "  'ㄷㅡ_ㄹㅜ_ㅋㅣㅇㅇㅡㄹ',\n",
       "  'ㅈㅣㅅㅇㅣ_ㄹㅏ_ㄱㅗ_',\n",
       "  'ㅁㅏㄹㅁㅗㅅㅎㅐ_ㅅㅓ_',\n",
       "  'ㅃㅣ_ㅈㅣㄴㄱㅓ_ㅇㅑ_',\n",
       "  'ㅃㅏㄹㄱㅐㅇㅇㅏ_'],\n",
       " ['ㅅㅔ_ㅌㅏㄱㅇㅣ_ㄹㅏ_ㄱㅗ_', 'ㅂㅘ_ㄷㅗ_', 'ㄷㅚㄴㄷㅏ_'],\n",
       " ['ㅇㅐ_ㅅㅐ_ㄲㅣ_ㄱㅏ_', 'ㅊㅗ_ㄷㅣㅇㄷㅗ_', 'ㅇㅏ_ㄴㅣ_ㄱㅗ_'],\n",
       " ['731ㅂㅜ_ㄷㅐ_ㅇㅢ_',\n",
       "  'ㅎㅜ_ㅇㅖ_ㄹㅏ_',\n",
       "  'ㄱㅡ_ㄹㅓㄴㅈㅣ_',\n",
       "  'ㄱㅏ_ㅎㅏㄱㅈㅓㄱㅇㅣㄴ',\n",
       "  'ㅇㅏ_ㅇㅣ_ㄷㅣ_ㅇㅓ_ㄴㅡㄴ',\n",
       "  'ㅅㅔ_ㄱㅖ_ㅊㅚ_ㄱㅗ_ㅇㅣㅁ',\n",
       "  'ㅇㅣ_ㄹㅐ_ㅅㅓ_',\n",
       "  'ㅇㅐ_ㄱㅛ_ㅁㅏㄴ',\n",
       "  'ㄸㅓㄹㅇㅓ_ㄷㅗ_',\n",
       "  'ㅂㅓㄹㄹㅣ_ㄴㅡㄴ',\n",
       "  'ㅎㅏㄴㄱㅜㄱㅇㅔ_',\n",
       "  'ㄱㅣ_ㄹㅡㄹ',\n",
       "  'ㅆㅓ_ㅅㅓ_',\n",
       "  'ㅈㅣㄴㅊㅜㄹㅎㅏ_ㄹㅕ_ㄱㅗ_',\n",
       "  'ㅎㅏ_ㅈㅣ_ㅈㅗ_ㅅㅔㄴㄴㅏㅁㅈㅏ_ㄷㅡㄹㅇㅡㄴ',\n",
       "  'ㅇㅣ_ㅃㅡㄴㅇㅕ_ㅈㅏ_ㅁㅏㄴ',\n",
       "  'ㅂㅗ_ㅁㅕㄴ',\n",
       "  'ㅅㅏ_ㅈㅗㄱㅇㅡㄹ',\n",
       "  'ㅁㅗㅅㅆㅡ_ㅁㅕ_',\n",
       "  'ㄱㅗㅇㅈㅜ_ㄷㅐ_ㅈㅓㅂㅎㅐ_ㅈㅜ_ㄴㅡㄴ',\n",
       "  'ㄴㅗㅁㄷㅡㄹㅇㅣ_ㄴㅣ_'],\n",
       " ['ㅈㅐ_ㅇㅏㅇㅇㅣ_ㅎㅏㄴㄱㅓㄴㅎㅐㅅㄴㅗ_'],\n",
       " ['ㄱㅡㄹㅆㅡㄴㅇㅣ_',\n",
       "  'ㅇㅘ_ㄲㅜ_',\n",
       "  'ㅅㅡㅇㄹㅣ_ㅇㅔ_',\n",
       "  'ㅂㅣ_ㅎㅏ_ㅁㅕㄴ',\n",
       "  'ㅂㅏㅇㅅㅏ_ㄴㅡㅇ',\n",
       "  'ㅍㅣ_ㅍㅗㄱ',\n",
       "  'ㅇㅝㄴㅅㅜㅇㅇㅣ_',\n",
       "  'ㅇㅣㄹㄷㅡㅅ'],\n",
       " ['ㅆㅣ_ㅂㅏㄹㄹㅕㄴ',\n",
       "  'ㅁㅕㅊㅍㅕㅇㅇㅣ_ㄱㅗ_',\n",
       "  'ㅁㅐㅅㄱㅐ_ㄷㅡ_ㄱㅏㅆㄴㅗ_',\n",
       "  'ㄷㅐ_ㅎㅏ_ㅇㅣ_ㅎㅐㅁㅎㅏ_ㄱㅗ_',\n",
       "  'ㅎㅐ_ㅂㅏㅆㄴㅏ_'],\n",
       " ['ㅇㅡㄴㅎㅐㅇㅇㅔ_',\n",
       "  'ㄷㅐ_ㅊㅜㄹ',\n",
       "  'ㅅㅏㅇㄷㅏㅁ',\n",
       "  'ㅂㅏㄷㅇㅡ_ㄹㅓ_',\n",
       "  'ㄱㅏ_ㅂㅗ_ㅁㅕㄴ',\n",
       "  'ㅈㅣㄱㅇㅓㅂㅇㅢ_',\n",
       "  'ㄱㅟ_ㅊㅓㄴ',\n",
       "  'ㅂㅏ_ㄹㅗ_',\n",
       "  'ㅇㅏㄹㄹㅕ_ㅈㅜㅁ']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fasttext 인풋 완성!\n",
    "sentence_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b30287",
   "metadata": {},
   "source": [
    "### FastText WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a7e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext 적용\n",
    "from gensim.models import FastText\n",
    "# 임베딩 차원: 50\n",
    "# window size: 좌우 2단어 비속어는 좌우단어와 별로 연관이 없다고 판단...\n",
    "# min_count: 최소 3번 등장한 단어들\n",
    "# workers: -1 전부!!\n",
    "# sg: skipgram이 더 성능이 좋기 때문\n",
    "# min_n max_n : n-gram단위인데 한글자가 3글자라 최소 자모3개부터 최대 6개까지 ngram하기로 하였다. 1글자 ~ 2글자\n",
    "# iter: 반복횟수 10\n",
    "model = FastText(sentence_list, size=50, window=2, min_count=3, workers=4, sg=1, min_n=3, max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a67fa1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1769"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 1769개 단어로 vocab이 만들어졌다.\n",
    "# len(model.wv)\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2383f874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㄱㅘㄴㅎㅏㄴ', 0.9992398023605347),\n",
       " ('ㅈㅣ_ㅂㅏㅇㅇㅡㄴ', 0.9991357326507568),\n",
       " ('ㅍㅐ_ㄷㅣㅇㅇㅡㄴ', 0.999131441116333),\n",
       " ('ㄱㅣㅁㅆㅣ_', 0.999125599861145),\n",
       " ('ㅁㅐ_ㄴㅕㄴ', 0.9991162419319153),\n",
       " ('ㅍㅐㄱㅌㅡ_ㄹㅡㄹ', 0.9991050958633423),\n",
       " ('ㄷㅗㄴㅇㅡㄹ', 0.9991037845611572),\n",
       " ('ㅇㅣ_ㄹㅡㅁ', 0.9991020560264587),\n",
       " ('ㅂㅜ_ㅂㅜㄴㄷㅗ_', 0.9990983009338379),\n",
       " ('ㅁㅏ_ㅌㅣ_ㅊㅣ_', 0.9990958571434021)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연도 같은 경우는 연도와 비슷한 단어들이 나온다.\n",
    "model.wv.most_similar(jamo_split(\"2018년\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bad4edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㄱㅐ_ㅅㅐ_ㄲㅣ_ㄷㅡㄹ', 0.9999813437461853),\n",
       " ('ㅇㅣ_ㅅㅐ_ㄲㅣ_', 0.999981164932251),\n",
       " ('ㅈㅓ_ㅅㅐ_ㄲㅣ_', 0.999980628490448),\n",
       " ('ㄱㅐ_ㅅㅐ_ㄲㅣ_ㄱㅏ_', 0.9999799728393555),\n",
       " ('ㅅㅐ_ㄲㅣ_', 0.9999778270721436),\n",
       " ('ㅂㅕㅇㅅㅣㄴㅅㅐ_ㄲㅣ_', 0.9999767541885376),\n",
       " ('ㅈㅝ_ㄹㅏ_ㅇㅣ_ㅅㅐ_ㄲㅣ_', 0.9999737739562988),\n",
       " ('ㅂㅠㅇㅅㅣㄴㅅㅐ_ㄲㅣ_', 0.9999736547470093),\n",
       " ('ㅅㅐ_ㄲㅣ_ㄴㅡㄴ', 0.9999733567237854),\n",
       " ('ㅇㅔㅁㅊㅏㅇㅅㅐ_ㄲㅣ_', 0.9999712109565735)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 욕설 같은 경우는 비슷한 형태의 욕설이 나온다.\n",
    "model.wv.most_similar(jamo_split(\"개새끼\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d657313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅆㅣ_ㅂㅏㄹ', 0.9999410510063171),\n",
       " ('ㅇㅏ_ㅈㅣㄱㄲㅏ_ㅈㅣ_', 0.9999346733093262),\n",
       " ('ㅇㅘㅆㄴㅡㄴㄷㅔ_', 0.9999276399612427),\n",
       " ('ㅅㅏ_ㄹㅏㅁㅇㅣ_', 0.9999276399612427),\n",
       " ('ㄱㅏ_ㄹㅡ_ㅊㅣ_ㄴㅡㄴ', 0.9999261498451233),\n",
       " ('ㅇㅣㅆㅇㅡㅁ', 0.9999252557754517),\n",
       " ('ㅂㅕㅇㅅㅣㄴㅇㅣ_', 0.9999247789382935),\n",
       " ('ㄲㅏ_ㅈㅣ_', 0.9999244213104248),\n",
       " ('ㅇㅣㅆㄴㅡㄴㅈㅣ_', 0.9999243021011353),\n",
       " ('ㄷㅐ_ㅎㅏㄴ', 0.999923825263977)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"시발\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78140479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅅㅣ_ㅂㅏㄹ', 0.9999171495437622),\n",
       " ('ㅇㅏㄶㄴㅡㄴ', 0.9999160766601562),\n",
       " ('ㅇㅣ_ㅂㅓㄴㅇㅔ_', 0.9999122023582458),\n",
       " ('ㄱㅓㅅㅇㅣ_', 0.9999105930328369),\n",
       " ('ㅂㅗㄴㅇㅣㄴㅇㅣ_', 0.9999102354049683),\n",
       " ('ㅇㅏㄶㄴㅡㄴㄷㅏ_', 0.9999076128005981),\n",
       " ('ㄴㅗㅁㅇㅣ_', 0.9999071955680847),\n",
       " ('ㅇㅣㅆㅇㅓ_ㅇㅛ_', 0.9999057054519653),\n",
       " ('ㅇㅏ_ㅊㅣㅁㅇㅔ_', 0.9999046325683594),\n",
       " ('ㄱㅏ_ㄹㅡ_ㅊㅣ_ㄴㅡㄴ', 0.9999037981033325)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시발점을 쳤더니.. 아주 관련없는 단어들이 뜬다. 뭐지?\n",
    "model.wv.most_similar(jamo_split(\"시발점\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1145ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅅㅐ_ㄲㅣ_ㄷㅡㄹㄷㅗ_', 0.999988317489624),\n",
       " ('ㅅㅐ_ㄲㅣ_ㄷㅡㄹㅇㅏ_', 0.9999850392341614),\n",
       " ('ㅅㅐ_ㄲㅣ_ㄱㅏ_', 0.9999841451644897),\n",
       " ('ㅂㅕㅇㅅㅣㄴㅅㅐ_ㄲㅣ_', 0.9999820590019226),\n",
       " ('ㅅㅐ_ㄲㅣ_ㄷㅡㄹ', 0.9999803900718689),\n",
       " ('ㅅㅐ_ㄲㅣ_ㄴㅡㄴ', 0.9999796152114868),\n",
       " ('ㄱㅐ_ㅅㅐ_ㄲㅣ_', 0.9999777674674988),\n",
       " ('ㄱㅐ_ㅅㅐ_ㄲㅣ_ㄱㅏ_', 0.9999760389328003),\n",
       " ('ㅅㅐ_ㄲㅣ_ㄷㅡㄹㅇㅣ_', 0.9999759197235107),\n",
       " ('ㅎㅗ_ㄹㅗ_ㅅㅐ_ㄲㅣ_', 0.999975323677063)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"새끼\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fdf2c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅃㅜㄴㅇㅣ_ㅈㅣ_', 0.9999749660491943),\n",
       " ('ㅎㅏ_ㄴㅏ_ㄱㅏ_', 0.9999688863754272),\n",
       " ('ㅇㅣ_ㄹㅏㄴㅇㅣ_', 0.9999685287475586),\n",
       " ('ㅊㅏ_ㄱㅏ_', 0.9999672174453735),\n",
       " ('ㄴㅏ_ㄹㅏ_ㄱㅏ_', 0.9999667406082153),\n",
       " ('ㅎㅏ_ㄴㅏ_', 0.9999665021896362),\n",
       " ('ㅇㅣ_ㄹㅐ_ㅅㅓ_', 0.9999662041664124),\n",
       " ('ㅁㅏㄴㄴㅏ_ㅅㅓ_', 0.9999660849571228),\n",
       " ('ㄸㅏ_ㄹㅏ_', 0.9999660849571228),\n",
       " ('ㅇㅣ_ㄹㅓㄴㅅㅣㄱㅇㅡ_ㄹㅗ_', 0.999965250492096)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"존나\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ad69ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㅈㅣ_ㄹㅏㄹㅎㅏ_ㄴㅔ_', 0.9999675750732422),\n",
       " ('ㅈㅣ_ㄹㅏㄹㄷㅗ_', 0.9999597072601318),\n",
       " ('ㅈㅣ_ㅈㅣ_ㅇㅠㄹㅇㅣ_', 0.9999583959579468),\n",
       " ('ㅇㅓㅄㄷㅏ_ㄴㅡㄴ', 0.9999532103538513),\n",
       " ('ㅎㅏ_ㅈㅣ_', 0.9999531507492065),\n",
       " ('ㅂㅕㅇㅅㅣㄴㅇㅣ_', 0.9999526739120483),\n",
       " ('ㅎㅏ_ㅈㅣ_ㅁㅏㄴ', 0.9999514818191528),\n",
       " ('ㅈㅏ_ㅈㅣ_', 0.9999507069587708),\n",
       " ('ㅈㅣ_ㄷㅣ_ㄱㅔ_ㅇㅣ_', 0.9999504089355469),\n",
       " ('ㅅㅐㅇㄱㅏㄱㄷㅗ_', 0.9999502897262573)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"지랄\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91bd21f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ㄱㅓㄹㄹㅔ_', 0.999894917011261),\n",
       " ('ㅎㅏ_ㄱㅓ_ㄴㅏ_', 0.9998724460601807),\n",
       " ('ㅇㅏ_ㅈㅜㅁㅁㅏ_', 0.999872088432312),\n",
       " ('ㅂㅏ_ㅋㅟ_ㅂㅓㄹㄹㅔ_', 0.9998716711997986),\n",
       " ('ㄷㅏ_ㄴㅣ_ㄴㅡㄴㄷㅔ_', 0.9998692274093628),\n",
       " ('ㅂㅓㄹㅇㅓ_ㅅㅓ_', 0.9998685717582703),\n",
       " ('ㅂㅓㄹㄹㅔ_ㄷㅡㄹ', 0.9998675584793091),\n",
       " ('ㅇㅏ_ㅈㅜ_', 0.9998667240142822),\n",
       " ('ㅇㅗ_ㅈㅣ_ㄱㅔ_', 0.9998656511306763),\n",
       " ('ㄷㅚ_ㄴㅡㄴㄷㅔ_', 0.9998652338981628)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(jamo_split(\"벌레\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27af411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model 저장\n",
    "model.save(\"./gensim_festtext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831539ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd157a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2404a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59b567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6fd32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d407a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d958cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d4c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2b3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d19f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e7d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b123dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b99ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ade9dd94",
   "metadata": {},
   "source": [
    "### 자모 분리하려고 했던 코드식들.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c58d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affce703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jamo in /anaconda/envs/py38_default/lib/python3.8/site-packages (0.4.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb1060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jamos-toolkit in /anaconda/envs/py38_default/lib/python3.8/site-packages (1.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jamos-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "508935ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ㄱㅏㄴㅏㄷㅏㅎㅏㄴㄱㅡㄹ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jamo 패키지 사용해보기 예시\n",
    "\n",
    "from jamo import h2j, j2hcj\n",
    "sample_text = \"가나다한글\"\n",
    "j2hcj(h2j(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc430f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 자모 스플릿 하는 코드\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "CHOSUNGS = [u'ㄱ',u'ㄲ',u'ㄴ',u'ㄷ',u'ㄸ',u'ㄹ',u'ㅁ',u'ㅂ',u'ㅃ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅉ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "JOONGSUNGS = [u'ㅏ',u'ㅐ',u'ㅑ',u'ㅒ',u'ㅓ',u'ㅔ',u'ㅕ',u'ㅖ',u'ㅗ',u'ㅘ',u'ㅙ',u'ㅚ',u'ㅛ',u'ㅜ',u'ㅝ',u'ㅞ',u'ㅟ',u'ㅠ',u'ㅡ',u'ㅢ',u'ㅣ']\n",
    "JONGSUNGS = [u'_',u'ㄱ',u'ㄲ',u'ㄳ',u'ㄴ',u'ㄵ',u'ㄶ',u'ㄷ',u'ㄹ',u'ㄺ',u'ㄻ',u'ㄼ',u'ㄽ',u'ㄾ',u'ㄿ',u'ㅀ',u'ㅁ',u'ㅂ',u'ㅄ',u'ㅅ',u'ㅆ',u'ㅇ',u'ㅈ',u'ㅊ',u'ㅋ',u'ㅌ',u'ㅍ',u'ㅎ']\n",
    "TOTAL = CHOSUNGS + JOONGSUNGS + JONGSUNGS\n",
    "\n",
    "# 자모분리\n",
    "def jamo_split(word, end_char=\"_\"):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for char in word:\n",
    "        \n",
    "        character_code = ord(char)\n",
    "        \n",
    "        if 0xD7A3 < character_code or character_code < 0xAC00:\n",
    "            result.append(char)\n",
    "            continue\n",
    "\n",
    "        chosung_index = int((((character_code - 0xAC00) / 28) / 21) % 19)\n",
    "        joongsung_index = int(((character_code - 0xAC00) / 28) % 21)\n",
    "        jongsung_index = int((character_code - 0xAC00) % 28)\n",
    "        \n",
    "        chosung = CHOSUNGS[chosung_index]\n",
    "        joongsung = JOONGSUNGS[joongsung_index]\n",
    "        jongsung = JONGSUNGS[jongsung_index]\n",
    "        \n",
    "        # 종성 범위 밖에 있는 것들은 end_char로 메꿔준다.\n",
    "        if jongsung_index == 0:\n",
    "            jongsung = end_char\n",
    "        \n",
    "        result.append(chosung)\n",
    "        result.append(joongsung)\n",
    "        result.append(jongsung)\n",
    "\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "# 자모결합\n",
    "def jamo_combine(word):\n",
    "\n",
    "    result = \"\"\n",
    "    index = 0\n",
    "    \n",
    "    while index < len(word):\n",
    "    \n",
    "        # 3개의 char를 보아 글자가 만들어지면 만들고 아니면 1개의 char만 추가한다.\n",
    "        try:\n",
    "            cho = CHOSUNGS.index(word[index]) * 21 * 28\n",
    "            joong = JOONGSUNGS.index(word[index+1]) * 28\n",
    "            jong = JONGSUNGS.index(word[index+2])\n",
    "\n",
    "            result += chr(cho + joong + jong + 0xAC00) \n",
    "            index += 3\n",
    "\n",
    "        except:\n",
    "            result += word[index]\n",
    "            index += 1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85244ed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_be_divided\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/frame.py:8833\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8822\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8824\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   8825\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8826\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8831\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   8832\u001b[0m )\n\u001b[0;32m-> 8833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mto_be_divided\u001b[0;34m(korean_word)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m####################################\u001b[39;00m\n\u001b[1;32m     16\u001b[0m r_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mkorean_word\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mw\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m힣\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     19\u001b[0m         ch1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mord\u001b[39m(w) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m588\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5581\u001b[0m ):\n\u001b[1;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "tmp.apply(to_be_divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "125f62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "문장       object\n",
       "혐오 여부     int64\n",
       "글자수       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8338f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e37230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2355cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 음절을 넘파이 배열로 바꾸기\n",
    "# chr() 함수는 유니코드 번호를 받아서 해당하는 문자를 반환하는 함수 --> '가'에 해당하는 유니코드인 44032를 chr()에 넣으면 '가'가 반환\n",
    "# ord() 함수는 문자를 받아서 대응하는 유니코드 번호를 반환 --> ord('가')를 치면 44032가 반환\n",
    "\n",
    "\n",
    "\n",
    "syllables = np.array([chr(code) for code in range(44032, 55204)])\n",
    "syllables = syllables.reshape(19, 21, 28)\n",
    "\n",
    "# .... 이 패키지는 말을 직접 언급해줘야 하나보다 ㅜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "초성의 인덱스 : (문자 - 0xAC00) / 21 / 28\n",
    "중성의 인덱스 : (문자 - 0xAC00 - (초성 인덱스 * 21 * 28)) / 28 \n",
    "종성의 인덱스 : (문자 - 0xAC00 - (초성 인덱스 * 21 * 28) - (중성 인덱스 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5158cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 초·중·종성 분리 --> 일부러 오타를 내어 비속어를 변형한 경우에도 비속어를 판별 할 수 있도록 한다\n",
    "\n",
    "\n",
    "def run(x):\n",
    "    consonant_list = [ord(char) for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"] #초성 유니코드 리스트\n",
    "    choseong_list = [char for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"] #초성리스트\n",
    "    jungseong_list = [char for char in \"ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\"] #중성 리스트\n",
    "    jongseong_list = [char for char in \"-ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\"] #종성 리스트\n",
    "    result = []\n",
    "    \n",
    "    for char in x:\n",
    "        if ord(char)==32: #띄어쓰기인 경우\n",
    "            result.append(char)\n",
    "            \n",
    "        elif 48<=ord(char)<=57: #숫자인 경우\n",
    "            result.append(char)\n",
    "            \n",
    "        elif consonant_list.count(char) == 0:\n",
    "            character_code = ord(char)\n",
    "            \n",
    "        if (55203 < character_code or character_code < 44032):\n",
    "            continue \n",
    "            \n",
    "            code = 44032\n",
    "            choseong_index = (character_code - code) // 21 // 28\n",
    "            jungseong_index = (character_code - code - (choseong_index * 21 *  28)) // 28\n",
    "            jongseong_index = character_code - code - (choseong_index * 21 * 28) - (jungseong_index * 28)\n",
    "            result.append(choseong_list[choseong_index])\n",
    "            result.append(jungseong_list[jungseong_index])\n",
    "            result.append(jongseong_list[jongseong_index])\n",
    "            \n",
    "        else:\n",
    "            choseong_index = consonant_list.index(ord(char))\n",
    "            result.append(choseong_list[choseong_index])\n",
    "            result.append(\"-\")\n",
    "            result.append(\"-\")\n",
    "        return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e244f3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "51340 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 각 문장을 jamo_split하여 저장\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#from JamoSplit import jamo_split, jamo_combine\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m댓글\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/anaconda/envs/check_up_py38_PT_TF/lib/python3.8/site-packages/pandas/core/series.py:4213\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4212\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 4213\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], Series):\n\u001b[1;32m   4216\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   4217\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd\u001b[38;5;241m.\u001b[39marray(mapped), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2403\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 각 문장을 jamo_split하여 저장\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#from JamoSplit import jamo_split, jamo_combine\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m댓글\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     30\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(jongseong_list[jongseong_index])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     choseong_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsonant_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(choseong_list[choseong_index])\n\u001b[1;32m     35\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 51340 is not in list"
     ]
    }
   ],
   "source": [
    "# 각 문장을 jamo_split하여 저장\n",
    "#from JamoSplit import jamo_split, jamo_combine\n",
    "tmp.loc[:,'댓글'] = tmp.loc[:,'댓글'].apply(lambda x: run(x))\n",
    "tmp.loc[:,'댓글'] = tmp.loc[:,'댓글'].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482e1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f0372d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JamosSeparator():\n",
    "    def __init__(self, string):\n",
    "        self.string = string\n",
    "        self.result = []\n",
    "        self.choseong_list = [char for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"]\n",
    "        self.jungseong_list = [char for char in \"ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\"]\n",
    "        self.jongseong_list = [char for char in \" ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\"]\n",
    "\n",
    "    def run(self):\n",
    "        for char in self.string:\n",
    "\n",
    "            character_code = ord(char)\n",
    "\n",
    "            # Do not process unless it is in Hangul syllables range.\n",
    "            if 0xD7A3 < character_code or character_code < 0xAC00:\n",
    "                continue\n",
    "\n",
    "            choseong_index = (character_code - 0xAC00) // 21 // 28\n",
    "            jungseong_index = (character_code - 0xAC00 - (choseong_index * 21 * 28)) // 28\n",
    "            jongseong_index = character_code - 0xAC00 - (choseong_index * 21 * 28) - (jungseong_index * 28)\n",
    "\n",
    "            self.result.append(self.choseong_list[choseong_index])\n",
    "            self.result.append(self.jungseong_list[jungseong_index])\n",
    "            self.result.append(self.jongseong_list[jongseong_index])\n",
    "            self.result.append(\"_\")\n",
    "\n",
    "    def get(self):\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d26425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a5cb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_be_divided(korean_word):\n",
    "    \"\"\"\n",
    "    한글 단어를 입력받아서 초성/중성/종성을 구분하여 리턴해줍니다. \n",
    "    \"\"\"\n",
    "    ####################################\n",
    "    # 초성 리스트. 00 ~ 18\n",
    "    CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ',\n",
    "                    'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    # 중성 리스트. 00 ~ 20\n",
    "    JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ',\n",
    "                     'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    # 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "    JONGSUNG_LIST = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ',\n",
    "                     'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    ####################################\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        if '가'<=w<='힣':\n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6443bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c006203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JamoUtils:\n",
    "    CHOSUNG = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ',\n",
    "                    'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    JUNGSUNG = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ',\n",
    "                    'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    JONGSUNG = ['', 'ㄱ', 'ㄲ', 'ᆪ', 'ᆫ', 'ᆬ', 'ᆭ', 'ㄷ',\n",
    "                    'ㄹ', 'ᆰ', 'ᆱ', 'ᆲ', 'ᆳ', 'ᆴ', 'ᆵ', 'ᆶ', 'ㅁ', 'ㅂ', 'ᆹ', 'ᆺ', 'ᆻ', 'ᆼ',\n",
    "                    'ᆽ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "#     def __init__(self):\n",
    "#         raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def split_one(target):\n",
    "        code_point = ord(target)\n",
    "        if 0xAC00 <= code_point <= 0xD79D:\n",
    "            start_value = ord(target[0]) - 0xAC00\n",
    "            jong = start_value % 28\n",
    "            jung = int(((start_value - jong) / 28) % 21)\n",
    "            cho = int((((start_value - jong) / 28) - jung) / 21)\n",
    "\n",
    "            return JamoUtils.CHOSUNG[cho], JamoUtils.JUNGSUNG[jung], JamoUtils.JONGSUNG[jong]\n",
    "\n",
    "        return target, '', ''\n",
    "\n",
    "    @staticmethod\n",
    "    def split(target):\n",
    "        result = []\n",
    "        for c in target:\n",
    "            result.append(JamoUtils.split_one(c))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b00840",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = np.array([chr(code) for code in range(44032, 55204)])\n",
    "syllables = syllables.reshape(19, 21, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "946cb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 바꾼 코드\n",
    "\n",
    "def run(x):\n",
    "    consonant_list = [ord(char) for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"] #초성 유니코드 리스트\n",
    "    choseong_list = [char for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"] #초성리스트\n",
    "    jungseong_list = [char for char in \"ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\"] #중성 리스트\n",
    "    jongseong_list = [char for char in \"-ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\"] #종성 리스트\n",
    "    result = []\n",
    "    \n",
    "    for char in x:\n",
    "        if ord(char)==32: #띄어쓰기인 경우\n",
    "            result.append(char)\n",
    "            \n",
    "        elif 48<=ord(char)<=57: #숫자인 경우\n",
    "            result.append(char)\n",
    "            \n",
    "        elif consonant_list.count(char) == 0:\n",
    "            character_code = ord(char)\n",
    "            \n",
    "        if 0xD7A3 < character_code or character_code < 0xAC00:\n",
    "            continue\n",
    "            \n",
    "            choseong_index = (character_code - 0xAC00) // 21 // 28\n",
    "            jungseong_index = (character_code - 0xAC00 - (choseong_index * 21 * 28)) // 28\n",
    "            jongseong_index = character_code - 0xAC00 - (choseong_index * 21 * 28) - (jungseong_index * 28)\n",
    "            \n",
    "            result.append(choseong_list[choseong_index])\n",
    "            result.append(jungseong_list[jungseong_index])\n",
    "            result.append(jongseong_list[jongseong_index])\n",
    "            \n",
    "        else:\n",
    "            choseong_index = consonant_list.index(ord(char))\n",
    "            result.append(choseong_list[choseong_index])\n",
    "            result.append(\"-\")\n",
    "            result.append(\"-\")\n",
    "        return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "16e68bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 고친것 2\n",
    "\n",
    "def to_be_divided(korean_word):\n",
    "    \"\"\"\n",
    "    한글 단어를 입력받아서 초성/중성/종성을 구분하여 리턴해줍니다. \n",
    "    \"\"\"\n",
    "    # 초성 유니코드 리스트\n",
    "    consonant_list = [ord(char) for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"] #초성 유니코드 리스트\n",
    "    \n",
    "    ####################################\n",
    "    # 초성 리스트. 00 ~ 18\n",
    "    choseong_list = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ',\n",
    "                    'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    # 중성 리스트. 00 ~ 20\n",
    "    jungseong_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ',\n",
    "                     'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    # 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "    jongseong_list = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ',\n",
    "                     'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    ####################################\n",
    "    \n",
    "    r_lst = []\n",
    "    for char in list(korean_word.strip()):\n",
    "        if '가'<=char<='힣':\n",
    "            ch1 = (ord(char) - ord('가')) // 588\n",
    "            ch2 = ((ord(char) - ord('가')) - (588 * ch1)) // 28\n",
    "            ch3 = (ord(char) - ord('가')) - (588 * ch1) - ch2 * 28\n",
    "            \n",
    "            r_lst.append(choseong_list[ch1])\n",
    "            r_lst.append(jungseong_list[ch2])\n",
    "            r_lst.append(jongseong_list[ch3])\n",
    "            \n",
    "        else:\n",
    "            choseong_index = consonant_list.index(ord(char))\n",
    "            r_lst.append(choseong_list[choseong_index])\n",
    "            r_lst.append(\"-\")\n",
    "            r_lst.append(\"-\")\n",
    "        return \"\".join(r_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a50323f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp7 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "19c80e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "49 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [169]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp7[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m문장\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtmp7\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m문장\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_be_divided\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36mto_be_divided\u001b[0;34m(korean_word)\u001b[0m\n\u001b[1;32m     31\u001b[0m     r_lst\u001b[38;5;241m.\u001b[39mappend(jongseong_list[ch3])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     choseong_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsonant_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     r_lst\u001b[38;5;241m.\u001b[39mappend(choseong_list[choseong_index])\n\u001b[1;32m     36\u001b[0m     r_lst\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 49 is not in list"
     ]
    }
   ],
   "source": [
    "tmp7['문장'] = tmp7['문장'].apply(to_be_divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2463c4ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [165]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mord\u001b[39m(\u001b[43mss\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "ord(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fa948cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51221"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941db69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075ec74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f859c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from jamo import h2j, j2hcj #초성/중성/종성분리\n",
    "\n",
    "\n",
    "f = open(\"./stopwords-ko.txt\", 'r', encoding=\"utf-8\")\n",
    "lines = f.readlines()\n",
    "stopwords = []\n",
    "for line in lines:\n",
    "    line = line.replace('\\n', '')\n",
    "    stopwords.append(line)\n",
    "f.close()   \n",
    "\n",
    "class c_token:    \n",
    "# 불용어 파일 불러오기 ==> 밖에서 지정해저야 오류 안생김                         \n",
    "         \n",
    "# 1 + 2 + stopword 그냥 다 합치기!\n",
    "    def preprocessing(self, input_str):\n",
    "    # 문자만 필터링\n",
    "        re_string = re.compile('[^ A-Za-z0-9ㄱ-ㅣ가-힣]+')\\\n",
    "            .sub('', input_str)\n",
    "    #형태소단위 \n",
    "        okt = Okt() #선택이유는 논문 참고\n",
    "        m_token = okt.morphs(re_string, stem=True)                                \n",
    "    # 초중성분리  ==> 너무 작게 쪼개져서 주석처리!!\n",
    "        # cm_token = []\n",
    "        # for i in m_token:\n",
    "        #     cm_token.append( j2hcj(h2j(i)) )\n",
    "    # 불용어 처리\n",
    "        result = [token for token in m_token if token not in stopwords]\n",
    "        preprocessed_text= ' '.join(result)\n",
    "        \n",
    "        return preprocessed_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1.문자만 필터링(이모티콘제외) & stopword(불용어)\n",
    "    def filter_str(self, input_str):\n",
    "        re_string = re.compile('[^ A-Za-z0-9ㄱ-ㅣ가-힣]+').sub('', input_str)\n",
    "        return print(re_string)\n",
    "\n",
    "# 2. \n",
    "# 2-1.텍스트를 형태소 단위로 나눔\n",
    "# norm(정규화),stem(어간추출) 기본값 False\n",
    "    def m_tokenize(self, input_str):\n",
    "        okt = Okt()\n",
    "        m_token = okt.morphs(self.filter_str(input_str))\n",
    "        return print(m_token)\n",
    "#2-2. 초성/중성/종성분리\n",
    "    def c_tokenize(self, input_str):\n",
    "        c_token = j2hcj(h2j(self.filter_str(input_str)))\n",
    "        return list(c_token)\n",
    "\n",
    "# 형태소단위분리 & 초중종성분리\n",
    "    def cm_tokenize(self, input_str):\n",
    "        okt = Okt()\n",
    "        mm_token = okt.morphs(self.filter_str(input_str))\n",
    "        cm_token = []\n",
    "        for i in mm_token:\n",
    "            cm_token.append(self.c_tokenize(i))\n",
    "        return cm_token\n",
    "\n",
    "# 4.텍스트에서 명사만 ==> 워드클라우드 \n",
    "# join(형태소/품사 설명) 기본값 False\n",
    "    def noun_tokenize(self, input_str):\n",
    "        okt = Okt()\n",
    "        token = okt.nouns(self.filter_str(input_str))\n",
    "        return token\n",
    "\n",
    "# 테스트하기\n",
    "# cl = c_token()\n",
    "# test = \"제품은 좋을수도 있고 나쁠수도 있는데 그걸 고객들을 속이려고 하고 심지어 사과도 안하고 양심도없지\"\n",
    "# result = cl.preprocessing(test)\n",
    "# print(result)\n",
    "# # ==> 제품 좋다 있다 나쁘다 있다 그걸 고객 속이다 하다 심지어 사과 하고 양심 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2f8f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ddf = pd.read_csv('./hate_speech_data_womad.csv', index_col=0)\n",
    "ddf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149122d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>혐오 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지금 어디 계세요?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>한국 시간에 시계 맞췄어?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>햄버거 두 개랑 콜라 주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>우리는 밤새 춤추고 노래했다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>무엇보다도, 스트레스를 줄이는 것이 중요합니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>개독냄새 나노 ㅋㅋㅋ조팔 개오글</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>사실상 페미니즘 영업사원 아니노 ㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>아버지는 아침 일찍 서울로 가셨다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>과천에 있는 국립박물관 가 봤어?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              문장  혐오 여부\n",
       "0                     지금 어디 계세요?      0\n",
       "1                 한국 시간에 시계 맞췄어?      0\n",
       "2               햄버거 두 개랑 콜라 주세요.      0\n",
       "3               우리는 밤새 춤추고 노래했다.      0\n",
       "4     무엇보다도, 스트레스를 줄이는 것이 중요합니다.      0\n",
       "...                          ...    ...\n",
       "1995           개독냄새 나노 ㅋㅋㅋ조팔 개오글      1\n",
       "1996     사실상 페미니즘 영업사원 아니노 ㅋㅋㅋㅋ       1\n",
       "1997                     ㅋㅋㅋㅋㅋㅋㅋ      1\n",
       "1998         아버지는 아침 일찍 서울로 가셨다.      0\n",
       "1999          과천에 있는 국립박물관 가 봤어?      0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316664d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "check_up_py38_PT_TF",
   "language": "python",
   "name": "conda-env-check_up_py38_PT_TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
