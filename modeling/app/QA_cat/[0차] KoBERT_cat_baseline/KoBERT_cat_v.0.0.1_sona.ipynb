{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff032c8",
   "metadata": {},
   "source": [
    "# 0. 들어가기 앞서\n",
    "\n",
    "* 'AS':0, '주문':1, '배송':2, '업무처리':3, '교환':4, '반품':5, '결제':6\n",
    "* 참고: https://velog.io/@seolini43/KOBERT%EB%A1%9C-%EB%8B%A4%EC%A4%91-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-%ED%8C%8C%EC%9D%B4%EC%8D%ACColab\n",
    "\n",
    "* 한국어언어모델 다양하게 사용해보기 : https://littlefoxdiary.tistory.com/81"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6590be",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fef1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gluonnlp\n",
    "# !pip install mxnet\n",
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14ce184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /anaconda/envs/version_test_azureml_py38/lib/python3.8/site-packages (1.22.3)\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c03f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f00e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27195632",
   "metadata": {},
   "source": [
    "# 2. 모델, 사전, 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d08d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_cat_baseline/.cache/kobert_v1.zip\n",
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_cat_baseline/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4d31c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '질의응답_K쇼핑_질문유형분류_원본.csv',\n",
       " '[0차] 원본데이터_preprocessing.ipynb',\n",
       " '질의응답_K쇼핑_질문분류_원본.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../[0차] 원본_preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0662872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../[0차] 원본_preprocessing/질의응답_K쇼핑_질문유형분류_원본.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2f3112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934121</th>\n",
       "      <td>그때 방송을 늦게 봐가지고 좀 설명 듣고 주문하고 싶거든요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501430</th>\n",
       "      <td>경기도 양평군 ㅇㅇㅇ ㅇㅇ ㅇㅇ 아파트 ㅇㅇㅇ동 ㅇㅇㅇ호 예요 이건 아까 자동 주...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341599</th>\n",
       "      <td>아 죄송한데 맞교환 좀 해주시면 안 될까요? 여름이 다 지나갈 것 같은데 못 입으면...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492669</th>\n",
       "      <td>그거를 자동으로 주문하는데 계속 안 되네요. 우리 아들한테 좀 부칠려고 하는데 어떻...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938096</th>\n",
       "      <td>물기는 안 생겨요?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725641</th>\n",
       "      <td>아 그럼 다시 휴대폰으로 주문할까요?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705619</th>\n",
       "      <td>아 무통장 입금 할게요.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28784</th>\n",
       "      <td>아 그러면 무통장 신한 은행  이걸로 되어 있는데  맞나요?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402363</th>\n",
       "      <td>그러면  맞교환이 되는 겁니까?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697065</th>\n",
       "      <td>네. 그런데 이 종은 반품을 하신다고요?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      msg  cat\n",
       "934121                  그때 방송을 늦게 봐가지고 좀 설명 듣고 주문하고 싶거든요.    1\n",
       "501430   경기도 양평군 ㅇㅇㅇ ㅇㅇ ㅇㅇ 아파트 ㅇㅇㅇ동 ㅇㅇㅇ호 예요 이건 아까 자동 주...    2\n",
       "341599  아 죄송한데 맞교환 좀 해주시면 안 될까요? 여름이 다 지나갈 것 같은데 못 입으면...    4\n",
       "492669  그거를 자동으로 주문하는데 계속 안 되네요. 우리 아들한테 좀 부칠려고 하는데 어떻...    2\n",
       "938096                                         물기는 안 생겨요?    1\n",
       "725641                              아 그럼 다시 휴대폰으로 주문할까요?     3\n",
       "705619                                      아 무통장 입금 할게요.    3\n",
       "28784                  아 그러면 무통장 신한 은행  이걸로 되어 있는데  맞나요?     6\n",
       "402363                                 그러면  맞교환이 되는 겁니까?     5\n",
       "697065                             네. 그런데 이 종은 반품을 하신다고요?    3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68210ad6",
   "metadata": {},
   "source": [
    "# 3. 질문유형 분류 시작\n",
    "\n",
    "* 'AS':0, '주문':1, '배송':2, '업무처리':3, '교환':4, '반품':5, '결제':6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7182b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2중 리스트로 변환됨\n",
    "\n",
    "data_list = []\n",
    "for q, label in zip(df[\"msg\"],df[\"cat\"])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ae42c",
   "metadata": {},
   "source": [
    "## 3-1. Train / Test set 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3766de",
   "metadata": {},
   "source": [
    "* 라벨링은 이미 진행했으므로, 바로 train/ test 분리 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "189c8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20346a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70761\n",
      "23588\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba4b04",
   "metadata": {},
   "source": [
    "## 3-2. KoBERT 입력 데이터로 만들기\n",
    "\n",
    "* 데이터를 train data와 test data로 나누었다면 각 데이터가 KoBERT 모델의 입력으로 들어갈 수 있는 형태가 되도록 토큰화, 정수 인코딩, 패딩 등을 해주어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "325540ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f60101ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "\n",
    "max_len = 64 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d51a085",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_cat_baseline/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "tokenizer= get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38a513a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 3990, 7835, 2123, 5859, 3135, 4926, 4064, 5330, 3135,  517,\n",
       "        6989, 5761, 6999,  517,   54,    3,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
       " array(17, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째는 패딩된 시퀀스\n",
    "# 두 번째는 길이와 타입에 대한 내용\n",
    "# 세 번재는 어텐션 마스크 시퀀스\n",
    "\n",
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd75b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a46aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch용 DataLoader 사용(torch 형식의 dataset을 만들어주기)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1b0fb",
   "metadata": {},
   "source": [
    "## 3-3. KoBERT 학습모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6cc27",
   "metadata": {},
   "source": [
    "* 'AS':0, 주문':1, '배송':2, '업무처리':3, '교환':4, '반품':5, '결제':6\n",
    "* 7가지의 class를 분류하기 때문에 num_classes는 7으로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ba1174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b75d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee52fb4",
   "metadata": {},
   "source": [
    "## 3-4. KoBERT 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1f3486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20597/2673822008.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbe66a3576f4804bee023d7e8c133f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 2.0365653038024902 train acc 0.140625\n",
      "epoch 1 batch id 201 loss 1.7634984254837036 train acc 0.23227611940298507\n",
      "epoch 1 batch id 401 loss 1.3957653045654297 train acc 0.3008494389027431\n",
      "epoch 1 batch id 601 loss 1.6216471195220947 train acc 0.3336366472545757\n",
      "epoch 1 batch id 801 loss 1.5650694370269775 train acc 0.3514942259675406\n",
      "epoch 1 batch id 1001 loss 1.303082823753357 train acc 0.36432317682317683\n",
      "epoch 1 train acc 0.36994546101089404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20597/2673822008.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c6bfadcb30418f8919d51c099f2239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.42388399578440233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af0f3273f1843629138c3084a24c1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 1.4395208358764648 train acc 0.359375\n",
      "epoch 2 batch id 201 loss 1.4817689657211304 train acc 0.4133240049751244\n",
      "epoch 2 batch id 401 loss 1.299129605293274 train acc 0.4251480673316708\n",
      "epoch 2 batch id 601 loss 1.488411784172058 train acc 0.4341202163061564\n",
      "epoch 2 batch id 801 loss 1.3585363626480103 train acc 0.4370708489388265\n",
      "epoch 2 batch id 1001 loss 1.1784110069274902 train acc 0.44183941058941056\n",
      "epoch 2 train acc 0.4449906689674944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22219d44746b4dcd81da6fa51864e93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.4485800587172538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977b3f84dde4410cbfe299288b5db339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 1.3924497365951538 train acc 0.421875\n",
      "epoch 3 batch id 201 loss 1.350772738456726 train acc 0.4601990049751244\n",
      "epoch 3 batch id 401 loss 1.21504807472229 train acc 0.47178927680798005\n",
      "epoch 3 batch id 601 loss 1.3864129781723022 train acc 0.4797992928452579\n",
      "epoch 3 batch id 801 loss 1.2582433223724365 train acc 0.4832826154806492\n",
      "epoch 3 batch id 1001 loss 1.1001523733139038 train acc 0.4889485514485514\n",
      "epoch 3 train acc 0.49229121642482243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab3166e608b400690e873869e9ee6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.45304031165311653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8194e0e9c57a433e8f19dde7aa406767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 1.3216768503189087 train acc 0.390625\n",
      "epoch 4 batch id 201 loss 1.1411126852035522 train acc 0.5119713930348259\n",
      "epoch 4 batch id 401 loss 1.1721765995025635 train acc 0.524002493765586\n",
      "epoch 4 batch id 601 loss 1.3821669816970825 train acc 0.5326799084858569\n",
      "epoch 4 batch id 801 loss 1.08504319190979 train acc 0.5357950998751561\n",
      "epoch 4 batch id 1001 loss 1.0340642929077148 train acc 0.5406468531468531\n",
      "epoch 4 train acc 0.5435271302871256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c806daa4c7ca4040b1b2db174b625960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.45825805480277026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d6adb69eff453492fb9a03313e5ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 1.1848827600479126 train acc 0.484375\n",
      "epoch 5 batch id 201 loss 1.0970348119735718 train acc 0.5651430348258707\n",
      "epoch 5 batch id 401 loss 1.0938646793365479 train acc 0.5737998753117207\n",
      "epoch 5 batch id 601 loss 1.1241867542266846 train acc 0.5795549084858569\n",
      "epoch 5 batch id 801 loss 1.0084482431411743 train acc 0.5792759051186017\n",
      "epoch 5 batch id 1001 loss 1.0068126916885376 train acc 0.5811376123876124\n",
      "epoch 5 train acc 0.582351185881886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb5ca6c09234dc5b68cd3511832d3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.45754761367058117\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee8b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "#모델의 형태를 포함하여 저장하기\n",
    "torch.save(model, 'KoBERT_cat_v.0.0.1_sona.pth')\n",
    "\n",
    "#불러오기\n",
    "# model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf52910",
   "metadata": {},
   "source": [
    "## 3-5.새로운 문장 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6470ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/adminuser/notebooks/modeling/question/[0차] KoBERT_cat_baseline/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            # 'AS':0, '주문':1, '배송':2, '업무처리':3, '교환':4, '반품':5, '결제':6\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"AS\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"주문\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"배송\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"업무처리\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"교환\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"반품\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"결제\")\n",
    "\n",
    "        print(\">> 입력하신 질문은 \" + test_eval[0] + \"유형이라고 판단됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02a6d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 : 라지사이즈는 몇 cm인가요?\n",
      ">> 입력하신 질문은 주문유형이라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 바꿔줄수있나요?\n",
      ">> 입력하신 질문은 배송유형이라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 어떻게 고치나요?\n",
      ">> 입력하신 질문은 업무처리유형이라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 환불되나요\n",
      ">> 입력하신 질문은 반품유형이라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 카드취소해주세요\n",
      ">> 입력하신 질문은 배송유형이라고 판단됩니다.\n",
      "\n",
      "\n",
      "하고싶은 말을 입력해주세요 : 서비스는 센터 번호는 뭔가요?\n",
      ">> 입력하신 질문은 배송유형이라고 판단됩니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m :\n\u001b[0;32m----> 3\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m하고싶은 말을 입력해주세요 : \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentence \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/version_test_azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/version_test_azureml_py38/lib/python3.8/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == 0 :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "version_test_azureml_py38",
   "language": "python",
   "name": "conda-env-version_test_azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
