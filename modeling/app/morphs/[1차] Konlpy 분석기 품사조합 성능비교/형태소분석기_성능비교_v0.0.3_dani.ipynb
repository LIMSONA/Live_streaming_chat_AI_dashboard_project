{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cb322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge jpype1==1.1\n",
    "# conda install konlpy\n",
    "# pip install konlpy 자바나 jpype 설치 필요없음\n",
    "# nltk.download('punkt')\n",
    "# conda install matplotlib\n",
    "# import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346b0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 사용 가능한지 테스트\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib.rcParams['axes.edgecolor'] = \"black\"\n",
    "# matplotlib.rcParams['axes.facecolor'] = \"white\"\n",
    "\n",
    "# plt.plot([\"Seoul\",\"Paris\",\"Seattle\"], [30,25,55])\n",
    "# plt.xlabel('City')\n",
    "# plt.ylabel('Response')\n",
    "# plt.title('Experiment Result')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4ed89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from random import seed\n",
    "from random import randint\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d06534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa868b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('naver_shopping.txt', sep = \"\\t\", header = None)\n",
    "df = df.sample(frac=0.1)   # 학습시간때문에 10% 만 사용함\n",
    "df.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f92afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if rate < 3 else 1 for rate in df.label] # 3점 미만이면 0(부정), 3점 초과이면 1(긍정)으로 라벨 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250 3750 5000\n",
      "11250 3750 5000\n"
     ]
    }
   ],
   "source": [
    "#평가 데이터셋 분리\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df['text'].tolist(), y, random_state=0)\n",
    "\n",
    "#학습, 검증 데이터셋분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=0)\n",
    "\n",
    "print(len(X_train), len(X_val), len(X_test))\n",
    "print(len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d6afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_txt = randint(0, len(X_train))\n",
    "\n",
    "# print('형태소 단위로 tokenize: ', okt.morphs(X_train[random_txt]))\n",
    "# print('명사만 추출: ', okt.nouns(X_train[random_txt]))\n",
    "\n",
    "# # morphs(text) : 텍스트에서 형태소를 반환한다\n",
    "# # nouns(text) : 텍스트에서 명사를 반환한다\n",
    "# # phrases(text) : 텍스트에서 어절을 뽑아낸다\n",
    "# # pos(text) : 텍스트에서 품사 정보를 부착하여 반환한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5181f95",
   "metadata": {},
   "source": [
    "### 크롤링된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd68db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "forders = os.listdir('/home/adminuser/notebooks/modeling/raw_data/crawling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb14795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(forders)):\n",
    "    if forders[i].split('.')[1] == 'csv':\n",
    "        file = '/home/adminuser/notebooks/modeling/raw_data/crawling/'+forders[i]\n",
    "        df= pd.read_csv(file,encoding='utf-8') \n",
    "        df_all = pd.concat([df_all, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61b855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07203588",
   "metadata": {},
   "source": [
    "### Okt 명사만 사용 (tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f211097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf1 = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "# min_df: 최소 빈도값을 설정\n",
    "# DF는 특정 단어가 나타나는 '문서의 수'를 의미\n",
    "# (단어 'home'의 경우 전체 문서에서 빈도는 4번 이지만,'home'이라는 단어가 포함된 문서의 수는 3개이기 때문에 DF = 3 )\n",
    "# DF의 최소값을 설정하여 해당 값보다 작은 DF를 가진 단어들은 단어사전 (vocabulary_)에서 제외하고, 인덱스를 부여하지 않음\n",
    "# 최소 DF가 5로 설정되었으니, 1,2,3,4인 것들은 모두 탈락하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16928df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf1.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b95a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f72e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_df_vectorizer = TfidfVectorizer(min_df = 2)\n",
    "# min_df_vectorizer.fit(text)\n",
    "# sorted(min_df_vectorizer.vocabulary_.items())\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sorted(X_train_tfidf.vocabulary_.items())\n",
    "# print(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04afbadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(max_iter=1000)\n",
    "results1= clf1.fit(X_train_tfidf, y_train)\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4be8484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.820\n",
      "#Test set score: 0.767\n"
     ]
    }
   ],
   "source": [
    "# train data 예측 정확도\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
    "# test data 예측 정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd707cd",
   "metadata": {},
   "source": [
    "### Okt 명사, 동사, 형용사를 사용 (tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3955e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text):\n",
    "    target_tags = ['None', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "538d2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8cd461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_twit = tfidf2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e44b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf_twit = tfidf2.transform(X_test)   \n",
    "\n",
    "#fit 하지 않는다!! (참고: https://deepinsight.tistory.com/165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea7039a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "results2 = clf2.fit(X_train_tfidf_twit, y_train)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72b3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.843\n",
      "#Test set score: 0.827\n"
     ]
    }
   ],
   "source": [
    "# train data 예측 정확도\n",
    "print('#Train set score: {:.3f}'.format(clf2.score(X_train_tfidf_twit, y_train)))\n",
    "# test data 예측 정확도\n",
    "print('#Test set score: {:.3f}'.format(clf2.score(X_test_tfidf_twit, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9061c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "530c7329",
   "metadata": {},
   "source": [
    "### sample data에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b15d6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp= df_all.sample(10)\n",
    "tmp[\"regrex\"]=tmp.comment.map(lambda x : re.compile('[^ A-Za-z0-9ㄱ-ㅣ가-힣]+').sub('', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86b6904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_txt_tfidf = tfidf1.transform(tmp['regrex'])\n",
    "clf1.predict(random_txt_tfidf)\n",
    "\n",
    "pred1 = pd.DataFrame({'clf1_label': clf1.predict(random_txt_tfidf)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c04733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_txt_tfidf_twit = tfidf2.transform(tmp['regrex']) #분석기 넘버 맞추기\n",
    "clf2.predict(random_txt_tfidf_twit)\n",
    "\n",
    "pred2 = pd.DataFrame({'clf2_label': clf2.predict(random_txt_tfidf_twit)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76485f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_compare = pd.concat([pred1, pred2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8e5e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_compare['comment'] = tmp.comment.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9da2fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1_label</th>\n",
       "      <th>clf2_label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>크</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>돌돌 말아서 보관 가능한가요?????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>추카드려요♡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>오히려 거리두기 끝난 요즘이 더 위험한거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>굿모닝 입니다 잠시왔어요^^🤗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>미세먼지땜에 마스크 해야되요 ㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022050229035281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>성인 중형은 라이브혜택 포함 안되나용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>안녕하세요~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㅋ시상자가 더씬난</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf1_label  clf2_label                     comment\n",
       "0           1           0                           크\n",
       "1           1           0        돌돌 말아서 보관 가능한가요?????\n",
       "2           1           1                      추카드려요♡\n",
       "3           1           0  오히려 거리두기 끝난 요즘이 더 위험한거 같아요\n",
       "4           1           0            굿모닝 입니다 잠시왔어요^^🤗\n",
       "5           1           0           미세먼지땜에 마스크 해야되요 ㅎ\n",
       "6           1           0            2022050229035281\n",
       "7           0           0        성인 중형은 라이브혜택 포함 안되나용\n",
       "8           1           0                      안녕하세요~\n",
       "9           1           0             ㅋㅋㅋㅋㅋㅋㅋ시상자가 더씬난"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e474b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('sample_file.txt', 'r')\n",
    "# sentence = f.read()\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4eab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('형태소:', t.morphs(sentence))\n",
    "# print('명사:', t.nouns(sentence))\n",
    "# print('품사 태깅 결과:', t.pos(sentence))\n",
    "\n",
    "# tokens_const = t.morphs(sentence)\n",
    "# print('토큰의 수:', len(tokens_const))\n",
    "# print(tokens_const[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "version_test_azureml_py38",
   "language": "python",
   "name": "conda-env-version_test_azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
