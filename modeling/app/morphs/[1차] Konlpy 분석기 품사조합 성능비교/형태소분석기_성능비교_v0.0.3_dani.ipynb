{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cb322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge jpype1==1.1\n",
    "# conda install konlpy\n",
    "# pip install konlpy ìë°”ë‚˜ jpype ì„¤ì¹˜ í•„ìš”ì—†ìŒ\n",
    "# nltk.download('punkt')\n",
    "# conda install matplotlib\n",
    "# import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346b0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib ì‚¬ìš© ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib.rcParams['axes.edgecolor'] = \"black\"\n",
    "# matplotlib.rcParams['axes.facecolor'] = \"white\"\n",
    "\n",
    "# plt.plot([\"Seoul\",\"Paris\",\"Seattle\"], [30,25,55])\n",
    "# plt.xlabel('City')\n",
    "# plt.ylabel('Response')\n",
    "# plt.title('Experiment Result')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4ed89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from random import seed\n",
    "from random import randint\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d06534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa868b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('naver_shopping.txt', sep = \"\\t\", header = None)\n",
    "df = df.sample(frac=0.1)   # í•™ìŠµì‹œê°„ë•Œë¬¸ì— 10% ë§Œ ì‚¬ìš©í•¨\n",
    "df.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f92afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if rate < 3 else 1 for rate in df.label] # 3ì  ë¯¸ë§Œì´ë©´ 0(ë¶€ì •), 3ì  ì´ˆê³¼ì´ë©´ 1(ê¸ì •)ìœ¼ë¡œ ë¼ë²¨ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250 3750 5000\n",
      "11250 3750 5000\n"
     ]
    }
   ],
   "source": [
    "#í‰ê°€ ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(df['text'].tolist(), y, random_state=0)\n",
    "\n",
    "#í•™ìŠµ, ê²€ì¦ ë°ì´í„°ì…‹ë¶„ë¦¬\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=0)\n",
    "\n",
    "print(len(X_train), len(X_val), len(X_test))\n",
    "print(len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d6afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_txt = randint(0, len(X_train))\n",
    "\n",
    "# print('í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ tokenize: ', okt.morphs(X_train[random_txt]))\n",
    "# print('ëª…ì‚¬ë§Œ ì¶”ì¶œ: ', okt.nouns(X_train[random_txt]))\n",
    "\n",
    "# # morphs(text) : í…ìŠ¤íŠ¸ì—ì„œ í˜•íƒœì†Œë¥¼ ë°˜í™˜í•œë‹¤\n",
    "# # nouns(text) : í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ë¥¼ ë°˜í™˜í•œë‹¤\n",
    "# # phrases(text) : í…ìŠ¤íŠ¸ì—ì„œ ì–´ì ˆì„ ë½‘ì•„ë‚¸ë‹¤\n",
    "# # pos(text) : í…ìŠ¤íŠ¸ì—ì„œ í’ˆì‚¬ ì •ë³´ë¥¼ ë¶€ì°©í•˜ì—¬ ë°˜í™˜í•œë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5181f95",
   "metadata": {},
   "source": [
    "### í¬ë¡¤ë§ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd68db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "forders = os.listdir('/home/adminuser/notebooks/modeling/raw_data/crawling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb14795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(forders)):\n",
    "    if forders[i].split('.')[1] == 'csv':\n",
    "        file = '/home/adminuser/notebooks/modeling/raw_data/crawling/'+forders[i]\n",
    "        df= pd.read_csv(file,encoding='utf-8') \n",
    "        df_all = pd.concat([df_all, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61b855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07203588",
   "metadata": {},
   "source": [
    "### Okt ëª…ì‚¬ë§Œ ì‚¬ìš© (tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f211097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf1 = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "# min_df: ìµœì†Œ ë¹ˆë„ê°’ì„ ì„¤ì •\n",
    "# DFëŠ” íŠ¹ì • ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚˜ëŠ” 'ë¬¸ì„œì˜ ìˆ˜'ë¥¼ ì˜ë¯¸\n",
    "# (ë‹¨ì–´ 'home'ì˜ ê²½ìš° ì „ì²´ ë¬¸ì„œì—ì„œ ë¹ˆë„ëŠ” 4ë²ˆ ì´ì§€ë§Œ,'home'ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì„œì˜ ìˆ˜ëŠ” 3ê°œì´ê¸° ë•Œë¬¸ì— DF = 3 )\n",
    "# DFì˜ ìµœì†Œê°’ì„ ì„¤ì •í•˜ì—¬ í•´ë‹¹ ê°’ë³´ë‹¤ ì‘ì€ DFë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤ì€ ë‹¨ì–´ì‚¬ì „ (vocabulary_)ì—ì„œ ì œì™¸í•˜ê³ , ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬í•˜ì§€ ì•ŠìŒ\n",
    "# ìµœì†Œ DFê°€ 5ë¡œ ì„¤ì •ë˜ì—ˆìœ¼ë‹ˆ, 1,2,3,4ì¸ ê²ƒë“¤ì€ ëª¨ë‘ íƒˆë½í•˜ê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16928df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf1.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b95a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f72e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_df_vectorizer = TfidfVectorizer(min_df = 2)\n",
    "# min_df_vectorizer.fit(text)\n",
    "# sorted(min_df_vectorizer.vocabulary_.items())\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sorted(X_train_tfidf.vocabulary_.items())\n",
    "# print(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04afbadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(max_iter=1000)\n",
    "results1= clf1.fit(X_train_tfidf, y_train)\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4be8484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.820\n",
      "#Test set score: 0.767\n"
     ]
    }
   ],
   "source": [
    "# train data ì˜ˆì¸¡ ì •í™•ë„\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
    "# test data ì˜ˆì¸¡ ì •í™•ë„\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd707cd",
   "metadata": {},
   "source": [
    "### Okt ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë¥¼ ì‚¬ìš© (tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3955e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text):\n",
    "    target_tags = ['None', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "538d2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8cd461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_twit = tfidf2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e44b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf_twit = tfidf2.transform(X_test)   \n",
    "\n",
    "#fit í•˜ì§€ ì•ŠëŠ”ë‹¤!! (ì°¸ê³ : https://deepinsight.tistory.com/165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea7039a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "results2 = clf2.fit(X_train_tfidf_twit, y_train)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72b3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.843\n",
      "#Test set score: 0.827\n"
     ]
    }
   ],
   "source": [
    "# train data ì˜ˆì¸¡ ì •í™•ë„\n",
    "print('#Train set score: {:.3f}'.format(clf2.score(X_train_tfidf_twit, y_train)))\n",
    "# test data ì˜ˆì¸¡ ì •í™•ë„\n",
    "print('#Test set score: {:.3f}'.format(clf2.score(X_test_tfidf_twit, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9061c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "530c7329",
   "metadata": {},
   "source": [
    "### sample dataì— ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b15d6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp= df_all.sample(10)\n",
    "tmp[\"regrex\"]=tmp.comment.map(lambda x : re.compile('[^ A-Za-z0-9ã„±-ã…£ê°€-í£]+').sub('', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86b6904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_txt_tfidf = tfidf1.transform(tmp['regrex'])\n",
    "clf1.predict(random_txt_tfidf)\n",
    "\n",
    "pred1 = pd.DataFrame({'clf1_label': clf1.predict(random_txt_tfidf)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c04733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_txt_tfidf_twit = tfidf2.transform(tmp['regrex']) #ë¶„ì„ê¸° ë„˜ë²„ ë§ì¶”ê¸°\n",
    "clf2.predict(random_txt_tfidf_twit)\n",
    "\n",
    "pred2 = pd.DataFrame({'clf2_label': clf2.predict(random_txt_tfidf_twit)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76485f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_compare = pd.concat([pred1, pred2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8e5e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_compare['comment'] = tmp.comment.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9da2fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf1_label</th>\n",
       "      <th>clf2_label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>í¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ëŒëŒ ë§ì•„ì„œ ë³´ê´€ ê°€ëŠ¥í•œê°€ìš”?????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ì¶”ì¹´ë“œë ¤ìš”â™¡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ì˜¤íˆë ¤ ê±°ë¦¬ë‘ê¸° ëë‚œ ìš”ì¦˜ì´ ë” ìœ„í—˜í•œê±° ê°™ì•„ìš”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>êµ¿ëª¨ë‹ ì…ë‹ˆë‹¤ ì ì‹œì™”ì–´ìš”^^ğŸ¤—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ë¯¸ì„¸ë¨¼ì§€ë•œì— ë§ˆìŠ¤í¬ í•´ì•¼ë˜ìš” ã…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022050229035281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ì„±ì¸ ì¤‘í˜•ì€ ë¼ì´ë¸Œí˜œíƒ í¬í•¨ ì•ˆë˜ë‚˜ìš©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ì‹œìƒìê°€ ë”ì”¬ë‚œ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf1_label  clf2_label                     comment\n",
       "0           1           0                           í¬\n",
       "1           1           0        ëŒëŒ ë§ì•„ì„œ ë³´ê´€ ê°€ëŠ¥í•œê°€ìš”?????\n",
       "2           1           1                      ì¶”ì¹´ë“œë ¤ìš”â™¡\n",
       "3           1           0  ì˜¤íˆë ¤ ê±°ë¦¬ë‘ê¸° ëë‚œ ìš”ì¦˜ì´ ë” ìœ„í—˜í•œê±° ê°™ì•„ìš”\n",
       "4           1           0            êµ¿ëª¨ë‹ ì…ë‹ˆë‹¤ ì ì‹œì™”ì–´ìš”^^ğŸ¤—\n",
       "5           1           0           ë¯¸ì„¸ë¨¼ì§€ë•œì— ë§ˆìŠ¤í¬ í•´ì•¼ë˜ìš” ã…\n",
       "6           1           0            2022050229035281\n",
       "7           0           0        ì„±ì¸ ì¤‘í˜•ì€ ë¼ì´ë¸Œí˜œíƒ í¬í•¨ ì•ˆë˜ë‚˜ìš©\n",
       "8           1           0                      ì•ˆë…•í•˜ì„¸ìš”~\n",
       "9           1           0             ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ì‹œìƒìê°€ ë”ì”¬ë‚œ"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e474b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('sample_file.txt', 'r')\n",
    "# sentence = f.read()\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4eab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('í˜•íƒœì†Œ:', t.morphs(sentence))\n",
    "# print('ëª…ì‚¬:', t.nouns(sentence))\n",
    "# print('í’ˆì‚¬ íƒœê¹… ê²°ê³¼:', t.pos(sentence))\n",
    "\n",
    "# tokens_const = t.morphs(sentence)\n",
    "# print('í† í°ì˜ ìˆ˜:', len(tokens_const))\n",
    "# print(tokens_const[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "version_test_azureml_py38",
   "language": "python",
   "name": "conda-env-version_test_azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
